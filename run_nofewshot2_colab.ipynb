{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c98hhB05X6ZF","executionInfo":{"status":"ok","timestamp":1724343204767,"user_tz":-540,"elapsed":2614,"user":{"displayName":"임병완","userId":"16912505565738020902"}},"outputId":"ad19e09b-9bce-4d06-81cc-ac7c182f6f1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"DdMyghv3X6ZJ","executionInfo":{"status":"ok","timestamp":1724343204767,"user_tz":-540,"elapsed":3,"user":{"displayName":"임병완","userId":"16912505565738020902"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"31166a35-f62b-474f-84ce-8fc0dd523001"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/Laptop/FINANCIAL_INFORMATION\n"]}],"source":["%cd /content/drive/Othercomputers/Laptop/FINANCIAL_INFORMATION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rpl9xn_aX6ZK"},"outputs":[],"source":["!pip install -q -r requirements.txt\n","!pip install --upgrade -q transformers"]},{"cell_type":"code","source":["# !huggingface-cli login"],"metadata":{"id":"6_0APDsumbJO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gAACYOpkX6ZK"},"outputs":[],"source":["# Model\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig, LlamaForCausalLM\n","from langchain_huggingface import HuggingFacePipeline\n","import torch\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain.prompts import PromptTemplate\n","# Vector stores\n","import fitz  # PyMuPDF\n","import pdfplumber\n","from langchain_community.vectorstores import FAISS\n","from langchain_huggingface import HuggingFaceEmbeddings\n","#from langchain_community.document_loaders import PyMuPDFLoader, PDFPlumberLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter, KonlpyTextSplitter, MarkdownHeaderTextSplitter\n","from langchain.text_splitter import MarkdownHeaderTextSplitter\n","#from langchain_community.retrievers import BM25Retriever, KNNRetriever\n","from langchain.retrievers import EnsembleRetriever\n","from langchain_community.vectorstores import FAISS\n","from langchain_huggingface import HuggingFaceEmbeddings\n","#from langchain_community.document_loaders import PyMuPDFLoader, PDFPlumberLoader ,UnstructuredPDFLoader\n","from langchain_community.retrievers import BM25Retriever, KNNRetriever\n","from langchain.retrievers import EnsembleRetriever\n","#from langchain_teddynote.retrievers import KiwiBM25Retriever, OktBM25Retriever\n","from langchain_teddynote.retrievers import OktBM25Retriever\n","from langchain.docstore.document import Document\n","#from concurrent.futures import ThreadPoolExecutor\n","import pandas as pd\n","import unicodedata\n","import pymupdf4llm\n","#import time\n","#import re\n","#from konlpy.tag import Okt\n","#from pdf2image import convert_from_path\n","import pytesseract\n","from konlpy.tag import Kkma\n","# etc\n","#import os\n","import pandas as pd\n","from tqdm import tqdm\n","import unicodedata\n","import logging\n","#from PyPDF2 import PdfReader\n","#import json\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'  # GPU 사용 가능 여부 및 MPS 지원 여부 확인\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wQ6fm_FtX6ZM"},"outputs":[],"source":["# intfloat/multilingual-e5-small\n","# jhgan/ko-sroberta-multitask\n","\n","def get_embedding():\n","\n","    embeddings = HuggingFaceEmbeddings(\n","        model_name='jhgan/ko-sroberta-multitask',\n","        model_kwargs={'device': device},\n","\n","        encode_kwargs={'normalize_embeddings': True})\n","    return embeddings\n","def normalize_string(s):\n","    try:\n","        normalized = unicodedata.normalize('NFC', s)\n","        return normalized.encode('utf-8', errors='replace').decode('utf-8')\n","    except Exception:\n","        return s\n","def clean_text(text):\n","    text = text.replace(\"�\", \" \").replace(\"\u0003\", \" \")  # 잘못된 인코딩 문자 제거\n","    return text\n","\n","def format_docs(docs):\n","    context = \"\"\n","\n","    for doc in docs:\n","        # Header 정보를 순서대로 추가\n","        for header_level in range(1, 6):\n","            header_key = f'Header{header_level}'\n","            if header_key in doc.metadata:\n","                context += f\"{header_key}: {doc.metadata[header_key]}\\n\"\n","        # 문서 내용 추가\n","        context += doc.page_content\n","        context += '\\n---\\n'\n","    return context\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CiJxnDx1X6ZN"},"outputs":[],"source":["def process_pdf(pdf_path):\n","    md_text = pymupdf4llm.to_markdown(pdf_path)\n","\n","    headers_to_split_on = [\n","        (\"#\", \"Header 1\"),\n","        (\"##\", \"Header 2\"),\n","        (\"###\", \"Header 3\"),\n","        (\"####\", \"Header 4\"),\n","        (\"#####\", \"Header 5\"),\n","        (\"######\", \"Header 6\")\n","    ]\n","\n","    md_header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=True)\n","    md_chunks = md_header_splitter.split_text(md_text)\n","\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=512, chunk_overlap=128\n","    )\n","\n","    splits = text_splitter.split_documents(md_chunks)\n","\n","    for i in splits:\n","        metadata = {'Source_path': pdf_path}\n","        i.metadata = {**i.metadata, **metadata}\n","    return splits\n","\n","\n","def make_db(df):\n","    documents = []\n","\n","    pdf_files = df['Source_path'].unique()\n","    for pdf_file in tqdm(pdf_files):\n","        # 문서 로드\n","        documents.extend(process_pdf(pdf_file))\n","\n","    print(f\"Total number of documents: {len(documents)}\")\n","\n","    faiss = FAISS.from_documents(documents, embedding=get_embedding())\n","    return faiss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-kbbq7E5X6ZO"},"outputs":[],"source":["def fewshot_db(df):\n","    df = df.drop('SAMPLE_ID', axis=1)\n","    df = df.drop('Source_path', axis=1)\n","    df = df.to_dict(orient='records')\n","    print(\"Loaded Fewshot Set:\", len(df))\n","    to_vectorize = [\"\\n\\n\".join(normalize_string(value) for value in example.values()) for example in df]\n","    faiss = FAISS.from_texts(to_vectorize, embedding=get_embedding())\n","    # bm = BM25Retriever.from_texts(to_vectorize)\n","    # knn = KNNRetriever.from_texts(to_vectorize, embeddings=get_embedding())\n","    return faiss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eQGqgXNfX6ZP"},"outputs":[],"source":["train_df = pd.read_csv('train.csv', encoding='utf-8')\n","test_df = pd.read_csv('test.csv', encoding='utf-8')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ATjsG5SMX6ZP"},"outputs":[],"source":["def format_docs(docs):\n","    context = \"\"\n","    for doc in docs:\n","        # Header 정보를 순서대로 추가\n","        for header_level in range(1, 6):\n","            header_key = f'Header {header_level}'\n","            if header_key in doc.metadata:\n","                context += f\"{header_key}: {doc.metadata[header_key]}\\n\"\n","        # 문서 내용 추가\n","        context += doc.page_content\n","        context += '\\n---\\n'\n","    return context"]},{"cell_type":"markdown","metadata":{"id":"BpRPDeKIX6ZQ"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pFPoRjz5X6Zb"},"outputs":[],"source":["def setup_llm_pipeline(model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"):\n","    # 토크나이저 로드 및 설정\n","        # 양자화 설정 적용\n","    bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n","    )\n","    model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config,low_cpu_mem_usage=True)\n","\n","    # # 일부 중요한 레이어는 FP16으로 유지\n","    # for name, module in model.named_modules():\n","    #     if \"attention\" in name or \"ffn\" in name:  # 중요한 레이어 식별 (예: attention 및 ffn)\n","    #         module.to(torch.float16)  # 이 부분은 16비트로 유지\n","\n","    tokenizer = AutoTokenizer.from_pretrained(model_id)\n","    terminators = [\n","    tokenizer.eos_token_id,\n","    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","    ]\n","\n","    text_generation_pipeline = pipeline(\n","        model=model,\n","        tokenizer=tokenizer,\n","        task=\"text-generation\",\n","        return_full_text=False,\n","        max_new_tokens=1024,\n","        eos_token_id = terminators,\n","        pad_token_id = tokenizer.eos_token_id\n","    )\n","\n","    llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n","\n","    return llm\n","# ghost-x/ghost-8b-beta-1608\n","# OpenBuddy/openbuddy-llama3.1-8b-v22.3-131k\n","llm = setup_llm_pipeline()"]},{"cell_type":"markdown","metadata":{"id":"3EknRGK9X6Zc"},"source":["### 점수"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OcCU3ZRWX6Zd"},"outputs":[],"source":["from collections import Counter\n","def calculate_f1_score(true_sentence, predicted_sentence, sum_mode=True):\n","\n","    #공백 제거\n","    true_sentence = ''.join(true_sentence.split())\n","    predicted_sentence = ''.join(predicted_sentence.split())\n","\n","    true_counter = Counter(true_sentence)\n","    predicted_counter = Counter(predicted_sentence)\n","\n","    #문자가 등장한 개수도 고려\n","    if sum_mode:\n","        true_positive = sum((true_counter & predicted_counter).values())\n","        predicted_positive = sum(predicted_counter.values())\n","        actual_positive = sum(true_counter.values())\n","\n","    #문자 자체가 있는 것에 focus를 맞춤\n","    else:\n","        true_positive = len((true_counter & predicted_counter).values())\n","        predicted_positive = len(predicted_counter.values())\n","        actual_positive = len(true_counter.values())\n","\n","    #f1 score 계산\n","    precision = true_positive / predicted_positive if predicted_positive > 0 else 0\n","    recall = true_positive / actual_positive if actual_positive > 0 else 0\n","    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","    return precision, recall, f1_score\n","\n","def calculate_average_f1_score(true_sentences, predicted_sentences):\n","\n","    total_precision = 0\n","    total_recall = 0\n","    total_f1_score = 0\n","\n","    for true_sentence, predicted_sentence in zip(true_sentences, predicted_sentences):\n","        precision, recall, f1_score = calculate_f1_score(true_sentence, predicted_sentence)\n","        total_precision += precision\n","        total_recall += recall\n","        total_f1_score += f1_score\n","\n","    avg_precision = total_precision / len(true_sentences)\n","    avg_recall = total_recall / len(true_sentences)\n","    avg_f1_score = total_f1_score / len(true_sentences)\n","\n","    return {\n","        'average_precision': avg_precision,\n","        'average_recall': avg_recall,\n","        'average_f1_score': avg_f1_score\n","    }"]},{"cell_type":"markdown","metadata":{"id":"WJryDd-GX6Zd"},"source":["### RUN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-tmUuelX6Zd"},"outputs":[],"source":["\n","def extract_answer(response):\n","    # AI: 로 시작하는 줄을 찾아 그 이후의 텍스트만 추출\n","    lines = response.split('\\n')\n","    for line in lines:\n","        line = line.replace('**', '')\n","        if line.startswith('Answer:'):\n","            return line.replace('Answer:', '').strip()\n","        if line.startswith('assistant:'):\n","            return line.replace('assistant:', '').strip()\n","    return response.strip()  # AI: 를 찾지 못한 경우 전체 응답을 정리해서 반환\n","\n","def rerun(question,context,answer,llm,num_repeat):\n","    full_template = \"<|begin_of_text|>\"\n","    full_template += \"\"\"<|start_header_id|>system<|end_header_id|>당신은 이전 답변을 검증하는 챗봇입니다. 질문과 문맥, 이전 답변을 참고해서 지시사항을 따르세요. 지시사항을 따를 때 서론 없이 출력하세요.<|eot_id|>\"\"\"\n","    full_template += f\"\"\"<|start_header_id|>user<|end_header_id|>Question: {question} \\n\\nContexts: {context} \\n\\nPrevious Answer: {answer} \\n\\n\"\"\"\n","    full_template += \"\"\"{input}<|eot_id|>\"\"\"\n","    full_template += \"\"\"<|start_header_id|>assistant<|end_header_id|>\"\"\"\n","\n","    prompt = PromptTemplate(template=full_template)\n","    chain = (\n","    {\n","        \"input\": RunnablePassthrough(),\n","    }\n","    | prompt\n","    | llm\n","    | StrOutputParser()\n","    )\n","    return chain.invoke(\"핵심 단어들을 바탕으로, 한 문장으로 요약하세요. 만약 한 문장이라면 그대로 출력하세요.\")\n","\n","def run(faiss,dataset,llm,k=2,verbose=False):\n","    results = []\n","    source_path = dataset.iloc[0]['Source_path']\n","    docs = faiss.similarity_search(\n","    query=\"\",  # 유사도 기반이 아닌 메타데이터 필터링만 사용하므로 query는 빈 값으로\n","    filter={\"Source_path\": source_path},\n","    k = 99,\n","    fetch_k = 20000\n","    )\n","    buff_faiss = FAISS.from_documents(docs, embedding=get_embedding())\n","    faiss_retriever_mmr = buff_faiss.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": k})\n","    faiss_retriever_sim = buff_faiss.as_retriever(search_kwargs={\"k\": k})\n","    knn_retriever = KNNRetriever.from_documents(docs, embeddings=get_embedding())\n","    knn_retriever.k = k\n","    bm_retriever = OktBM25Retriever.from_documents(docs)\n","    bm_retriever.k = k\n","\n","    ensemble_retriever = EnsembleRetriever(retrievers=[faiss_retriever_mmr,faiss_retriever_sim,knn_retriever,bm_retriever], weight=[0.25 ,0.25,0.25 ,0.25])\n","\n","\n","    for i, row in (dataset.iterrows()):\n","        if source_path != row['Source_path']:\n","            source_path = row['Source_path']\n","            docs = faiss.similarity_search(\n","                query=\"\",  # 유사도 기반이 아닌 메타데이터 필터링만 사용하므로 query는 빈 값으로\n","                filter={\"Source_path\": source_path},\n","                k = 99,\n","                fetch_k = 20000\n","            )\n","            buff_faiss = FAISS.from_documents(docs, embedding=get_embedding())\n","            faiss_retriever_mmr = buff_faiss.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": k})\n","            faiss_retriever_sim = buff_faiss.as_retriever(search_kwargs={\"k\": k})\n","            knn_retriever = KNNRetriever.from_documents(docs, embeddings=get_embedding())\n","            knn_retriever.k = k\n","            bm_retriever = OktBM25Retriever.from_documents(docs)\n","            bm_retriever.k = k\n","\n","            ensemble_retriever = EnsembleRetriever(retrievers=[faiss_retriever_mmr,faiss_retriever_sim,knn_retriever,bm_retriever], weight=[0.25 ,0.25,0.25 ,0.25])\n","\n","\n","        full_template = \"<|begin_of_text|>\"\n","        full_template += \"\"\"<|start_header_id|>system<|end_header_id|>\n","당신은 유용한 금융 정보 QnA 챗봇입니다.\n","질문을 차근차근 생각하고, 답변 시 반드시 문맥 정보를 활용해야합니다.\n","질문에 내용을 전부 대답하세요.\n","객관적이고 공식적인 문체를 사용해 정확하게 작성하세요.\n","서론 없이 핵심 내용을 최대한 짧고 간결하게 작성해주세요. <|eot_id|>\n","\"\"\"\n","        question = row['Question']\n","        # full_template += \"\"\" \"\"\"\n","        contexts = ensemble_retriever.invoke(normalize_string(question))\n","\n","        contexts = format_docs(contexts)\n","        full_template += \"\"\"<|start_header_id|>user<|end_header_id|>Question: {input}\\n\\n\"\"\"\n","        full_template += f\"\"\"Contexts: {contexts}<|eot_id|>\"\"\"\n","        full_template += \"\"\"<|start_header_id|>assistant<|end_header_id>\"\"\"\n","\n","        prompt = PromptTemplate(template=full_template, input_variables=[\"input\"])\n","        qa_chain = (\n","        {\n","            \"input\": RunnablePassthrough(),\n","        }\n","        | prompt\n","        | llm\n","        | StrOutputParser()\n","        )\n","\n","        answer = qa_chain.invoke(input=question)\n","        answer = extract_answer(answer)\n","        lines = answer.split('\\n')\n","        if  len(lines) > 1 or '|' in answer or ':' in answer:\n","            previous = answer\n","            try:\n","                before = calculate_f1_score(row['Answer'],answer)[2]\n","            except:\n","                before = None\n","            answer = rerun(question=question,\n","                           context=contexts,\n","                           answer=answer,\n","                           llm=llm,\n","                           num_repeat=1)\n","        answer = extract_answer(answer)\n","        results.append({\n","            \"Question\": question,\n","            \"Answer\": answer,\n","            \"Source\": row['Source']\n","        })\n","        if verbose:\n","            print(f\"{i}/{len(dataset)}\")\n","            print(\"Question: \", question, end=\" | \")\n","            print(\"Context Number |\",len(contexts))\n","            try:\n","                print(calculate_f1_score(row['Answer'],answer)[2],end=\" | \")\n","            except:\n","                pass\n","            print(\"Answer: \", results[-1]['Answer'])\n","            try:\n","                print(\"Before: \",before,\" | \",previous)\n","\n","                previous = None\n","                before = None\n","            except:\n","                pass\n","\n","            try:\n","                print(\"REAL Answer: \",row['Answer'])\n","            except:\n","                pass\n","\n","            print()\n","\n","    return results"]},{"cell_type":"markdown","metadata":{"id":"wpEp-dhDX6Ze"},"source":["### 케이폴드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BsP2dAnHX6Zf"},"outputs":[],"source":["# from sklearn.model_selection import KFold\n","# import copy\n","\n","# weight = [0.3,0.3,0.4]\n","# train_faiss_db,knn_retriever ,train_bm_retrievier = make_db(train_df)\n","\n","# train_k = 3\n","# train_bm_retrievier.k = train_k\n","# knn_retriever.k = train_k\n","# train_faiss_retriever = train_faiss_db.as_retriever(search_type=\"mmr\",search_kwargs={'k':train_k} )\n","# train_ensemble_retriever = EnsembleRetriever(\n","#     retrievers=[train_bm_retrievier, knn_retriever,train_faiss_retriever], weights=weight , search_kwargs={'k':train_k}\n","# )\n","\n","\n","# fewshot_k = 3\n","\n","# k_folds = 4\n","# fold_results = []\n","# kf = KFold(n_splits=k_folds, shuffle=True, random_state=52)\n","# for fold, (train_index, val_index) in enumerate(kf.split(train_df)):\n","#     fold_result = []\n","#     train_set = train_df.iloc[train_index]\n","#     val_set = train_df.iloc[val_index]\n","\n","#     faiss = make_db(val_set)\n","\n","#     pred = run(faiss,val_set, llm, verbose=True)\n","#     result = pd.DataFrame()\n","#     result['pred'] = [result['Answer'] for result in pred]\n","#     val_set.index = range(len(val_set))\n","#     result['gt'] = val_set['Answer']\n","\n","#     result = calculate_average_f1_score(result['gt'], result['pred'])\n","#     print(result)\n","#     fold_results.append(result)\n","#     break"]},{"cell_type":"markdown","metadata":{"id":"w6cRyhfnX6Zf"},"source":["### 실전"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"THntFWRyX6Zf"},"outputs":[],"source":["def save(results):\n","    # 제출용 샘플 파일 로드\n","    submit_df = pd.read_csv(\"./sample_submission.csv\")\n","    # 생성된 답변을 제출 DataFrame에 추가\n","    submit_df['Answer'] = [item['Answer'] for item in results]\n","    submit_df['Answer'] = submit_df['Answer'].fillna(\"데이콘\")     # 모델에서 빈 값 (NaN) 생성 시 채점에 오류가 날 수 있음 [ 주의 ]\n","    time = pd.Timestamp.now()\n","    # 결과를 CSV 파일로 저장\n","    submit_df.to_csv(f\"./submission_bw/sub_{time.month}_{time.day}_{time.hour}{time.minute}.csv\", encoding='UTF-8-sig', index=False)\n","    print(\"저장 완료\")\n","\n","faiss= make_db(test_df)\n","\n","results = run(faiss, test_df, llm, verbose=True)\n","save(results)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}