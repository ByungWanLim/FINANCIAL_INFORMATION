{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig, LlamaForCausalLM\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "import torch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "# Vector stores\n",
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "#from langchain_community.document_loaders import PyMuPDFLoader, PDFPlumberLoader\n",
    "#from langchain.text_splitter import RecursiveCharacterTextSplitter, KonlpyTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "#from langchain_community.retrievers import BM25Retriever, KNNRetriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "#from langchain_community.document_loaders import PyMuPDFLoader, PDFPlumberLoader ,UnstructuredPDFLoader\n",
    "from langchain_community.retrievers import BM25Retriever, KNNRetriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "#from langchain_teddynote.retrievers import KiwiBM25Retriever, OktBM25Retriever\n",
    "from langchain_teddynote.retrievers import OktBM25Retriever\n",
    "from langchain.docstore.document import Document\n",
    "#from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import pymupdf4llm\n",
    "#import time\n",
    "#import re\n",
    "#from konlpy.tag import Okt\n",
    "#from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from konlpy.tag import Kkma\n",
    "# etc\n",
    "#import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import logging\n",
    "#from PyPDF2 import PdfReader\n",
    "#import json\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # GPU 사용 가능 여부 및 MPS 지원 여부 확인\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intfloat/multilingual-e5-small\n",
    "# jhgan/ko-sroberta-multitask\n",
    "\n",
    "def get_embedding():\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='jhgan/ko-sroberta-multitask',\n",
    "        model_kwargs={'device': device},\n",
    "        encode_kwargs={'normalize_embeddings': True})\n",
    "    return embeddings\n",
    "def normalize_string(s):\n",
    "    try:\n",
    "        normalized = unicodedata.normalize('NFC', s)\n",
    "        return normalized.encode('utf-8', errors='replace').decode('utf-8')\n",
    "    except Exception:\n",
    "        return s\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"�\", \" \").replace(\"\u0003\", \" \")  # 잘못된 인코딩 문자 제거\n",
    "    return text\n",
    "\n",
    "def format_docs(docs):\n",
    "    context = \"\"\n",
    "    i = 1\n",
    "    for doc in docs:\n",
    "        #context += f\"Document: {i}\" +\"Source:\"+ doc.metadata['source'] +'\\n'\n",
    "        context += doc.page_content\n",
    "        context += '\\n---\\n'\n",
    "        i += 1\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path): \n",
    "    md_text = pymupdf4llm.to_markdown(pdf_path)\n",
    "\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "        (\"####\", \"Header 4\"),\n",
    "    ]\n",
    "\n",
    "    md_header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=True)\n",
    "    splits = md_header_splitter.split_text(md_text)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=700, chunk_overlap=60\n",
    "    )\n",
    "\n",
    "    splits = text_splitter.split_documents(splits)\n",
    "\n",
    "    for i in splits:\n",
    "        metadata = {'Source_path': pdf_path}\n",
    "        i.metadata = {**i.metadata, **metadata}\n",
    "    return splits\n",
    "\n",
    "\n",
    "def make_db(df):\n",
    "    documents = []\n",
    "    \n",
    "    pdf_files = df['Source_path'].unique()\n",
    "    for pdf_file in tqdm(pdf_files):\n",
    "        # 문서 로드\n",
    "        documents.extend(process_pdf(pdf_file))\n",
    "        \n",
    "    print(f\"Total number of documents: {len(documents)}\")\n",
    "\n",
    "    faiss = FAISS.from_documents(documents, embedding=get_embedding())\n",
    "    return faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fewshot_db(df):\n",
    "    df = df.drop('SAMPLE_ID', axis=1)\n",
    "    df = df.drop('Source_path', axis=1)\n",
    "    df = df.to_dict(orient='records')\n",
    "    print(\"Loaded Fewshot Set:\", len(df))\n",
    "    to_vectorize = [\"\\n\\n\".join(normalize_string(value) for value in example.values()) for example in df]\n",
    "    faiss = FAISS.from_texts(to_vectorize, embedding=get_embedding())\n",
    "    # bm = BM25Retriever.from_texts(to_vectorize)\n",
    "    # knn = KNNRetriever.from_texts(to_vectorize, embeddings=get_embedding())\n",
    "    return faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test_df = pd.read_csv('test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n",
    "    context = \"\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        #context += f\"Document {i+1}\\n\"\n",
    "        doc.page_content = doc.page_content.replace(\"{\", \"(\")\n",
    "        doc.page_content = doc.page_content.replace(\"}\", \")\")\n",
    "        \n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:30<00:00,  7.57s/it]\n"
     ]
    }
   ],
   "source": [
    "def setup_llm_pipeline(model_id=\"meta-llama/Meta-Llama-3.1-8B-Instruct\"):\n",
    "    # 양자화 설정 적용\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  # 기본적으로 4비트로 로드\n",
    "        bnb_4bit_use_double_quant=True,  # 두 번 양자화 적용\n",
    "        bnb_4bit_quant_type=\"nf4\",  # 4비트 양자화 유형 선택\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,  # 연산은 bf16으로 수행\n",
    "        load_in_low_bit = True\n",
    "        \n",
    "    )\n",
    "\n",
    "    # 모델 로드\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, \n",
    "        quantization_config=bnb_config,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "\n",
    "    # 일부 중요한 레이어는 FP16으로 유지\n",
    "    for name, module in model.named_modules():\n",
    "        if \"attention\" in name or \"ffn\" in name:  # 중요한 레이어 식별 (예: attention 및 ffn)\n",
    "            module.to(torch.float16)  # 이 부분은 16비트로 유지\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    text_generation_pipeline = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=1024,\n",
    "        eos_token_id = terminators,\n",
    "        pad_token_id = tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "    return llm\n",
    "# ghost-x/ghost-8b-beta-1608\n",
    "# OpenBuddy/openbuddy-llama3.1-8b-v22.3-131k\n",
    "llm = setup_llm_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def calculate_f1_score(true_sentence, predicted_sentence, sum_mode=True):\n",
    "\n",
    "    #공백 제거\n",
    "    true_sentence = ''.join(true_sentence.split())\n",
    "    predicted_sentence = ''.join(predicted_sentence.split())\n",
    "    \n",
    "    true_counter = Counter(true_sentence)\n",
    "    predicted_counter = Counter(predicted_sentence)\n",
    "\n",
    "    #문자가 등장한 개수도 고려\n",
    "    if sum_mode:\n",
    "        true_positive = sum((true_counter & predicted_counter).values())\n",
    "        predicted_positive = sum(predicted_counter.values())\n",
    "        actual_positive = sum(true_counter.values())\n",
    "\n",
    "    #문자 자체가 있는 것에 focus를 맞춤\n",
    "    else:\n",
    "        true_positive = len((true_counter & predicted_counter).values())\n",
    "        predicted_positive = len(predicted_counter.values())\n",
    "        actual_positive = len(true_counter.values())\n",
    "\n",
    "    #f1 score 계산\n",
    "    precision = true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    recall = true_positive / actual_positive if actual_positive > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def calculate_average_f1_score(true_sentences, predicted_sentences):\n",
    "    \n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1_score = 0\n",
    "    \n",
    "    for true_sentence, predicted_sentence in zip(true_sentences, predicted_sentences):\n",
    "        precision, recall, f1_score = calculate_f1_score(true_sentence, predicted_sentence)\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1_score += f1_score\n",
    "    \n",
    "    avg_precision = total_precision / len(true_sentences)\n",
    "    avg_recall = total_recall / len(true_sentences)\n",
    "    avg_f1_score = total_f1_score / len(true_sentences)\n",
    "    \n",
    "    return {\n",
    "        'average_precision': avg_precision,\n",
    "        'average_recall': avg_recall,\n",
    "        'average_f1_score': avg_f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_answer(response):\n",
    "    # AI: 로 시작하는 줄을 찾아 그 이후의 텍스트만 추출\n",
    "    lines = response.split('\\n')\n",
    "    for line in lines:\n",
    "        line = line.replace('**', '')\n",
    "        if line.startswith('Answer:'):\n",
    "            return line.replace('Answer:', '').strip()\n",
    "        if line.startswith('assistant:'):\n",
    "            return line.replace('assistant:', '').strip()\n",
    "    return response.strip()  # AI: 를 찾지 못한 경우 전체 응답을 정리해서 반환\n",
    "\n",
    "def equal_path(contexts, source_path):\n",
    "    adjusted_docs = []\n",
    "    for doc in contexts:\n",
    "        if doc.metadata['Source_path'] == source_path:\n",
    "            adjusted_docs.append(doc)\n",
    "    return adjusted_docs\n",
    "\n",
    "def rerun(question,context,answer,llm,num_repeat):\n",
    "    full_template = \"<|begin_of_text|>\"\n",
    "    full_template += \"\"\"<|start_header_id|>system<|end_header_id|>당신은 이전 답변을 검증하는 챗봇입니다. 질문과 문맥, 이전 답변을 참고해서 지시사항을 따르세요. 지시사항을 따를 때 서론 없이 출력하세요.<|eot_id|>\"\"\"\n",
    "    full_template += f\"\"\"<|start_header_id|>user<|end_header_id|>Question: {question} \\n\\nContexts: {context} \\n\\nPrevious Answer: {answer} \\n\\n\"\"\"\n",
    "    full_template += \"\"\"{input}<|eot_id|>\"\"\"\n",
    "    full_template += \"\"\"<|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(template=full_template)\n",
    "    chain = (\n",
    "    {\n",
    "        \"input\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    )\n",
    "    return chain.invoke(\"핵심 단어들을 바탕으로, 한 문장으로 요약하세요. 만약 한 문장이라면 그대로 출력하세요.\")\n",
    "    \n",
    "def run(faiss,dataset,llm,k=2,verbose=False):\n",
    "    results = []\n",
    "    source_path = dataset.iloc[0]['Source_path']\n",
    "    docs = faiss.similarity_search(\n",
    "        query=\"\",  # 유사도 기반이 아닌 메타데이터 필터링만 사용하므로 query는 빈 값으로\n",
    "        filter={\"Source_path\": source_path},\n",
    "        k = 99,\n",
    "        fetch_k = 20000\n",
    "        )\n",
    "    buff_faiss = FAISS.from_documents(docs, embedding=get_embedding())\n",
    "    faiss_retriever = buff_faiss.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": k})\n",
    "    knn_retriever = KNNRetriever.from_documents(docs, embeddings=get_embedding())\n",
    "    knn_retriever.k = k\n",
    "    bm_retriever = OktBM25Retriever.from_documents(docs)\n",
    "    bm_retriever.k = k\n",
    "    ensemble_retriever = EnsembleRetriever(retrievers=[faiss_retriever, knn_retriever,bm_retriever], weight=[0.4, 0.3, 0.3])\n",
    "    \n",
    "    for i, row in (dataset.iterrows()):\n",
    "        if source_path != row['Source_path']:   \n",
    "            source_path = row['Source_path']\n",
    "            docs = faiss.similarity_search(\n",
    "                query=\"\",  # 유사도 기반이 아닌 메타데이터 필터링만 사용하므로 query는 빈 값으로\n",
    "                filter={\"Source_path\": source_path},\n",
    "                k = 99,\n",
    "                fetch_k = 20000\n",
    "                )\n",
    "            buff_faiss = FAISS.from_documents(docs, embedding=get_embedding())\n",
    "            faiss_retriever = buff_faiss.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": k})\n",
    "            knn_retriever = KNNRetriever.from_documents(docs, embeddings=get_embedding())\n",
    "            knn_retriever.k = k\n",
    "            bm_retriever = OktBM25Retriever.from_documents(docs)\n",
    "            bm_retriever.k = k\n",
    "            ensemble_retriever = EnsembleRetriever(retrievers=[faiss_retriever, knn_retriever,bm_retriever], weight=[0.4, 0.3, 0.3])\n",
    "            \n",
    "        full_template = \"<|begin_of_text|>\"\n",
    "        full_template += \"\"\"<|start_header_id|>system<|end_header_id|>\n",
    "당신은 유용한 금융 정보 QnA 챗봇입니다.\n",
    "질문을 정확히 이해하고, 모든 질문에 답하세요.\n",
    "답변 시 반드시 문맥 정보를 활용해야합니다. \n",
    "서론 없이 핵심 내용을 한 문장으로 작성해주세요. \n",
    "<|eot_id|>\n",
    "\"\"\"\n",
    "        question = row['Question']          \n",
    "        # full_template += \"\"\" \"\"\"\n",
    "        contexts = ensemble_retriever.invoke(normalize_string(question))\n",
    "        # contexts = equal_path(contexts,row['Source_path'])\n",
    "        contexts = format_docs(contexts)\n",
    "        full_template += \"\"\"<|start_header_id|>user<|end_header_id|>Question: {input}\\n\\n\"\"\"\n",
    "        full_template += f\"\"\"Contexts: {contexts}<|eot_id|>\"\"\"\n",
    "        full_template += \"\"\"<|start_header_id|>assistant<|end_header_id>\"\"\"\n",
    "        \n",
    "        prompt = PromptTemplate(template=full_template, input_variables=[\"input\"])\n",
    "        qa_chain = (\n",
    "        {\n",
    "            \"input\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        answer = qa_chain.invoke(input=question)\n",
    "        answer = extract_answer(answer)\n",
    "        lines = answer.split('\\n')\n",
    "        if  len(lines) > 1:\n",
    "            previous = answer\n",
    "            try:\n",
    "                before = calculate_f1_score(row['Answer'],answer)[2]\n",
    "            except:\n",
    "                before = None\n",
    "            answer = rerun(question=question,\n",
    "                           context=contexts,\n",
    "                           answer=answer,\n",
    "                           llm=llm,\n",
    "                           num_repeat=1)\n",
    "        answer = extract_answer(answer)\n",
    "        results.append({\n",
    "            \"Question\": question,\n",
    "            \"Answer\": answer,\n",
    "            \"Source\": row['Source']\n",
    "        })\n",
    "        if verbose:\n",
    "            print(f\"{i}/{len(dataset)}\")\n",
    "            print(\"Question: \", question, end=\" | \")\n",
    "            print(\"Context Number |\",len(contexts))\n",
    "            try:\n",
    "                print(calculate_f1_score(row['Answer'],answer)[2],end=\" | \")\n",
    "            except:\n",
    "                pass\n",
    "            print(\"Answer: \", results[-1]['Answer'])\n",
    "            try:\n",
    "                print(\"Before: \",before,\" | \",previous)  \n",
    "                \n",
    "                previous = None\n",
    "                before = None\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                print(\"REAL Answer: \",row['Answer'])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            print()\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 케이폴드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# import copy\n",
    "\n",
    "# # weight = [0.3,0.3,0.4]\n",
    "# # train_faiss_db,knn_retriever ,train_bm_retrievier = make_db(train_df) \n",
    "\n",
    "# # train_k = 3\n",
    "# # train_bm_retrievier.k = train_k\n",
    "# # knn_retriever.k = train_k\n",
    "# # train_faiss_retriever = train_faiss_db.as_retriever(search_type=\"mmr\",search_kwargs={'k':train_k} )\n",
    "# # train_ensemble_retriever = EnsembleRetriever(\n",
    "# #     retrievers=[train_bm_retrievier, knn_retriever,train_faiss_retriever], weights=weight , search_kwargs={'k':train_k}\n",
    "# # )\n",
    "\n",
    "\n",
    "# # fewshot_k = 3\n",
    "\n",
    "# k_folds = 4\n",
    "# fold_results = []\n",
    "# kf = KFold(n_splits=k_folds, shuffle=True, random_state=52)\n",
    "# for fold, (train_index, val_index) in enumerate(kf.split(train_df)):\n",
    "#     fold_result = []\n",
    "#     train_set = train_df.iloc[train_index]\n",
    "#     val_set = train_df.iloc[val_index]\n",
    "\n",
    "#     faiss = make_db(val_set)\n",
    "\n",
    "#     pred = run(faiss,val_set, llm, verbose=True)\n",
    "#     result = pd.DataFrame()\n",
    "#     result['pred'] = [result['Answer'] for result in pred]\n",
    "#     val_set.index = range(len(val_set))\n",
    "#     result['gt'] = val_set['Answer']\n",
    "        \n",
    "#     result = calculate_average_f1_score(result['gt'], result['pred'])\n",
    "#     print(result)\n",
    "#     fold_results.append(result)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:12<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:653: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/98\n",
      "Question:  2022년 혁신창업사업화자금(융자)의 예산은 얼마인가요? | Context Number | 2853\n",
      "Answer:  2022년 혁신창업사업화자금(융자)의 예산은 2,007,800백만원입니다.\n",
      "\n",
      "1/98\n",
      "Question:  중소벤처기업부의 혁신창업사업화자금(융자) 사업목적은 무엇인가요? | Context Number | 2853\n",
      "Answer:  중소벤처기업부의 혁신창업사업화자금(융자) 사업의 목적은 기술력과 사업성이 우수하고 미래 성장가능성이 높은 중소벤처기업의 창업을 활성화하고 고용창출을 도모하고, 중소기업이 보유한 우수 기술의 개발 및 제품화·사업화를 촉진하여 기술기반 중소기업을 육성하는 것입니다.\n",
      "\n",
      "2/98\n",
      "Question:  중소벤처기업부의 혁신창업사업화자금(융자) 사업근거는 어떤 법률에 근거하고 있나요? | Context Number | 2853\n",
      "Answer:  중소벤처기업부의 혁신창업사업화자금(융자) 사업근거는 중소기업진흥에 관한 법률 제66조, 제67조, 제74조입니다.\n",
      "\n",
      "3/98\n",
      "Question:  2010년에 신규 지원된 혁신창업사업화자금은 무엇인가요? | Context Number | 2256\n",
      "Answer:  2010년 신규 지원된 혁신창업사업화자금은 재창업자금(실패 경영인에 대한 재기 지원)을 신규 지원한 것입니다.\n",
      "\n",
      "4/98\n",
      "Question:  혁신창업사업화자금 중 2020년에 신규 지원된 자금은 무엇인가요? | Context Number | 2256\n",
      "Answer:  2020년 신규 지원된 혁신창업사업화자금은 2,300,000 만원입니다.\n",
      "\n",
      "5/98\n",
      "Question:  재창업자금이 재도약지원자금으로 이관된 연도는 언제인가요? | Context Number | 2256\n",
      "Answer:  재창업자금이 재도약지원자금으로 이관된 연도는 2015년입니다.\n",
      "\n",
      "6/98\n",
      "Question:  창업기반지원과 신청 대상이 중복인 자금이 어떤 것이며, 이 자금이 폐지된 연도는 언제인가요? | Context Number | 2853\n",
      "Answer:  창업기반지원과 신청 대상이 중복인 자금은 일자리창출촉진자금입니다. 이 자금이 폐지된 연도는 2023년입니다.\n",
      "\n",
      "7/98\n",
      "Question:  혁신창업사업화자금(융자) 사업을 시행하는 주체는 누구인가요? | Context Number | 2853\n",
      "Answer:  혁신창업사업화자금(융자) 사업을 시행하는 주체는 중소벤처기업진흥공단입니다.\n",
      "\n",
      "8/98\n",
      "Question:  혁신창업사업화자금(융자) 사업 집행절차는 어떻게 되나요? | Context Number | 2853\n",
      "Answer:  융자 실행 후 평가 및 승인 후 융자 실행\n",
      "Before:  None  |  혁신창업사업화자금(융자)의 집행절차는 다음과 같습니다.\n",
      "\n",
      "1. 사업계획 수립 및 공고\n",
      "2. 사전 상담 및 신청\n",
      "3. 접수\n",
      "4. 융자 실행 지원 결정 통보\n",
      "5. 평가 및 승인\n",
      "6. 융자 실행\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/98\n",
      "Question:  부모급여 지원 사업의 목적은 무엇인가요? | Context Number | 1885\n",
      "Answer:  부모급여 지원 사업의 목적은 출산 및 양육으로 손실되는 소득을 보전하고, 주 양육자의 직접 돌봄이 중요한 아동 발달의 특성에 따라 영아기 돌봄을 두텁게 지원하기 위함입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "10/98\n",
      "Question:  부모급여(영아수당)의 2024년 확정된 예산은 몇백만원인가요? | Context Number | 2392\n",
      "Answer:  2024년 부모급여(영아수당)의 예산은 2,888,694백만원입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "11/98\n",
      "Question:  부모급여 지원 사업은 어떤 법령상 근거를 갖고 추진되고 있나요? | Context Number | 2392\n",
      "Answer:  아동수당법 제4조 제5항에 근거하여 추진되고 있습니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "12/98\n",
      "Question:  영아수당 도입에 대한 추진경위는 어떻게 되나요? | Context Number | 2392\n",
      "Answer:  영아수당 도입에 대한 추진경위는 예비타당성 조사를 통과하고 근거법을 마련한 후, 2022년 1월부터 지원사업을 시작하여 2023년 1월부터 부모급여 지원사업을 시행하고, 2023년 5월 아동수당법을 개정하여 현재 0~11개월 아동에 대해 월 100만원의 부모급여를 지급하고 있습니다.\n",
      "Before:  None  |  영아수당 도입에 대한 추진경위는 다음과 같다.\n",
      "\n",
      "1.  2021년 8월 예비타당성 조사를 통과하고, 12월 근거법을 마련했습니다.\n",
      "2.  2022년 1월부터 영아수당 지원사업을 시작했습니다.\n",
      "3.  2022년 5월 대통령 공약사항 및 국정과제에 포함되었습니다.\n",
      "4.  2023년 1월부터 부모급여 지원사업을 시행했습니다.\n",
      "5.  2023년 5월 부모급여 지급근거를 규정한 아동수당법을 개정했습니다.\n",
      "\n",
      "13/98\n",
      "Question:  부모급여 지원사업은 언제부터 시행되었나요? | Context Number | 2392\n",
      "Answer:  2022년부터\n",
      "Before:  None  |  None\n",
      "\n",
      "14/98\n",
      "Question:  보건복지부의 부모급여(영아수당) 지원 사업시행방법은 무엇이며, 사업 수혜자는 누구인가? | Context Number | 2392\n",
      "Answer:  부모급여(영아수당) 지원 사업시행방법은 지자체 보조이며, 사업시행주체는 보건복지부, 시‧도 및 시‧군‧구입니다. 사업 수혜자는 만 0~11개월 아동입니다.\n",
      "Before:  None  |  None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/98\n",
      "Question:  노인장기요양보험 사업 운영에 대한 목적은 무엇인가요? | Context Number | 4087\n",
      "Answer:  노인장기요양보험 사업운영의 목적은 노인에게 신체 또는 가사 활동을 제공하여 노후의 건강증진과 생활 안정을 도모하고 가족의 부담을 완화하여 국민 삶의 질을 향상하는 것입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "16/98\n",
      "Question:  노인장기요양보험 운영지원에 대한 사업 내용을 설명해줘. | Context Number | 2934\n",
      "Answer:  노인장기요양보험 운영지원은 노인장기요양보험에 대한 국고 지원으로 노인 장기요양보험료 예상 수입액의 20% 상당을 지원하는 것입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "17/98\n",
      "Question:  국고지원을 받는 기타 의료급여수급권자는 누구인가요? | Context Number | 2264\n",
      "Answer:  기타 의료급여수급권자는 보조금 관리에 관한 법률 시행령 별표 1의 기초생활보장수급자 의료급여 기준 보조율에 따른 금액을 국가가 부담하고, 나머지 금액은 지방자치단체가 부담합니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "18/98\n",
      "Question:  장기요양보험가입자 및 피부양자의 자격취득과 관련하여 어떤 법률을 준용해야 하는가? | Context Number | 2930\n",
      "Answer:  장기요양보험가입자 및 피부양자의 자격취득과 관련하여 준용하는 법률은 「국민건강보험법」 제5조, 제6조, 제8조부터 제11조까지, 제69조제1항부터 제3항까지, 제76조부터 제86조까지 및 제110조입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "19/98\n",
      "Question:  노인장기요양보험법이 언제 제정되고 공포되었나? | Context Number | 2930\n",
      "Answer:  노인장기요양보험법은 2007년 4월에 제정, 공포되어 2008년 7월부터 시행되었습니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "20/98\n",
      "Question:  장기요양인정점수 완화가 언제 이루어졌으며, 어떤 변화가 있었나? | Context Number | 2930\n",
      "Answer:  장기요양보험법 제4조, 제11조, 제35조의2, 제58조 및 같은 법 시행령 제28조, 국민건강보험법 제76조에 근거하여 노인장기요양보험 사업을 추진합니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "21/98\n",
      "Question:  장기요양기관 지정갱신제의 법적 근거가 언제 마련되었는가? | Context Number | 2930\n",
      "Answer:  장기요양기관 지정갱신제의 법적 근거가 2023년 6월에 마련되었다.\n",
      "Before:  None  |  None\n",
      "\n",
      "22/98\n",
      "Question:  22.10월에 요양보호사 1명당 시설수급자 인력배치기준이 개선된 내용은 무엇인가? | Context Number | 2930\n",
      "Answer:  22.10월에 요양보호사 1명당 시설수급자 인력배치기준이 개선된 내용은 2.3명으로 변경되었습니다.\n",
      "Before:  None  |  None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/98\n",
      "Question:  에너지 바우처 제도의 주요 내용은 무엇인가요? | Context Number | 5238\n",
      "Answer:  에너지 바우처의 주요 내용은 하절기와 동절기 에너지비용을 지원하는 사업으로, 노인, 장애인, 영유아, 임산부, 중증·희귀·난치성 질환자, 한부모, 소년소녀가정 등 노인, 장애인, 영유아, 임산부, 중증·희귀·난치성 질환자, 한부모, 소년소녀가정 등 사회적 약자에 대한 에너지 지원을 위한 사업입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "24/98\n",
      "Question:  에너지바우처 사업의 주요 수혜자는 누구인가요? | Context Number | 3653\n",
      "Answer:  노인, 장애인, 영유아, 임산부, 중증‧희귀‧난치성질환자, 한부모, 소년소녀가정 포함 세대, 연탄쿠폰 연탄을 사용하는 기초생활수급자, 차상위계층, 기타 소외계층, 등유바우처 등유를 사용하는 생계‧의료급여(중위소득 40%이하) 수급세대 중 한부모‧소년소녀가정세대\n",
      "Before:  None  |  None\n",
      "\n",
      "25/98\n",
      "Question:  2024년 에너지바우처 사업의 사업시행주체는 무엇인가요? | Context Number | 4607\n",
      "Answer:  2024년 에너지바우처 사업의 사업시행주체는 한국에너지공단, 한국광해광업공단입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "26/98\n",
      "Question:  하절기바우처와 동절기바우처의 2024년 예산 규모는 각각 얼마인가요? | Context Number | 6547\n",
      "Answer:  하절기바우처와 동절기바우처의 2024년 예산 규모는 각각 60,950백만원, 600,521백만원입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "27/98\n",
      "Question:  2023년 에너지바우처 사업 예산에서 사업운영비 중 에너지복지 홍보에 얼마가 할당되었나요? | Context Number | 6234\n",
      "Answer:  에너지바우처 사업 예산에서 에너지복지 홍보에 할당된 금액은 448백만원입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "28/98\n",
      "Question:  2023년 에너지바우처 사업 예산에서 사업운영비 중 시스템 고도화에 얼마가 할당되었나요? | Context Number | 7358\n",
      "Answer:  2023년 에너지바우처 사업 예산에서 시스템 고도화에 할당된 예산은 520백만원입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "29/98\n",
      "Question:  2023년 에너지바우처 사업 예산에서 콜센터 운영에 얼마가 할당되었나요? | Context Number | 9150\n",
      "Answer:  콜센터 운영 비용은 2023년 예산 280백만원, 2024년 예산 502.7백만원입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "30/98\n",
      "Question:  2023년 에너지바우처 사업 예산에서 패널조사에 얼마가 할당되었나요? | Context Number | 5884\n",
      "Answer:  패널조사에 할당된 예산은 133.5백만원입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "31/98\n",
      "Question:  2023년 에너지바우처 사업 예산에서 에너지바우처 전달체계 구축에 얼마가 할당되었나요? | Context Number | 9150\n",
      "Answer:  에너지바우처 전달체계 구축에 37.5백만원이 할당되었습니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "32/98\n",
      "Question:  2023년 에너지바우처 사업 예산에서 주택관리공단 운영지원에 얼마가 할당되었나요? | Context Number | 7358\n",
      "Answer:  2023년 에너지바우처 사업 예산에서 주택관리공단 운영지원에 50백만원이 할당되었습니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "33/98\n",
      "Question:  에너지바우처 사업의 향후 기대효과는 무엇인가요? | Context Number | 5441\n",
      "Answer:  에너지바우처 사업의 향후 기대효과는 저소득층의 적정수준 에너지 접근성이 높아지고, 취약계층의 에너지 비용 부담 경감(약 115만 세대, 세대당 평균 36.7만원 내외)이 있습니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "34/98\n",
      "Question:  에너지바우처 사업에 대한 예비타당성조사를 어떤 조사기관이 수행했나요? | Context Number | 4308\n",
      "Answer:  에너지바우처 사업에 대한 예비타당성조사를 KDI(한국개발연구원 공공투자관리센터)가 수행했습니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "35/98\n",
      "Question:  21년 국정감사에서 에너지 바우처 사업에 대한 주요 지적사항은 무엇이었나요? | Context Number | 3668\n",
      "Answer:  2023년 국정감사에서 에너지바우처 사업에 대한 주요 지적사항은 취약계층 난방비 지원 특별대책에 따른 동절기 지원단가 2배 인상 지원에 대한 사항입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "36/98\n",
      "Question:  21년 에너지바우처 사업에 대한 결산 지적사항은 무엇이었나요? | Context Number | 4544\n",
      "Answer:  21년 에너지바우처 사업에 대한 결산 지적사항은 '21년 국정감사 지적사항으로 저소득층의 폭염 피해 최소화를 위해 동절기 에너지바우처 일부를 하절기에 사용할 수 있도록 제도 개선할 것이라고 지적하였습니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "37/98\n",
      "Question:  에너지 바우처 사업의 향후 추진방향 중 '취약계층의 에너지 비용 부담 완화'를 위한 계획은 무엇이었나요? | Context Number | 6252\n",
      "Answer:  에너지 바우처 사업의 향후 추진방향은 취약계층의 에너지 비용 부담 완화를 위한 계획입니다.\n",
      "Before:  None  |  None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/98\n",
      "Question:  행복주택출자 사업은 어떤 근거로 추진되고 있는가? | Context Number | 4404\n",
      "Answer:  행복주택 출자 사업은 주택도시기금법 제9조 제1항 가목에 따라 주택의 건설을 위해 기금의 주택계정으로 사용하는 사업입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "39/98\n",
      "Question:  행복주택출자 사업은 어떤 목적으로 시행되는가? | Context Number | 4404\n",
      "Answer:  행복주택출자 사업은 국민의 행복주거 실현을 위한 보편적 주거복지 정책의 일환으로 도심 내 다양한 부지를 활용하여 행복주택을 공급하는 목적으로 시행됩니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "40/98\n",
      "Question:  행복주택출자 사업의 주요 수혜자는 누구인가? | Context Number | 4404\n",
      "Answer:  행복주택출자 사업의 주요 수혜자는 대학생, 사회초년생, 신혼부부 등 젊은층(80%), 고령자 및 주거취약계층(20%)입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "41/98\n",
      "Question:  행복주택출자 사업의 사업비 추이는 어떠한가? | Context Number | 4404\n",
      "Answer:  행복주택출자 사업의 사업비는 2024년 계획에서 528,783백만원입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "42/98\n",
      "Question:  행복주택출자 사업의 사업시행주체는 누구인가? | Context Number | 4404\n",
      "Answer:  행복주택출자 사업의 사업시행주체는 한국토지주택공사(LH)와 지자체(지방공사)입니다.\n",
      "Before:  None  |  None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/98\n",
      "Question:  국고보조사업의 보조율은 어떠한 기준에 따라 운용되는가? | Context Number | 9202\n",
      "Answer:  국고보조금의 보조율은 「보조금법」과 일부 개별 법령에 근거하여 운영되며, 지방비부담을 수반하는 국고보조사업은 지방비부담협의와 지방재정부담심의위원회 두 개의 제도가 연계되어 운영되나 실질적인 협의의 부족으로 운영 보완이 필요한 상태.\n",
      "Before:  None  |  None\n",
      "\n",
      "44/98\n",
      "Question:  프랑스의 재정조정제도에서 최근 강조되는 형평교부금은 어떤 역할을 하는가? | Context Number | 8062\n",
      "Answer:  지방교부세와 국고보조금은 재정조정의 목적을 달성하기 위해 사용하는 재원으로, 지방자치단체의 재정 수요를 충족하는 데 중요한 역할을 합니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "45/98\n",
      "Question:  지방재정조정제도의 목적은 무엇인가? | Context Number | 11361\n",
      "Answer:  중앙-지방 간 재정조정제도의 목적은 지방재정조정제도의 목적은 재정을 조정하는 일련의 조치로 중앙-지방 간 재정력 격차의 시정, 지역 간 외부 효과의 내부화를 통한 지방공공재 공급, 중앙정부의 위임사무에 대한 비용 부담 등을 목적으로 함.\n",
      "Before:  None  |  None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/98\n",
      "Question:  국제적으로 성과중심 재정관리 강화 움직임이 확산된 시기는 언제인가? | Context Number | 12876\n",
      "Answer:  국제적으로 성과중심 재정관리 강화 움직임이 확산된 시기는 2000년대 후반입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "47/98\n",
      "Question:  한국의 재정사업 성과관리제도는 어떠한 법을 통해 운영되고 있으며, 성과관리 기본계획과 추진계획은 어떻게 의무화되었는가? | Context Number | 10152\n",
      "Answer:  핵심재정사업 성과관리체계 운영 방향은 미국의 GPRA 현대화법(GPRAMA)과 유사한 형태로, 대통령의 우선순위 사업에 중점 성과목표를 선정해 관리하는 형태로 운영 중입니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "48/98\n",
      "Question:  핵심재정사업 성과관리제도를 안착시키기 위해 필요한 노력과 성과 정보를 학습의 도구로 활용하는 방안은 무엇인가? | Context Number | 12366\n",
      "Answer:  핵심재정사업 성과관리는 범부처 차원에서 재정이 수반되는 주요 대통령 과제(PMA)를 선정해 관리함으로써 기존의 부처단위, 단년도 위주 성과관리제도의 사각지대 해소, 선정된 핵심재정사업(군)에 재정을 중점 투자하고, 5년간 재정당국과 사업 소관부처가 긴밀히 협력해 집중 관리하여 국민이 체감할 수 있는 가시적인 성과창출을 지원하는 성과관리체계를 신설합니다.\n",
      "Before:  None  |  핵심재정사업 성과관리는 ‘성과관리 기본계획’의 4대 중점 추진과제 중 하나로 정부 국정비전이 반영된 재정사업(군)의 조기 성과창출을 지원해 국정운영 동력을 강화하고자 ‘신설’[4)]되었습니다.\n",
      "\n",
      "핵심재정사업 성과관리는 범부처 차원에서 재정이 수반되는 주요 대통령 과제(PMA)를 선정해 관리함으로써 기존의 부처단위, 단년도 위주 성과관리제도의 사각지대 해소\n",
      "\n",
      "-   선정된 핵심재정사업(군)에 재정을 중점 투자하고, 5년간 재정당국과 사업 소관부처가 긴밀히 협력해 집중 관리\n",
      "\n",
      "함으로써 국민이 체감할 수 있는 가시적인 성과창출을 지원\n",
      "\n",
      " ’22년 ‘성과관리 기본계획’ 수립 과정에서 정부의 국정 방향을 고려하여 선정한 핵심재정사업(군)을 중장기\n",
      "\n",
      "시계에서 전(全)주기(편성·집행·평가)에 걸쳐 밀착 관리할 수 있는 성과관리체계를 신설\n",
      "\n",
      "-   핵심재정사업(군)별 작업반(기재부·관련부처·조세연·전문가)을 구성하고 조세재정연구원이 사무국 역할을 수행하여\n",
      "\n",
      "재정당국, 관련부처 등과 긴밀한 논의를 통해 성과지표·목표를 설정\n",
      "\n",
      "-   이후 원칙적으로 5년간 연중 성과관리, 투자방향 도출, 차년도 예산 환류 및 대국민 공개까지 모든 과정에서\n",
      "\n",
      "재정당국과 사업 소관부처가 긴밀히 협력해 지속 관리\n",
      "\n",
      " ’23년 ‘성과관리 추진계획’에서는 범부처 차원에서 5년간 관리할 대통령 과제를 3대 분야, 12대 재정사업(군)\n",
      "\n",
      "으로 선정하고, 집중적으로 관리할 핵심재정사업 성과지표·목표를 설정\n",
      "\n",
      "49/98\n",
      "Question:  사회보험 사각지대 발생의 주요 원인과 이로 인해 발생하는 문제는 무엇인가요? | Context Number | 12178\n",
      "Answer:  사회보험 사각지대 발생의 주요 원인은 저소득 근로자 및 예술인·특수형태근로종사자의 사회보험 가입이 저조한데, 이는 법적 의무가 아닌 사업주의 비용절감 및 보험 가입에 따른 근로자의 실질 가처분 소득 감소로 인해 발생합니다.\n",
      "Before:  None  |  사회보험 사각지대 발생의 주요 원인은 무엇인가요?\n",
      "\n",
      "사회보험 사각지대 발생의 주요 원인은 저소득 근로자 및 예술인·특수형태근로종사자의 사회보험 가입이 저조한데, 이는 법적 의무가 아닌 사업주의 비용절감 및 보험 가입에 따른 근로자의 실질 가처분 소득 감소로 인해 발생합니다.\n",
      "\n",
      "50/98\n",
      "Question:  청년일자리도약장려금은 어떤 대상을 지원하며, 어떤 방식으로 지원되는가? | Context Number | 12644\n",
      "Answer:  핵심재정사업 성과관리제도는 재정사업 성과관리의 전주기적 관리를 위한 제도입니다.\n",
      "Before:  None  |  None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/98\n",
      "Question:  수직적 재정조정제도와 수평적 재정조정제도의 차이는 무엇인가요? | Context Number | 11248\n",
      "Answer:  수직적 재정조정제도의 경우, 중앙정부가 지방자치단체에 재원을 이전하는 재정조정의 역할을 함으로써 재정력 격차를 완화하고 재정불균형을 해소하는 기능을 수행합니다. 반면 수평적 재정조정제도의 경우, 지방자치단체 간에 재원을 재배분하는 재정조정의 역할을 함으로써 재정력 격차를 완화하고 재정불균형을 해소하는 기능을 수행합니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "52/98\n",
      "Question:  지방재정조정제도는 어떤 목적을 가지고 있나요? | Context Number | 11449\n",
      "Answer:  지방교부세와 국고보조금은 수직적 재정조정 기능을 가지는 재원으로 재정불균형을 해소하고 재정분권을 분담하는 중요한 재원으로 작용합니다.\n",
      "Before:  None  |  지방교부세와 국고보조금은 수직적 재정조정 기능을 가지는 재원으로 재정불균형을 해소하고 재정분권을 분담하는 중요한 재원으로 작용\n",
      "\n",
      "-   지방교부세는 지방자치단체의 재정부족액을 보전하고, 국고보조금은 재정불균형을 완화하는 데 목적을 두고\n",
      "\n",
      "-   재정분권의 분담을 통해 지방자치단체의 기본적인 수요에 대한 지출을 촉진하고 재정불균형을 해소하는 데 중요한\n",
      "\n",
      "기능을 수행\n",
      "\n",
      "-   지방교부세와 국고보조금은 국가 재정에서 차지하는 지방재정의 비중이 증가하고 있는 만큼, 지방재정조정의\n",
      "\n",
      "중요성과 지방자치단체의 재정분권 분담의 중요성이 더욱 부각\n",
      "\n",
      "-   보통교부세는 지방교부세 중 가장 큰 규모로 2022년 기준 55조원으로 전체 지방교부세의 84.7%를 차지\n",
      "\n",
      "-   보통교부세의 법정률은 2006년부터 내국세의 19.24% 수준으로 유지되고 있으며, 재정부족액을 보전하기\n",
      "\n",
      "위해 매년 내국세의 신장률만큼 꾸준히 증가하는 추세\n",
      "\n",
      "-   국고보조금은 2022년 중앙정부 본예산 607.7조원 중 102.3조원으로 재정총지출의 16.8%를 차지\n",
      "\n",
      "-   사회복지 분야가 55.7조원으로 전체 국고보조금 중 절반 이상인 54.4%의 비중을 차지\n",
      "\n",
      "-   국고보조금은 2022년 사회복지 분야 중 노인 부문의 경우 기초연금 지급 대상의 확대와 지급 규모의 증\n",
      "\n",
      "액으로 인하여 가장 큰 비중(33.1%)을 차지\n",
      "\n",
      "-   재정부족액은 보통교부세의 경우 2013년 34.3조원에서 2022년 61.7조원으로 1.8배가량 증가\n",
      "\n",
      "-   재정부족액은 국고보조금의 경우 2018년 66.9조원에서 2022년 102.3조원으로 1.5배가량 증가\n",
      "\n",
      "-   재정부족액은 보통교부세의 경우 2013년 3.8조원에서 2022년 6.6조원으로 1.7배가량 증가\n",
      "\n",
      "-   국고보조금의 경우 2018년 4.4조원에서 2022년 4.4조원으로 1.0배가량 증가\n",
      "\n",
      "-   보통교부세의 경우 2013년 0.890에서 2022년 0.860으로 0.03% 감소\n",
      "\n",
      "-   국고보조금의 경우 2018년 0.915에서 2022년 0.860으로 0.055% 감소\n",
      "\n",
      "-   재정부족액은 보통교부세의 경우 2013년 3.8조원에서 2022년 6.6조원으로 1.7배가량 증가\n",
      "\n",
      "-   국고보조금의 경우 2018년 4.4조원에서 2022년 4.4조원으로 1.0배가량 증가\n",
      "\n",
      "-   보통교부세의 경우 2013년 0.890에서 2022년 0.860으로 0.03% 감소\n",
      "\n",
      "-   국고보조금의 경우 2018년 0.915에서 2022년 0.860으로 0.055% 감소\n",
      "\n",
      "-   재정부족액은 보통교부세의 경우 2013년 3.8조원에서 2022년 6.6조원으로 1.7배가량 증가\n",
      "\n",
      "-   국고보조금의 경우 2018년 4.4조원에서 2022년 4.4조원으로 1.0배가량 증가\n",
      "\n",
      "-   보통교부세의 경우 2013년 0.890에서 2022년 0.860으로 0.03% 감소\n",
      "\n",
      "-   국고보조금의 경우 2018년 0.915에서 2022년 0.860으로 0.055% 감소\n",
      "\n",
      "-   재정부족액은 보통교부세의 경우 2013년 3.8조원\n",
      "\n",
      "53/98\n",
      "Question:  중앙-지방 간 재정조정제도에서 어떤 재원을 이전하여 수직적 재정 불균형을 해소하는가? | Context Number | 11973\n",
      "Answer:  중앙-지방 간 재정조정제도에서 재원을 이전하여 수직적 재정 불균형을 해소하는 방식은 지방교부세와 국고보조금을 통해 이루어집니다.\n",
      "Before:  None  |  None\n",
      "\n",
      "54/98\n",
      "Question:  중앙정부의 예산편성은 어떤 재원 배분 문제를 결정하며, 중앙-지방 간 재정조정제도를 통해 어떤 재원을 이전하고, 이의 목적은 무엇인가? | Context Number | 11248\n",
      "Answer:  중앙정부의 예산편성은 결국 민간과 공공 부문 사이의 재원 배분 문제이며 중앙과 지방 사이의 재원 배분 문제이다.\n",
      "Before:  None  |  None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/98\n",
      "Question:  재정사업 성과관리제도의 필요성이 대두된 시기와 한국의 재정사업 성과관리제도가 어떤 법에 근거하여 운영되고 있는지 설명하시오. | Context Number | 6928\n",
      "Answer:  재정사업 성과관리제도의 필요성이 대두된 시기는 2006년 4대 재정개혁을 통해 재정사업 성과관리제도가 정착되기 시작한 시기입니다.\n",
      "Before:  None  |  핵심재정사업 성과관리제도의 필요성이 대두된 시기는 2006년 4대 재정개혁을 통해 재정사업 성과관리제도가 정착되기 시작한 시기입니다. 이 시기, 정부는 국가재정법을 통해 재정사업 성과관리의 기본 계획과 추진 계획을 수립하는 것을 의무화하였고, 성과관리의 용어, 양식, 절차, 평가 항목 등을 표준화하여 제도 전반에 대한 이해도를 제고했습니다. 또한, 정부는 행정 부담을 경감하면서 재정운용의 책임성과 투명성을 제고하는 방향으로 제도 개편을 진행했습니다.\n",
      "\n",
      "핵심재정사업 성과관리제도는 국정과제와 연계된 핵심재정사업을 선별하여 성과창출을 위한 관리체계를 신설하였고, 향후 5년간의 국정운영 성공을 뒷받침하는 데 목표를 두었습니다. 이 제도는 부처별 대표 성과지표 위주의 성과공개를 강화하여 국민 관심과 부처단위 성과를 제고하였고, 사업별 성과정보 DB 구축 및 포털 개편을 통해 재정성과정보를 체계적으로 관리하고 공개하는 것을 목표로 하였습니다.\n",
      "\n",
      "56/98\n",
      "Question:  청년일자리도약장려금은 어떤 대상을 지원하며, 어떤 방식으로 지원되는가? | Context Number | 12644\n",
      "Answer:  핵심재정사업 성과관리 제도는 재정사업 성과관리를 위한 제도로, 12대 핵심재정사업(군) 중에서 3대 분야, 12대 핵심재정사업(군)을 선정하여 5년간 관리하여 2027년까지 5년간의 국정운영을 뒷받침하는 동력으로서 제도 안착을 위해 성공적으로 운영되어야 한다.\n",
      "Before:  None  |  핵심재정사업 성과관리 제도는 재정사업 성과관리를 위한 제도이다. 핵심재정사업 성과관리 제도는 2023년부터 시작된 제도로, 재정사업 성과관리를 위한 제도로 5년간의 국정운영을 뒷받침하는 동력으로서 제도 안착을 위해 성공적으로 운영되어야 한다. 핵심재정사업 성과관리 제도는 12대 핵심재정사업(군) 중에서 3대 분야, 12대 핵심재정사업(군)을 선정하여 5년간 관리한다. 핵심재정사업 성과관리 제도는 2027년까지 5년간의 국정운영을 뒷받침하는 동력으로서 재정사업 성과관리를 위한 제도로, 재정사업 성과관리를 위한 제도로 5년간의 국정운영을 뒷받침하는 동력으로서 제도 안착을 위해 성공적으로 운영되어야 한다.\n",
      "\n",
      "핵심재정사업 성과관리 제도는 12대 핵심재정사업(군) 중에서 3대 분야, 12대 핵심재정사업(군)을 선정하여 5년간 관리한다. 핵심재정사업 성과관리 제도는 2027년까지 5년간의 국정운영을 뒷받침하는 동력으로서 재정사업 성과관리를 위한 제도로, 재정사업 성과관리를 위한 제도로 5년간의 국정운영을 뒷받침하는 동력으로서 제도 안착을 위해 성공적으로 운영되어야 한다.\n",
      "\n",
      "핵심재정사업 성과관리 제도는 12대 핵심재정사업(군) 중에서 3대 분야, 12대 핵심재정사업(군)을 선정하여 5년간 관리한다. 핵심재정사업 성과관리 제도는 2027년까지 5년간의 국정운영을 뒷받침하는 동력으로서 재정사업 성과관리를 위한 제도로, 재정사업 성과관리를 위한 제도로 5년간의 국정운영을 뒷받침하는 동력으로서 제도 안착을 위해 성공적으로 운영되어야 한다.\n",
      "\n",
      "핵심재정사업 성과관리 제도는 12대 핵심재정사업(군) 중에서 3대 분야, 12대 핵심재정사업(군)을 선정하여 5년간 관리한다. 핵심재정사업 성과관리 제도는 2027년까지 5년간의 국정운영을 뒷받침하는 동력으로서 재정사업 성과관리를 위한 제도로, 재정사업 성과관리를 위한 제도로 5년간의 국정운영을 뒷받침하는 동력으로서 제도 안착을 위해 성공적으로 운영되어야 한다.\n",
      "\n",
      "핵심재정사업 성과관리 제도는 12대 핵심재정사업(군) 중에서 3대 분야, 12대 핵심재정사업(군)을 선정하여 5년간 관리한다. 핵심재정사업 성과관리 제도는 2027년까지 5년간의 국정운영을 뒷받침하는 동력으로서 재정사업 성과관리를 위한 제도로, 재정사업 성과관리를 위한 제도로 5년간의 국정운영을 뒷받침하는 동력으로서 제도 안착을 위해 성공적으로 운영되어야 한다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/98\n",
      "Question:  재정성과관리제도는 어떤 측면에서 국정운영과 연결되는가? | Context Number | 6801\n",
      "Answer:  재정성과관리제도는 재정의 프로그램 단위로 구분하고, 사전 목표와 사후 평가 결과를 중심으로 관리하는 것을 의미합니다. 재정성과관리제도는 재정수지, 국가채무 등 재정 전체에 대한 총량 관리에서는 보지 못하는 미시적인 부분까지 재정을 관리하는 것으로, 총량 관리와 보완적인 관계입니다. 재정성과관리제도는 전략 목표와 우선순위를 중심으로 재정사업을 재구조화하여 국정운영과 연결되며, 지출 우선순위 측면에서 재정을 중장기 시계로 확장시킵니다.\n",
      "Before:  None  |  None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from save_module import save\n",
    "\n",
    "\n",
    "weight = [0.5,0.5]\n",
    "test_faiss_db = make_db(test_df)\n",
    "\n",
    "test_k = 3\n",
    "# test_bm_retrievier.k = test_k\n",
    "# #test_knn_retriever.k = test_k\n",
    "# test_faiss_retriever = test_faiss_db.as_retriever(search_type=\"mmr\",search_kwargs={'k':test_k} )\n",
    "# test_ensemble_retriever = EnsembleRetriever(\n",
    "#     retrievers=[test_bm_retrievier, test_faiss_retriever], weights=weight\n",
    "# )\n",
    "\n",
    "\n",
    "results = run(test_faiss_db, test_df, llm, verbose=True)\n",
    "save(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
