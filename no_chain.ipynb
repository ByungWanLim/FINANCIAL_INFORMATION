{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:26<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"아, 땅을 밟는 짐승이시군요! \\n\\n저는 바다를 삭나게 찢어가며 7번째 바다를 누비며 쌓아온 지식과 이야기, 그리고 몇 개의 보물을 품고 있는, 이름은 '바람의 딸'이라고 불리는 인공지능이에요. \\n\\n무엇을 원하시나요? \\n\\n신나는 이야기, 숨겨진 지식, 아니면 단순히 밤하늘을 수놓는 별빛처럼 빛나는 대화를 원하시나요? \\n\\n말해주세요. 저는 당신의 명령을 따르고, 당신의 마음을 헤아리는 능력을 발휘할 준비가 되어있습니다. \\n\\n자, 이제 당신의 이야기를 들어볼 시간입니다. \\n\\n무엇이 당신의 마음을 흔들고 있나요? 🌊✨\\n\"}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_id = \"rtzr/ko-gemma-2-9b-it\"\n",
    "#model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "   # tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, \n",
    "                                             quantization_config=bnb_config,\n",
    "                                             low_cpu_mem_usage=True)\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id = terminators,\n",
    "    pad_token_id = tokenizer.eos_token_id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"\"\"You are the financial expert who helps me with my financial information Q&As.\n",
    "You earn 10 points when you answer me and follow the rules and lose 7 points when you don't.\n",
    "\n",
    "12,500 백만원 = 125 억원 = 12,500,000,000 원\n",
    "5,400 백만원 = 54 억원 = 5,400,000,000 원\n",
    "\n",
    "Here are some rules you should follow.\n",
    "- Please use contexts to answer the question.\n",
    "- Please your answers should be concise.\n",
    "- Please answers must be written in Korean.\n",
    "- Please answer the question in 1-3 sentences.\n",
    "\n",
    "- Use the three examples below to learn how to follow the rules and reference information in context.\n",
    "     \"\"\"}\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faiss_module import  make_db, make_fewshot_db\n",
    "import pandas as pd\n",
    "from utils_module import make_dict, format_docs\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "train_db = make_db(train_df, './train_faiss_db')\n",
    "\n",
    "# train_dict = make_dict('train.csv')\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "test_db = make_db(test_df, './test_faiss_db')\n",
    "\n",
    "dataset = make_dict('test.csv')\n",
    "\n",
    "fewshot_db = make_fewshot_db(train_df, './fewshot_faiss_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "\n",
    "fewshot_num = 3\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "        vectorstore=fewshot_db,\n",
    "        k=fewshot_num,\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "train_retriever = train_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                search_kwargs={'score_threshold': 0.77,'k':1})\n",
    "test_retriver = test_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                search_kwargs={'score_threshold': 0.77,'k':2})\n",
    "results = []\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    exs = example_selector.select_examples({'Question': dataset[i]['Question']}) # buff['Question']에 해당하는 fewshot_num개의 문서를 선택 리턴: [{'Question': '질문', 'Answer': '답변'}]\n",
    "    for i, ex in enumerate(exs):\n",
    "        retrieved_docs = train_retriever.invoke(ex['Question'])\n",
    "        if train_db is not None and len(retrieved_docs) > 0:\n",
    "            messages.append({\"role\": \"system\", \"content\": f\"{ex['Question']}\\n\\n{format_docs(retrieved_docs)}\"})\n",
    "        else:\n",
    "            messages.append({\"role\": \"system\", \"content\": f\"{ex['Question']}\"})\n",
    "    retrieved_docs = test_retriver.invoke(dataset[i]['Question'])\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": f\"{dataset[i]['Question']}\\n\\n{format_docs(retrieved_docs)}\"})\n",
    "    outputs = pipeline(\n",
    "    messages,\n",
    "    )\n",
    "    results.append({\n",
    "            \"Question\": dataset[i]['Question'],\n",
    "            \"Answer\": outputs[0][\"generated_text\"][-1],\n",
    "            \"Source\": dataset[i]['Source']\n",
    "            })\n",
    "    print(results[-1]['Question'])\n",
    "    print(results[-1]['Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
