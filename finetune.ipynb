{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "from faiss_module import make_db\n",
    "import pandas as pd\n",
    "def format_docs(docs):\n",
    "    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n",
    "    context = \"\"\n",
    "    # context = \"<|start_header_id|>system<|end_header_id|>\\nContext\\n\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        #context += f\"Document {i+1}\\n\"\n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    # context += \"<|eot_id|>\"\n",
    "    return context \n",
    "\n",
    "def format_docs_wnum(docs):\n",
    "    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n",
    "    context = \"\"\n",
    "    # context = \"<|start_header_id|>system<|end_header_id|>\\nContext\\n\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        context += f\"Document {i+1}\\n\"\n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    # context += \"<|eot_id|>\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파인튜닝 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS DB from: ./train_faiss_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_db = make_db(train_df,'./train_faiss_db')\n",
    "answer_list = []\n",
    "context_list = []\n",
    "context_list_wnum = []\n",
    "for i, entry in enumerate(train_df.to_dict(orient='records')):\n",
    "    question = entry['Question']\n",
    "    answer = entry['Answer']+\"<|eot_id|>\"\n",
    "    # print(question)\n",
    "    # print(answer)\n",
    "    train_retriever = train_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                search_kwargs={'filter': {'source':entry['Source_path']},'score_threshold': 0.76,'k':3})\n",
    "    docs = train_retriever.invoke(question)\n",
    "    if len(docs) == 0:\n",
    "        context_list.append(\"None\")\n",
    "        context_list_wnum.append(\"None\")\n",
    "    else:\n",
    "        #print(format_docs(docs))\n",
    "        context_list.append(format_docs(docs))\n",
    "        context_list_wnum.append(format_docs_wnum(docs))\n",
    "    answer_list.append(answer)\n",
    "    \n",
    "train_df['Answer'] = answer_list\n",
    "train_df['context'] = context_list\n",
    "train_df['context_wnum'] = context_list_wnum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 생성\n",
    "def create_prompt(row):\n",
    "    context = row['context']\n",
    "    question = row['Question']\n",
    "    prompt  =f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "You are a Korean Q&A Assistant.<|eot_id|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "{context}\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{question}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "train_df['prompt'] = train_df.apply(create_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Source_path</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>context</th>\n",
       "      <th>context_wnum</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>2024년 중앙정부 재정체계는 어떻게 구성되어 있나요?</td>\n",
       "      <td>2024년 중앙정부 재정체계는 예산(일반·특별회계)과 기금으로 구분되며, 2024년...</td>\n",
       "      <td>주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는 예산(일반 ･특별회계...</td>\n",
       "      <td>Document 1\\n주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>2024년 중앙정부의 예산 지출은 어떻게 구성되어 있나요?</td>\n",
       "      <td>2024년 중앙정부의 예산 지출은 일반회계 356.5조원, 21개 특별회계 81.7...</td>\n",
       "      <td>주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는 예산(일반 ･특별회계...</td>\n",
       "      <td>Document 1\\n주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>기금이 예산과 다른 점은?</td>\n",
       "      <td>기금은 예산과 구분되는 재정수단으로서 재정운영의 신축성을 기할 필요가 있을 때, 정...</td>\n",
       "      <td>일반회계와 특별회계로 구분\\n∙기금은 예산과 구분되는 재정수단으로서 재정운영의 신축...</td>\n",
       "      <td>Document 1\\n일반회계와 특별회계로 구분\\n∙기금은 예산과 구분되는 재정수단...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>일반회계, 특별회계, 기금 간의 차이점은 무엇인가요?</td>\n",
       "      <td>일반회계는 특정 사업 운영 및 특정 세입으로 특정 세출을 충당하는데 사용되고, 특별...</td>\n",
       "      <td>일반회계와 특별회계로 구분\\n∙기금은 예산과 구분되는 재정수단으로서 재정운영의 신축...</td>\n",
       "      <td>Document 1\\n일반회계와 특별회계로 구분\\n∙기금은 예산과 구분되는 재정수단...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>2024년 총수입은 얼마이며, 예산수입과 기금수입은 각각 몇 조원인가요?</td>\n",
       "      <td>2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216...</td>\n",
       "      <td>∙2023년 예산(625.7조원) 대비 2024년 예산(612.2조원) 2.2% 감...</td>\n",
       "      <td>Document 1\\n∙2023년 예산(625.7조원) 대비 2024년 예산(612...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SAMPLE_ID               Source                             Source_path  \\\n",
       "0  TRAIN_000  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "1  TRAIN_001  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "2  TRAIN_002  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "3  TRAIN_003  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "4  TRAIN_004  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "\n",
       "                                   Question  \\\n",
       "0            2024년 중앙정부 재정체계는 어떻게 구성되어 있나요?   \n",
       "1          2024년 중앙정부의 예산 지출은 어떻게 구성되어 있나요?   \n",
       "2                            기금이 예산과 다른 점은?   \n",
       "3             일반회계, 특별회계, 기금 간의 차이점은 무엇인가요?   \n",
       "4  2024년 총수입은 얼마이며, 예산수입과 기금수입은 각각 몇 조원인가요?   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  2024년 중앙정부 재정체계는 예산(일반·특별회계)과 기금으로 구분되며, 2024년...   \n",
       "1  2024년 중앙정부의 예산 지출은 일반회계 356.5조원, 21개 특별회계 81.7...   \n",
       "2  기금은 예산과 구분되는 재정수단으로서 재정운영의 신축성을 기할 필요가 있을 때, 정...   \n",
       "3  일반회계는 특정 사업 운영 및 특정 세입으로 특정 세출을 충당하는데 사용되고, 특별...   \n",
       "4  2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216...   \n",
       "\n",
       "                                             context  \\\n",
       "0  주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는 예산(일반 ･특별회계...   \n",
       "1  주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는 예산(일반 ･특별회계...   \n",
       "2  일반회계와 특별회계로 구분\\n∙기금은 예산과 구분되는 재정수단으로서 재정운영의 신축...   \n",
       "3  일반회계와 특별회계로 구분\\n∙기금은 예산과 구분되는 재정수단으로서 재정운영의 신축...   \n",
       "4  ∙2023년 예산(625.7조원) 대비 2024년 예산(612.2조원) 2.2% 감...   \n",
       "\n",
       "                                        context_wnum  \\\n",
       "0  Document 1\\n주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는...   \n",
       "1  Document 1\\n주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는...   \n",
       "2  Document 1\\n일반회계와 특별회계로 구분\\n∙기금은 예산과 구분되는 재정수단...   \n",
       "3  Document 1\\n일반회계와 특별회계로 구분\\n∙기금은 예산과 구분되는 재정수단...   \n",
       "4  Document 1\\n∙2023년 예산(625.7조원) 대비 2024년 예산(612...   \n",
       "\n",
       "                                              prompt  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋을 학습셋과 검증셋으로 나누기\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=52)\n",
    "\n",
    "# train_df는 학습셋, val_df는 검증셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 허깅페이스 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# 양자화 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "#만약 GPU에서 amp(Automatic Mixed Precision)를 지원한다면, fp16 대신 bfloat16을 사용하는 것이 더욱 안정적일 수 있습니다.\n",
    "\n",
    "# 모델 로드 및 양자화 설정 적용\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# LoRA 어댑터 설정 추가\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    inference_mode=False, \n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1\n",
    ")\n",
    "# task_type: 적용할 작업의 유형(GPT 계열의 경우 CAUSAL_LM).\n",
    "# inference_mode: 학습 모드(False) 또는 추론 모드(True).\n",
    "# r: LoRA의 병목 차원.\n",
    "# lora_alpha: 스케일링 인자.\n",
    "# lora_dropout: 드롭아웃 확률.\n",
    "\n",
    "# 모델에 LoRA 어댑터 적용\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# 이후 Trainer를 사용해 파인튜닝을 진행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 396/396 [00:00<00:00, 5236.86 examples/s]\n",
      "Map: 100%|██████████| 396/396 [00:00<00:00, 10690.53 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 4642.95 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 8692.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from datasets import Dataset\n",
    "# 토크나이즈 함수 정의\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['prompt'], padding='max_length', truncation=True, max_length=512)\n",
    "# 모델의 정답 라벨 설정\n",
    "def add_labels(examples):\n",
    "    labels = tokenizer(examples['Answer'], padding='max_length', truncation=True, max_length=512).input_ids\n",
    "    examples['labels'] = labels\n",
    "    return examples\n",
    "\n",
    "\n",
    "# 예시로, 기존 데이터셋 생성\n",
    "train_dataset = Dataset.from_pandas(train_df[['prompt', 'Answer']])\n",
    "val_dataset = Dataset.from_pandas(val_df[['prompt', 'Answer']])\n",
    "\n",
    "# 토크나이징과 라벨 추가는 동일하게 적용\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "train_dataset = train_dataset.map(add_labels, batched=True)\n",
    "\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(add_labels, batched=True)\n",
    "\n",
    "# DistributedSampler 생성\n",
    "train_sampler = DistributedSampler(train_dataset)\n",
    "val_sampler = DistributedSampler(val_dataset)\n",
    "\n",
    "# DataLoader에 샘플러 적용\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=1)\n",
    "val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "# F1 점수를 계산하는 함수\n",
    "def calculate_f1_score(true_sentence, predicted_sentence, sum_mode=True):\n",
    "    true_sentence = ''.join(true_sentence.split())\n",
    "    predicted_sentence = ''.join(predicted_sentence.split())\n",
    "    \n",
    "    true_counter = Counter(true_sentence)\n",
    "    predicted_counter = Counter(predicted_sentence)\n",
    "    \n",
    "    if sum_mode:\n",
    "        true_positive = sum((true_counter & predicted_counter).values())\n",
    "        predicted_positive = sum(predicted_counter.values())\n",
    "        actual_positive = sum(true_counter.values())\n",
    "    else:\n",
    "        true_positive = len((true_counter & predicted_counter).values())\n",
    "        predicted_positive = len(predicted_counter.values())\n",
    "        actual_positive = len(true_counter.values())\n",
    "\n",
    "    precision = true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    recall = true_positive / actual_positive if actual_positive > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "# compute_metrics 함수 정의\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    predicted_sentences = [tokenizer.decode(pred, skip_special_tokens=True) for pred in predictions]\n",
    "    true_sentences = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
    "    \n",
    "    f1_scores = [calculate_f1_score(true, pred)[2] for true, pred in zip(true_sentences, predicted_sentences)]\n",
    "    avg_f1_score = np.mean(f1_scores)\n",
    "    \n",
    "    return {\"f1\": avg_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 396/1188 [03:35<07:06,  1.86it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\accelerate\\utils\\operations.py:155\u001b[0m, in \u001b[0;36msend_to_device\u001b[1;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: BatchEncoding.to() got an unexpected keyword argument 'non_blocking'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     19\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 파인튜닝 실행\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\trainer.py:1948\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1946\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\trainer.py:2386\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2386\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m   2389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[0;32m   2390\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\trainer.py:2814\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2812\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[1;32m-> 2814\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m   2817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\trainer.py:2771\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[1;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[0;32m   2770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 2771\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2772\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2774\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\trainer.py:3676\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3673\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3675\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3676\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3677\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3679\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   3680\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   3681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3684\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3686\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   3687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\trainer.py:3857\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3854\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3856\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[1;32m-> 3857\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3858\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Update the observed num examples\u001b[39;49;00m\n\u001b[0;32m   3859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfind_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3860\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\accelerate\\data_loader.py:463\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\accelerate\\utils\\operations.py:157\u001b[0m, in \u001b[0;36msend_to_device\u001b[1;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# `torch.Tensor.to(<int num>)` is not supported by `torch_npu` (see this [issue](https://github.com/Ascend/pytorch/issues/16)).\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# This call is inside the try-block since is_npu_available is not supported by torch.compile.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_npu_available():\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:803\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m--> 803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    805\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# TrainingArguments 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                  # 결과를 저장할 디렉토리\n",
    "    evaluation_strategy=\"epoch\",             # 에포크마다 평가\n",
    "    per_device_train_batch_size=1,           # GPU 하나당 배치 크기 (DataLoader에서 설정한 것과 일치시킴)\n",
    "    per_device_eval_batch_size=1,            # GPU 하나당 평가 배치 크기 (DataLoader에서 설정한 것과 일치시킴)\n",
    "    num_train_epochs=3,                      # 학습할 에포크 수\n",
    "    learning_rate=5e-5,                      # 학습률\n",
    "    weight_decay=0.01,                       # 가중치 감소\n",
    "    fp16=True,                               # Mixed Precision 사용 (메모리 절약 및 학습 속도 증가)\n",
    "    dataloader_pin_memory=True,              # DataLoader가 메모리 핀 설정을 하도록 설정\n",
    "    dataloader_drop_last=False,              # 배치가 나누어 떨어지지 않을 경우 마지막 배치 드롭 여부\n",
    "    report_to=\"none\",                        # 로깅이나 기타 리포팅 도구를 사용하지 않음 (필요시 변경)\n",
    ")\n",
    "\n",
    "# Trainer 설정\n",
    "trainer = Trainer(\n",
    "    model=model,                             # 학습할 모델\n",
    "    args=training_args,                      # 위에서 설정한 TrainingArguments\n",
    "    train_dataloader=train_dataloader,       # 커스텀 DataLoader (DistributedSampler 사용)\n",
    "    eval_dataloader=val_dataloader,          # 커스텀 DataLoader (DistributedSampler 사용)\n",
    "    tokenizer=tokenizer,                     # 사용 중인 토크나이저\n",
    "    compute_metrics=compute_metrics          # 평가 메트릭 함수 (선택 사항)\n",
    ")\n",
    "\n",
    "# 학습 수행\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.save_pretrained(\"./saved_model\")\n",
    "tokenizer.save_pretrained(\"./saved_model\")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# 양자화된 모델과 LoRA 어댑터가 적용된 모델 로드\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./saved_model\", quantization_config=bnb_config)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./saved_model\", quantization_config=bnb_config)\n",
    "# model = PeftModel.from_pretrained(model, \"./saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
