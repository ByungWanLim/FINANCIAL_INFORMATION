{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "from faiss_module import make_db\n",
    "import pandas as pd\n",
    "def format_docs(docs):\n",
    "    \"\"\"ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…\"\"\"\n",
    "    context = \"\"\n",
    "    # context = \"<|start_header_id|>system<|end_header_id|>\\nContext\\n\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        #context += f\"Document {i+1}\\n\"\n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    # context += \"<|eot_id|>\"\n",
    "    return context \n",
    "\n",
    "def format_docs_wnum(docs):\n",
    "    \"\"\"ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…\"\"\"\n",
    "    context = \"\"\n",
    "    # context = \"<|start_header_id|>system<|end_header_id|>\\nContext\\n\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        context += f\"Document {i+1}\\n\"\n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    # context += \"<|eot_id|>\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## íŒŒì¸íŠœë‹ ë°ì´í„°ì…‹ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS DB from: ./train_faiss_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_db = make_db(train_df,'./train_faiss_db')\n",
    "answer_list = []\n",
    "context_list = []\n",
    "context_list_wnum = []\n",
    "for i, entry in enumerate(train_df.to_dict(orient='records')):\n",
    "    question = entry['Question']\n",
    "    answer = entry['Answer']+\"<|eot_id|>\"\n",
    "    # print(question)\n",
    "    # print(answer)\n",
    "    train_retriever = train_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                search_kwargs={'filter': {'source':entry['Source_path']},'score_threshold': 0.76,'k':3})\n",
    "    docs = train_retriever.invoke(question)\n",
    "    #print(format_docs(docs))\n",
    "    answer_list.append(answer)\n",
    "    context_list.append(format_docs(docs))\n",
    "    context_list_wnum.append(format_docs_wnum(docs))\n",
    "    \n",
    "train_df['Answer'] = answer_list\n",
    "train_df['context'] = context_list\n",
    "train_df['context_wnum'] = context_list_wnum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "def create_prompt(row):\n",
    "    context = row['context']\n",
    "    question = row['Question']\n",
    "    prompt  =f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "You are a Korean Q&A Assistant.<|eot_id|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "{context}\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{question}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "train_df['prompt'] = train_df.apply(create_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Source_path</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>context</th>\n",
       "      <th>context_wnum</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ</td>\n",
       "      <td>./train_source/1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ.pdf</td>\n",
       "      <td>2024ë…„ ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ” ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?</td>\n",
       "      <td>2024ë…„ ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ” ì˜ˆì‚°(ì¼ë°˜Â·íŠ¹ë³„íšŒê³„)ê³¼ ê¸°ê¸ˆìœ¼ë¡œ êµ¬ë¶„ë˜ë©°, 2024ë…„...</td>\n",
       "      <td>ì£¼ìš” ì¬ì •í†µê³„â—\\nâ… .\\n201ì¬ì •ì²´ê³„\\nâ–¸ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ” ì˜ˆì‚°(ì¼ë°˜ ï½¥íŠ¹ë³„íšŒê³„...</td>\n",
       "      <td>Document 1\\nì£¼ìš” ì¬ì •í†µê³„â—\\nâ… .\\n201ì¬ì •ì²´ê³„\\nâ–¸ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ”...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ</td>\n",
       "      <td>./train_source/1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ.pdf</td>\n",
       "      <td>2024ë…„ ì¤‘ì•™ì •ë¶€ì˜ ì˜ˆì‚° ì§€ì¶œì€ ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?</td>\n",
       "      <td>2024ë…„ ì¤‘ì•™ì •ë¶€ì˜ ì˜ˆì‚° ì§€ì¶œì€ ì¼ë°˜íšŒê³„ 356.5ì¡°ì›, 21ê°œ íŠ¹ë³„íšŒê³„ 81.7...</td>\n",
       "      <td>ì£¼ìš” ì¬ì •í†µê³„â—\\nâ… .\\n201ì¬ì •ì²´ê³„\\nâ–¸ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ” ì˜ˆì‚°(ì¼ë°˜ ï½¥íŠ¹ë³„íšŒê³„...</td>\n",
       "      <td>Document 1\\nì£¼ìš” ì¬ì •í†µê³„â—\\nâ… .\\n201ì¬ì •ì²´ê³„\\nâ–¸ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ”...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ</td>\n",
       "      <td>./train_source/1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ.pdf</td>\n",
       "      <td>ê¸°ê¸ˆì´ ì˜ˆì‚°ê³¼ ë‹¤ë¥¸ ì ì€?</td>\n",
       "      <td>ê¸°ê¸ˆì€ ì˜ˆì‚°ê³¼ êµ¬ë¶„ë˜ëŠ” ì¬ì •ìˆ˜ë‹¨ìœ¼ë¡œì„œ ì¬ì •ìš´ì˜ì˜ ì‹ ì¶•ì„±ì„ ê¸°í•  í•„ìš”ê°€ ìˆì„ ë•Œ, ì •...</td>\n",
       "      <td>âˆ™ìœµìì‚¬ì—… ë“± ê¸°ê¸ˆ ê³ ìœ ì‚¬ì—… ìˆ˜í–‰\\ní™•ì • ì ˆì°¨âˆ™ë¶€ì²˜ì˜ ì˜ˆì‚° ìš”êµ¬\\nâˆ™ê¸°íšì¬ì •ë¶€ì˜ ì •...</td>\n",
       "      <td>Document 1\\nâˆ™ìœµìì‚¬ì—… ë“± ê¸°ê¸ˆ ê³ ìœ ì‚¬ì—… ìˆ˜í–‰\\ní™•ì • ì ˆì°¨âˆ™ë¶€ì²˜ì˜ ì˜ˆì‚° ìš”...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ</td>\n",
       "      <td>./train_source/1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ.pdf</td>\n",
       "      <td>ì¼ë°˜íšŒê³„, íŠ¹ë³„íšŒê³„, ê¸°ê¸ˆ ê°„ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?</td>\n",
       "      <td>ì¼ë°˜íšŒê³„ëŠ” íŠ¹ì • ì‚¬ì—… ìš´ì˜ ë° íŠ¹ì • ì„¸ì…ìœ¼ë¡œ íŠ¹ì • ì„¸ì¶œì„ ì¶©ë‹¹í•˜ëŠ”ë° ì‚¬ìš©ë˜ê³ , íŠ¹ë³„...</td>\n",
       "      <td>íŠ¹ë³„íšŒê³„49.6 47.2 51.3 53.6 59.1 59.7 71.6 81.7\\n(...</td>\n",
       "      <td>Document 1\\níŠ¹ë³„íšŒê³„49.6 47.2 51.3 53.6 59.1 59.7 ...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ</td>\n",
       "      <td>./train_source/1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ.pdf</td>\n",
       "      <td>2024ë…„ ì´ìˆ˜ì…ì€ ì–¼ë§ˆì´ë©°, ì˜ˆì‚°ìˆ˜ì…ê³¼ ê¸°ê¸ˆìˆ˜ì…ì€ ê°ê° ëª‡ ì¡°ì›ì¸ê°€ìš”?</td>\n",
       "      <td>2024ë…„ ì´ìˆ˜ì…ì€ 612.2ì¡°ì›ì´ë©°, ì˜ˆì‚°ìˆ˜ì…ì€ 395.5ì¡°ì›, ê¸°ê¸ˆìˆ˜ì…ì€ 216...</td>\n",
       "      <td>ì£¼ìš” ì¬ì •í†µê³„â—\\nâ… .\\n402ì¬ì •ìˆ˜ì…\\nâ–¸2024ë…„ë„ ì´ìˆ˜ì…ì€ 612.2ì¡°ì›ì´ë©°,...</td>\n",
       "      <td>Document 1\\nì£¼ìš” ì¬ì •í†µê³„â—\\nâ… .\\n402ì¬ì •ìˆ˜ì…\\nâ–¸2024ë…„ë„ ì´ìˆ˜ì…...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SAMPLE_ID               Source                             Source_path  \\\n",
       "0  TRAIN_000  1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ  ./train_source/1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ.pdf   \n",
       "1  TRAIN_001  1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ  ./train_source/1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ.pdf   \n",
       "2  TRAIN_002  1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ  ./train_source/1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ.pdf   \n",
       "3  TRAIN_003  1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ  ./train_source/1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ.pdf   \n",
       "4  TRAIN_004  1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ  ./train_source/1-1 2024 ì£¼ìš” ì¬ì •í†µê³„ 1ê¶Œ.pdf   \n",
       "\n",
       "                                   Question  \\\n",
       "0            2024ë…„ ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ” ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?   \n",
       "1          2024ë…„ ì¤‘ì•™ì •ë¶€ì˜ ì˜ˆì‚° ì§€ì¶œì€ ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?   \n",
       "2                            ê¸°ê¸ˆì´ ì˜ˆì‚°ê³¼ ë‹¤ë¥¸ ì ì€?   \n",
       "3             ì¼ë°˜íšŒê³„, íŠ¹ë³„íšŒê³„, ê¸°ê¸ˆ ê°„ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?   \n",
       "4  2024ë…„ ì´ìˆ˜ì…ì€ ì–¼ë§ˆì´ë©°, ì˜ˆì‚°ìˆ˜ì…ê³¼ ê¸°ê¸ˆìˆ˜ì…ì€ ê°ê° ëª‡ ì¡°ì›ì¸ê°€ìš”?   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  2024ë…„ ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ” ì˜ˆì‚°(ì¼ë°˜Â·íŠ¹ë³„íšŒê³„)ê³¼ ê¸°ê¸ˆìœ¼ë¡œ êµ¬ë¶„ë˜ë©°, 2024ë…„...   \n",
       "1  2024ë…„ ì¤‘ì•™ì •ë¶€ì˜ ì˜ˆì‚° ì§€ì¶œì€ ì¼ë°˜íšŒê³„ 356.5ì¡°ì›, 21ê°œ íŠ¹ë³„íšŒê³„ 81.7...   \n",
       "2  ê¸°ê¸ˆì€ ì˜ˆì‚°ê³¼ êµ¬ë¶„ë˜ëŠ” ì¬ì •ìˆ˜ë‹¨ìœ¼ë¡œì„œ ì¬ì •ìš´ì˜ì˜ ì‹ ì¶•ì„±ì„ ê¸°í•  í•„ìš”ê°€ ìˆì„ ë•Œ, ì •...   \n",
       "3  ì¼ë°˜íšŒê³„ëŠ” íŠ¹ì • ì‚¬ì—… ìš´ì˜ ë° íŠ¹ì • ì„¸ì…ìœ¼ë¡œ íŠ¹ì • ì„¸ì¶œì„ ì¶©ë‹¹í•˜ëŠ”ë° ì‚¬ìš©ë˜ê³ , íŠ¹ë³„...   \n",
       "4  2024ë…„ ì´ìˆ˜ì…ì€ 612.2ì¡°ì›ì´ë©°, ì˜ˆì‚°ìˆ˜ì…ì€ 395.5ì¡°ì›, ê¸°ê¸ˆìˆ˜ì…ì€ 216...   \n",
       "\n",
       "                                             context  \\\n",
       "0  ì£¼ìš” ì¬ì •í†µê³„â—\\nâ… .\\n201ì¬ì •ì²´ê³„\\nâ–¸ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ” ì˜ˆì‚°(ì¼ë°˜ ï½¥íŠ¹ë³„íšŒê³„...   \n",
       "1  ì£¼ìš” ì¬ì •í†µê³„â—\\nâ… .\\n201ì¬ì •ì²´ê³„\\nâ–¸ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ” ì˜ˆì‚°(ì¼ë°˜ ï½¥íŠ¹ë³„íšŒê³„...   \n",
       "2  âˆ™ìœµìì‚¬ì—… ë“± ê¸°ê¸ˆ ê³ ìœ ì‚¬ì—… ìˆ˜í–‰\\ní™•ì • ì ˆì°¨âˆ™ë¶€ì²˜ì˜ ì˜ˆì‚° ìš”êµ¬\\nâˆ™ê¸°íšì¬ì •ë¶€ì˜ ì •...   \n",
       "3  íŠ¹ë³„íšŒê³„49.6 47.2 51.3 53.6 59.1 59.7 71.6 81.7\\n(...   \n",
       "4  ì£¼ìš” ì¬ì •í†µê³„â—\\nâ… .\\n402ì¬ì •ìˆ˜ì…\\nâ–¸2024ë…„ë„ ì´ìˆ˜ì…ì€ 612.2ì¡°ì›ì´ë©°,...   \n",
       "\n",
       "                                        context_wnum  \\\n",
       "0  Document 1\\nì£¼ìš” ì¬ì •í†µê³„â—\\nâ… .\\n201ì¬ì •ì²´ê³„\\nâ–¸ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ”...   \n",
       "1  Document 1\\nì£¼ìš” ì¬ì •í†µê³„â—\\nâ… .\\n201ì¬ì •ì²´ê³„\\nâ–¸ì¤‘ì•™ì •ë¶€ ì¬ì •ì²´ê³„ëŠ”...   \n",
       "2  Document 1\\nâˆ™ìœµìì‚¬ì—… ë“± ê¸°ê¸ˆ ê³ ìœ ì‚¬ì—… ìˆ˜í–‰\\ní™•ì • ì ˆì°¨âˆ™ë¶€ì²˜ì˜ ì˜ˆì‚° ìš”...   \n",
       "3  Document 1\\níŠ¹ë³„íšŒê³„49.6 47.2 51.3 53.6 59.1 59.7 ...   \n",
       "4  Document 1\\nì£¼ìš” ì¬ì •í†µê³„â—\\nâ… .\\n402ì¬ì •ìˆ˜ì…\\nâ–¸2024ë…„ë„ ì´ìˆ˜ì…...   \n",
       "\n",
       "                                              prompt  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ë°ì´í„°ì…‹ì„ í•™ìŠµì…‹ê³¼ ê²€ì¦ì…‹ìœ¼ë¡œ ë‚˜ëˆ„ê¸°\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=52)\n",
    "\n",
    "# train_dfëŠ” í•™ìŠµì…‹, val_dfëŠ” ê²€ì¦ì…‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í—ˆê¹…í˜ì´ìŠ¤ ë°ì´í„°ì…‹ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:21<00:00,  5.42s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# ì–‘ìí™” ì„¤ì •\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ ë° ì–‘ìí™” ì„¤ì • ì ìš©\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# LoRA ì–´ëŒ‘í„° ì„¤ì • ì¶”ê°€\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    inference_mode=False, \n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1\n",
    ")\n",
    "# task_type: ì ìš©í•  ì‘ì—…ì˜ ìœ í˜•(GPT ê³„ì—´ì˜ ê²½ìš° CAUSAL_LM).\n",
    "# inference_mode: í•™ìŠµ ëª¨ë“œ(False) ë˜ëŠ” ì¶”ë¡  ëª¨ë“œ(True).\n",
    "# r: LoRAì˜ ë³‘ëª© ì°¨ì›.\n",
    "# lora_alpha: ìŠ¤ì¼€ì¼ë§ ì¸ì.\n",
    "# lora_dropout: ë“œë¡­ì•„ì›ƒ í™•ë¥ .\n",
    "\n",
    "# ëª¨ë¸ì— LoRA ì–´ëŒ‘í„° ì ìš©\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# ì´í›„ Trainerë¥¼ ì‚¬ìš©í•´ íŒŒì¸íŠœë‹ì„ ì§„í–‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 396/396 [00:00<00:00, 3115.56 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 396/396 [00:00<00:00, 9569.47 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 3048.61 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 8967.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "# í† í¬ë‚˜ì´ì¦ˆ í•¨ìˆ˜ ì •ì˜\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['prompt'], padding='max_length', truncation=True, max_length=512)\n",
    "# ëª¨ë¸ì˜ ì •ë‹µ ë¼ë²¨ ì„¤ì •\n",
    "def add_labels(examples):\n",
    "    labels = tokenizer(examples['Answer'], padding='max_length', truncation=True, max_length=512).input_ids\n",
    "    examples['labels'] = labels\n",
    "    return examples\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "train_dataset = Dataset.from_pandas(train_df[['prompt', 'Answer']])\n",
    "# ë°ì´í„°ì…‹ì— í† í¬ë‚˜ì´ì¦ˆ ì ìš©\n",
    "tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.map(add_labels, batched=True)\n",
    "# ê²€ì¦ì…‹ì—ë„ ë™ì¼í•˜ê²Œ ì ìš©\n",
    "tokenized_eval_dataset = Dataset.from_pandas(val_df[['prompt', 'Answer']])\n",
    "tokenized_eval_dataset = tokenized_eval_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = tokenized_eval_dataset.map(add_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "# F1 ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "def calculate_f1_score(true_sentence, predicted_sentence, sum_mode=True):\n",
    "    true_sentence = ''.join(true_sentence.split())\n",
    "    predicted_sentence = ''.join(predicted_sentence.split())\n",
    "    \n",
    "    true_counter = Counter(true_sentence)\n",
    "    predicted_counter = Counter(predicted_sentence)\n",
    "    \n",
    "    if sum_mode:\n",
    "        true_positive = sum((true_counter & predicted_counter).values())\n",
    "        predicted_positive = sum(predicted_counter.values())\n",
    "        actual_positive = sum(true_counter.values())\n",
    "    else:\n",
    "        true_positive = len((true_counter & predicted_counter).values())\n",
    "        predicted_positive = len(predicted_counter.values())\n",
    "        actual_positive = len(true_counter.values())\n",
    "\n",
    "    precision = true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    recall = true_positive / actual_positive if actual_positive > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "# compute_metrics í•¨ìˆ˜ ì •ì˜\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    predicted_sentences = [tokenizer.decode(pred, skip_special_tokens=True) for pred in predictions]\n",
    "    true_sentences = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
    "    \n",
    "    f1_scores = [calculate_f1_score(true, pred)[2] for true, pred in zip(true_sentences, predicted_sentences)]\n",
    "    avg_f1_score = np.mean(f1_scores)\n",
    "    \n",
    "    return {\"f1\": avg_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 10/594 [01:50<1:45:27, 10.83s/it]"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# íŒŒì¸íŠœë‹ ì„¤ì •\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",  # ì—í¬í¬ë§ˆë‹¤ ê²€ì¦ì„ ìˆ˜í–‰í•˜ë„ë¡ ì„¤ì •\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Trainer ì„ ì–¸\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# íŒŒì¸íŠœë‹ ì‹¤í–‰\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì €ì¥\n",
    "model.save_pretrained(\"./saved_model\")\n",
    "tokenizer.save_pretrained(\"./saved_model\")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# ì–‘ìí™”ëœ ëª¨ë¸ê³¼ LoRA ì–´ëŒ‘í„°ê°€ ì ìš©ëœ ëª¨ë¸ ë¡œë“œ\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./saved_model\", quantization_config=bnb_config)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./saved_model\", quantization_config=bnb_config)\n",
    "# model = PeftModel.from_pretrained(model, \"./saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
