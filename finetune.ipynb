{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "from faiss_module import make_db\n",
    "import pandas as pd\n",
    "def format_docs(docs):\n",
    "    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n",
    "    context = \"\"\n",
    "    # context = \"<|start_header_id|>system<|end_header_id|>\\nContext\\n\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        #context += f\"Document {i+1}\\n\"\n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    # context += \"<|eot_id|>\"\n",
    "    return context \n",
    "\n",
    "def format_docs_wnum(docs):\n",
    "    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n",
    "    context = \"\"\n",
    "    # context = \"<|start_header_id|>system<|end_header_id|>\\nContext\\n\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        context += f\"Document {i+1}\\n\"\n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    # context += \"<|eot_id|>\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파인튜닝 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS DB from: ./train_faiss_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_db = make_db(train_df,'./train_faiss_db')\n",
    "answer_list = []\n",
    "context_list = []\n",
    "context_list_wnum = []\n",
    "for i, entry in enumerate(train_df.to_dict(orient='records')):\n",
    "    question = entry['Question']\n",
    "    answer = entry['Answer']+\"<|eot_id|>\"\n",
    "    # print(question)\n",
    "    # print(answer)\n",
    "    train_retriever = train_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                search_kwargs={'filter': {'source':entry['Source_path']},'score_threshold': 0.76,'k':3})\n",
    "    docs = train_retriever.invoke(question)\n",
    "    #print(format_docs(docs))\n",
    "    answer_list.append(answer)\n",
    "    context_list.append(format_docs(docs))\n",
    "    context_list_wnum.append(format_docs_wnum(docs))\n",
    "    \n",
    "train_df['Answer'] = answer_list\n",
    "train_df['context'] = context_list\n",
    "train_df['context_wnum'] = context_list_wnum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 생성\n",
    "def create_prompt(row):\n",
    "    context = row['context']\n",
    "    question = row['Question']\n",
    "    prompt  =f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "You are a Korean Q&A Assistant.<|eot_id|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "{context}\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{question}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "train_df['prompt'] = train_df.apply(create_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Source_path</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>context</th>\n",
       "      <th>context_wnum</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>2024년 중앙정부 재정체계는 어떻게 구성되어 있나요?</td>\n",
       "      <td>2024년 중앙정부 재정체계는 예산(일반·특별회계)과 기금으로 구분되며, 2024년...</td>\n",
       "      <td>주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는 예산(일반 ･특별회계...</td>\n",
       "      <td>Document 1\\n주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>2024년 중앙정부의 예산 지출은 어떻게 구성되어 있나요?</td>\n",
       "      <td>2024년 중앙정부의 예산 지출은 일반회계 356.5조원, 21개 특별회계 81.7...</td>\n",
       "      <td>주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는 예산(일반 ･특별회계...</td>\n",
       "      <td>Document 1\\n주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>기금이 예산과 다른 점은?</td>\n",
       "      <td>기금은 예산과 구분되는 재정수단으로서 재정운영의 신축성을 기할 필요가 있을 때, 정...</td>\n",
       "      <td>∙융자사업 등 기금 고유사업 수행\\n확정 절차∙부처의 예산 요구\\n∙기획재정부의 정...</td>\n",
       "      <td>Document 1\\n∙융자사업 등 기금 고유사업 수행\\n확정 절차∙부처의 예산 요...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>일반회계, 특별회계, 기금 간의 차이점은 무엇인가요?</td>\n",
       "      <td>일반회계는 특정 사업 운영 및 특정 세입으로 특정 세출을 충당하는데 사용되고, 특별...</td>\n",
       "      <td>특별회계49.6 47.2 51.3 53.6 59.1 59.7 71.6 81.7\\n(...</td>\n",
       "      <td>Document 1\\n특별회계49.6 47.2 51.3 53.6 59.1 59.7 ...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>2024년 총수입은 얼마이며, 예산수입과 기금수입은 각각 몇 조원인가요?</td>\n",
       "      <td>2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216...</td>\n",
       "      <td>주요 재정통계●\\nⅠ.\\n402재정수입\\n▸2024년도 총수입은 612.2조원이며,...</td>\n",
       "      <td>Document 1\\n주요 재정통계●\\nⅠ.\\n402재정수입\\n▸2024년도 총수입...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SAMPLE_ID               Source                             Source_path  \\\n",
       "0  TRAIN_000  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "1  TRAIN_001  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "2  TRAIN_002  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "3  TRAIN_003  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "4  TRAIN_004  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "\n",
       "                                   Question  \\\n",
       "0            2024년 중앙정부 재정체계는 어떻게 구성되어 있나요?   \n",
       "1          2024년 중앙정부의 예산 지출은 어떻게 구성되어 있나요?   \n",
       "2                            기금이 예산과 다른 점은?   \n",
       "3             일반회계, 특별회계, 기금 간의 차이점은 무엇인가요?   \n",
       "4  2024년 총수입은 얼마이며, 예산수입과 기금수입은 각각 몇 조원인가요?   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  2024년 중앙정부 재정체계는 예산(일반·특별회계)과 기금으로 구분되며, 2024년...   \n",
       "1  2024년 중앙정부의 예산 지출은 일반회계 356.5조원, 21개 특별회계 81.7...   \n",
       "2  기금은 예산과 구분되는 재정수단으로서 재정운영의 신축성을 기할 필요가 있을 때, 정...   \n",
       "3  일반회계는 특정 사업 운영 및 특정 세입으로 특정 세출을 충당하는데 사용되고, 특별...   \n",
       "4  2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216...   \n",
       "\n",
       "                                             context  \\\n",
       "0  주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는 예산(일반 ･특별회계...   \n",
       "1  주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는 예산(일반 ･특별회계...   \n",
       "2  ∙융자사업 등 기금 고유사업 수행\\n확정 절차∙부처의 예산 요구\\n∙기획재정부의 정...   \n",
       "3  특별회계49.6 47.2 51.3 53.6 59.1 59.7 71.6 81.7\\n(...   \n",
       "4  주요 재정통계●\\nⅠ.\\n402재정수입\\n▸2024년도 총수입은 612.2조원이며,...   \n",
       "\n",
       "                                        context_wnum  \\\n",
       "0  Document 1\\n주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는...   \n",
       "1  Document 1\\n주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는...   \n",
       "2  Document 1\\n∙융자사업 등 기금 고유사업 수행\\n확정 절차∙부처의 예산 요...   \n",
       "3  Document 1\\n특별회계49.6 47.2 51.3 53.6 59.1 59.7 ...   \n",
       "4  Document 1\\n주요 재정통계●\\nⅠ.\\n402재정수입\\n▸2024년도 총수입...   \n",
       "\n",
       "                                              prompt  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋을 학습셋과 검증셋으로 나누기\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=52)\n",
    "\n",
    "# train_df는 학습셋, val_df는 검증셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 허깅페이스 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.42s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# 양자화 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# 모델 로드 및 양자화 설정 적용\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# LoRA 어댑터 설정 추가\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    inference_mode=False, \n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1\n",
    ")\n",
    "# task_type: 적용할 작업의 유형(GPT 계열의 경우 CAUSAL_LM).\n",
    "# inference_mode: 학습 모드(False) 또는 추론 모드(True).\n",
    "# r: LoRA의 병목 차원.\n",
    "# lora_alpha: 스케일링 인자.\n",
    "# lora_dropout: 드롭아웃 확률.\n",
    "\n",
    "# 모델에 LoRA 어댑터 적용\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# 이후 Trainer를 사용해 파인튜닝을 진행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 396/396 [00:00<00:00, 3115.56 examples/s]\n",
      "Map: 100%|██████████| 396/396 [00:00<00:00, 9569.47 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 3048.61 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 8967.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "# 토크나이즈 함수 정의\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['prompt'], padding='max_length', truncation=True, max_length=512)\n",
    "# 모델의 정답 라벨 설정\n",
    "def add_labels(examples):\n",
    "    labels = tokenizer(examples['Answer'], padding='max_length', truncation=True, max_length=512).input_ids\n",
    "    examples['labels'] = labels\n",
    "    return examples\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = Dataset.from_pandas(train_df[['prompt', 'Answer']])\n",
    "# 데이터셋에 토크나이즈 적용\n",
    "tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.map(add_labels, batched=True)\n",
    "# 검증셋에도 동일하게 적용\n",
    "tokenized_eval_dataset = Dataset.from_pandas(val_df[['prompt', 'Answer']])\n",
    "tokenized_eval_dataset = tokenized_eval_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = tokenized_eval_dataset.map(add_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "# F1 점수를 계산하는 함수\n",
    "def calculate_f1_score(true_sentence, predicted_sentence, sum_mode=True):\n",
    "    true_sentence = ''.join(true_sentence.split())\n",
    "    predicted_sentence = ''.join(predicted_sentence.split())\n",
    "    \n",
    "    true_counter = Counter(true_sentence)\n",
    "    predicted_counter = Counter(predicted_sentence)\n",
    "    \n",
    "    if sum_mode:\n",
    "        true_positive = sum((true_counter & predicted_counter).values())\n",
    "        predicted_positive = sum(predicted_counter.values())\n",
    "        actual_positive = sum(true_counter.values())\n",
    "    else:\n",
    "        true_positive = len((true_counter & predicted_counter).values())\n",
    "        predicted_positive = len(predicted_counter.values())\n",
    "        actual_positive = len(true_counter.values())\n",
    "\n",
    "    precision = true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    recall = true_positive / actual_positive if actual_positive > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "# compute_metrics 함수 정의\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    predicted_sentences = [tokenizer.decode(pred, skip_special_tokens=True) for pred in predictions]\n",
    "    true_sentences = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
    "    \n",
    "    f1_scores = [calculate_f1_score(true, pred)[2] for true, pred in zip(true_sentences, predicted_sentences)]\n",
    "    avg_f1_score = np.mean(f1_scores)\n",
    "    \n",
    "    return {\"f1\": avg_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/594 [01:50<1:45:27, 10.83s/it]"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# 파인튜닝 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",  # 에포크마다 검증을 수행하도록 설정\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Trainer 선언\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# 파인튜닝 실행\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.save_pretrained(\"./saved_model\")\n",
    "tokenizer.save_pretrained(\"./saved_model\")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# 양자화된 모델과 LoRA 어댑터가 적용된 모델 로드\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./saved_model\", quantization_config=bnb_config)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./saved_model\", quantization_config=bnb_config)\n",
    "# model = PeftModel.from_pretrained(model, \"./saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
