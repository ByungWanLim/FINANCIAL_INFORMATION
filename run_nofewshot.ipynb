{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "import torch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "# Vector stores\n",
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PDFPlumberLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, KonlpyTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever, KNNRetriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PDFPlumberLoader ,UnstructuredPDFLoader\n",
    "from langchain_community.retrievers import BM25Retriever, KNNRetriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_teddynote.retrievers import KiwiBM25Retriever\n",
    "from langchain.docstore.document import Document\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import pymupdf4llm\n",
    "import time\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from konlpy.tag import Kkma\n",
    "# etc\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import logging\n",
    "from PyPDF2 import PdfReader\n",
    "import json\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # GPU 사용 가능 여부 및 MPS 지원 여부 확인\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "# intfloat/multilingual-e5-small\n",
    "# jhgan/ko-sroberta-multitask\n",
    "def get_embedding():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='jhgan/ko-sroberta-multitask',\n",
    "        model_kwargs={'device': device},\n",
    "        encode_kwargs={'normalize_embeddings': True})\n",
    "    return embeddings\n",
    "\n",
    "def normalize_string(s):\n",
    "    try:\n",
    "        normalized = unicodedata.normalize('NFC', s)\n",
    "        return normalized.encode('utf-8', errors='replace').decode('utf-8')\n",
    "    except Exception:\n",
    "        return s\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"�\", \" \").replace(\"\u0003\", \" \") # 잘못된 인코딩 문자 제거\n",
    "    text = ' '.join(text.split())  # 여러 공백을 하나로 줄임\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs(pdf_path):\n",
    "    documents = []\n",
    "    failed_pages = []  # 실패한 페이지를 추적하기 위한 리스트\n",
    "\n",
    "    try:\n",
    "        # 페이지 단위로 pymupdf4llm 사용\n",
    "        md_read = pymupdf4llm.to_markdown(pdf_path, page_chunks=True)\n",
    "        total_pages = len(md_read)\n",
    "\n",
    "        for page_data in md_read:\n",
    "            try:\n",
    "                page_number = page_data.get('metadata', {}).get('page', None)\n",
    "                if page_number is None:\n",
    "                    raise ValueError(\"Page number missing in metadata\")\n",
    "\n",
    "                text = clean_text(normalize_string(page_data.get('text', '')))\n",
    "                if not text:\n",
    "                    raise ValueError(\"Empty text\")  # 텍스트가 비어 있으면 예외 발생\n",
    "\n",
    "                metadata = {\n",
    "                    \"file_path\": pdf_path,\n",
    "                    \"page_number\": page_number,\n",
    "                    \"total_pages\": total_pages,\n",
    "                    \"tables\": page_data.get('tables', [])\n",
    "                }\n",
    "\n",
    "                document = Document(page_content=text, metadata=metadata)\n",
    "                documents.append(document)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Failed to process page {page_number} with pymupdf4llm: {e}\")\n",
    "                failed_pages.append(page_number)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to read PDF with pymupdf4llm: {e}\")\n",
    "        # pymupdf4llm 전체 실패 시 모든 페이지를 PyMuPDF로 처리하도록 설정\n",
    "        failed_pages = list(range(1, len(fitz.open(pdf_path)) + 1))\n",
    "\n",
    "    # 실패한 페이지에 대해 PyMuPDF로 재처리\n",
    "    if failed_pages:\n",
    "        try:\n",
    "            doc = fitz.open(pdf_path)\n",
    "            for page_num in failed_pages:\n",
    "                page = doc.load_page(page_num - 1)  # 페이지 번호는 0부터 시작하기 때문에 -1\n",
    "                text = page.get_text(\"text\")\n",
    "                if text:\n",
    "                    text = clean_text(normalize_string(text))\n",
    "                    metadata = {\n",
    "                        \"file_path\": pdf_path,\n",
    "                        \"page_number\": page_num,\n",
    "                        \"total_pages\": doc.page_count\n",
    "                    }\n",
    "                    document = Document(page_content=text, metadata=metadata)\n",
    "                    documents.append(document)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to read PDF with PyMuPDF: {e}\")\n",
    "\n",
    "    return documents\n",
    "\n",
    "def chunk_documents(docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=60,\n",
    "        separators=[\"\\n\\n\", \".\", \"?\", \"!\", \"\\n\", \"\\t\"]\n",
    "    )\n",
    "    chunks = []\n",
    "\n",
    "    for doc in docs:\n",
    "        text = doc.page_content\n",
    "        metadata = doc.metadata\n",
    "\n",
    "        # 표가 있는 경우 페이지 전체를 하나의 청크로 사용\n",
    "        if metadata.get('tables'):\n",
    "            chunks.append(Document(page_content=text, metadata=metadata))\n",
    "        else:\n",
    "            text_chunks = text_splitter.split_text(text)\n",
    "            chunks.extend([Document(page_content=chunk, metadata=metadata) for chunk in text_chunks])\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def make_db(df):\n",
    "    documents = []\n",
    "    pdf_files = df['Source_path'].unique()\n",
    "\n",
    "    # tqdm으로 파일 처리 진행 상황 표시\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(get_docs, pdf_files), total=len(pdf_files), desc=\"Processing PDFs\"))\n",
    "\n",
    "    for result in results:\n",
    "        documents.extend(result)\n",
    "\n",
    "    # 정규화\n",
    "    for doc in documents:\n",
    "        doc.page_content = normalize_string(doc.page_content)\n",
    "\n",
    "    # 표가 망가지지 않도록 청크 분할 처리\n",
    "    chunks = chunk_documents(documents)\n",
    "    print(f\"Total number of chunks: {len(chunks)}\")\n",
    "\n",
    "    faiss = FAISS.from_documents(chunks, embedding=get_embedding())\n",
    "    bm = BM25Retriever.from_documents(chunks)\n",
    "\n",
    "    return faiss, bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fewshot_db(df):\n",
    "    df = df.drop('SAMPLE_ID', axis=1)\n",
    "    df = df.drop('Source_path', axis=1)\n",
    "    df = df.to_dict(orient='records')\n",
    "    print(\"Loaded Fewshot Set:\", len(df))\n",
    "    to_vectorize = [\"\\n\\n\".join(normalize_string(value) for value in example.values()) for example in df]\n",
    "    faiss = FAISS.from_texts(to_vectorize, embedding=get_embedding())\n",
    "    # bm = BM25Retriever.from_texts(to_vectorize)\n",
    "    # knn = KNNRetriever.from_texts(to_vectorize, embeddings=get_embedding())\n",
    "    return faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test_df = pd.read_csv('test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n",
    "    context = \"\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        #context += f\"Document {i+1}\\n\"\n",
    "        doc.page_content = doc.page_content.replace(\"{\", \"(\")\n",
    "        doc.page_content = doc.page_content.replace(\"}\", \")\")\n",
    "        \n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:20<00:00,  5.08s/it]\n"
     ]
    }
   ],
   "source": [
    "def setup_llm_pipeline(model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"):\n",
    "    # 토크나이저 로드 및 설정\n",
    "        # 양자화 설정 적용\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config,low_cpu_mem_usage=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    text_generation_pipeline = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        return_full_text=False,\n",
    "\n",
    "        max_new_tokens=1024,\n",
    "        eos_token_id = terminators,\n",
    "        pad_token_id = tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "    return llm\n",
    "llm = setup_llm_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(response):\n",
    "    # AI: 로 시작하는 줄을 찾아 그 이후의 텍스트만 추출\n",
    "    lines = response.split('\\n')\n",
    "    for line in lines:\n",
    "        line = line.replace('**', '')\n",
    "        if line.startswith('Answer:'):\n",
    "            return line.replace('Answer:', '').strip()\n",
    "        if line.startswith('assistant:'):\n",
    "            return line.replace('assistant:', '').strip()\n",
    "    return response.strip()  # AI: 를 찾지 못한 경우 전체 응답을 정리해서 반환\n",
    "\n",
    "\n",
    "\n",
    "def run (test,dataset,llm,verbose=False):\n",
    "    results = []\n",
    "    for i, row in (dataset.iterrows()):\n",
    "# \n",
    "        full_template = \"<|begin_of_text|>\"\n",
    "        full_template += \"\"\"<|start_header_id|>system<|end_header_id|>\n",
    "당신은 유용한 금융 정보 QnA 챗봇입니다. \n",
    "문맥을 바탕으로 질문들에 대한 답변을 서론 없이 객관적이고 공식적인 문체로 작성하세요.<|eot_id|>\n",
    "\"\"\"\n",
    "        question = row['Question']          \n",
    "        full_template += \"\"\" \"\"\"\n",
    "        contexts = test.invoke(normalize_string(question))\n",
    "        contexts = format_docs(contexts)\n",
    "        full_template += \"\"\"<|start_header_id|>user<|end_header_id|>Question: {input}\\n전체 출력은 1 문장으로 답변해주세요.\\n\\n\"\"\"\n",
    "        full_template += f\"\"\"Context: {contexts}<|eot_id|>\\n\\n\"\"\"\n",
    "        full_template += \"\"\"<|start_header_id|>assistant<|end_header_id>\"\"\"\n",
    "        \n",
    "        prompt = PromptTemplate(template=full_template, input_variables=[\"input\"])\n",
    "        qa_chain = (\n",
    "        {\n",
    "            \"input\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        answer = qa_chain.invoke(input=question)\n",
    "        answer = extract_answer(answer)\n",
    "        results.append({\n",
    "            \"Question\": question,\n",
    "            \"Answer\": answer,\n",
    "            \"Source\": row['Source']\n",
    "        })\n",
    "        if verbose:\n",
    "            print(f\"={i}/{len(dataset)}\")\n",
    "            print(\"Question: \", question, end=\" | \")\n",
    "            print(\"Context Number |\",len(contexts))\n",
    "            print(\"Answer: \", results[-1]['Answer'])\n",
    "            try:\n",
    "                print(\"REAL Answer: \",row['Answer'])\n",
    "            except:\n",
    "                pass\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def calculate_f1_score(true_sentence, predicted_sentence, sum_mode=True):\n",
    "\n",
    "    #공백 제거\n",
    "    true_sentence = ''.join(true_sentence.split())\n",
    "    predicted_sentence = ''.join(predicted_sentence.split())\n",
    "    \n",
    "    true_counter = Counter(true_sentence)\n",
    "    predicted_counter = Counter(predicted_sentence)\n",
    "\n",
    "    #문자가 등장한 개수도 고려\n",
    "    if sum_mode:\n",
    "        true_positive = sum((true_counter & predicted_counter).values())\n",
    "        predicted_positive = sum(predicted_counter.values())\n",
    "        actual_positive = sum(true_counter.values())\n",
    "\n",
    "    #문자 자체가 있는 것에 focus를 맞춤\n",
    "    else:\n",
    "        true_positive = len((true_counter & predicted_counter).values())\n",
    "        predicted_positive = len(predicted_counter.values())\n",
    "        actual_positive = len(true_counter.values())\n",
    "\n",
    "    #f1 score 계산\n",
    "    precision = true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    recall = true_positive / actual_positive if actual_positive > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def calculate_average_f1_score(true_sentences, predicted_sentences):\n",
    "    \n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1_score = 0\n",
    "    \n",
    "    for true_sentence, predicted_sentence in zip(true_sentences, predicted_sentences):\n",
    "        precision, recall, f1_score = calculate_f1_score(true_sentence, predicted_sentence)\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1_score += f1_score\n",
    "    \n",
    "    avg_precision = total_precision / len(true_sentences)\n",
    "    avg_recall = total_recall / len(true_sentences)\n",
    "    avg_f1_score = total_f1_score / len(true_sentences)\n",
    "    \n",
    "    return {\n",
    "        'average_precision': avg_precision,\n",
    "        'average_recall': avg_recall,\n",
    "        'average_f1_score': avg_f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "Processing PDFs:   0%|          | 0/16 [00:00<?, ?it/s]ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "Processing PDFs:   6%|▋         | 1/16 [00:03<00:46,  3.13s/it]ERROR:root:Failed to read PDF with pymupdf4llm: not a textpage of this page\n",
      "Processing PDFs: 100%|██████████| 16/16 [00:43<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:660: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=1/124\n",
      "Question:  2024년 중앙정부의 예산 지출은 어떻게 구성되어 있나요? | Context Number | 122\n",
      "Answer:  2024년도 중앙정부 예산은 총 574조원으로, 이 중 일반회계는 435조원, 특별회계는 139조원으로 구성됩니다.\n",
      "REAL Answer:  2024년 중앙정부의 예산 지출은 일반회계 356.5조원, 21개 특별회계 81.7조원으로 구성되어 있습니다.\n",
      "=4/124\n",
      "Question:  2024년 총수입은 얼마이며, 예산수입과 기금수입은 각각 몇 조원인가요? | Context Number | 1966\n",
      "Answer:  2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216.7조원입니다.\n",
      "REAL Answer:  2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216.7조원입니다.\n",
      "=6/124\n",
      "Question:  2024년의 기금수입은 어떻게 구성되어 있나요? | Context Number | 836\n",
      "Answer:  2024년 기금수입은 사회서비스 투자펀드 조성에 70억원, 사회복지 일반 부문은 10조 8,894억원으로 증가합니다.\n",
      "REAL Answer:  2024년도 기금수입은 사회보장성기금 92.3조원, 경상이전수입 39.6조원, 기타 84.7조원으로 구성되어 있습니다.\n",
      "=11/124\n",
      "Question:  2024년 총지출 기준 예산의 일반회계와 특별회계의 비중이 각각 얼마인가? | Context Number | 828\n",
      "Answer:  2024년 총지출 기준 예산의 일반회계와 특별회계의 비중은 65.8%와 34.2%입니다.\n",
      "REAL Answer:  2024년 총지출 중 일반회계와 특별회계의 비중은 각각 54.3%와 12.4%이다.\n",
      "=19/124\n",
      "Question:  2020년 결산 기준, 연구개발비 중 개발연구 규모는 몇 억원인가? | Context Number | 2606\n",
      "Answer:  2020년 결산 기준, 연구개발비 중 개발연구 규모는 78,754억원입니다.\n",
      "REAL Answer:  2020년 결산 기준 연구개발비 중 개발연구 규모는 78754억원이다.\n",
      "=20/124\n",
      "Question:  세출예산현액이란? | Context Number | 796\n",
      "Answer:  세출예산현액이란 중앙정부의 일반회계와 특별회계의 지출을 모두 합한 예산총계에서 중복 계산된 '회계간' 및 '회계내 계정간' 내부거래지출을 차감한 수치입니다.\n",
      "REAL Answer:  예산 확정 후 전년도로부터의 이월액 반영, 추경 편성, 기금운용계획 변경, 이용・전용, 예비비 증액 등을 반영한 것으로, 실제 지출할 수 있는 한도액을 의미한다.\n",
      "=23/124\n",
      "Question:  2022년 기준, 일반회계, 특별회계, 기금의 집행률은? | Context Number | 1924\n",
      "Answer:  2022년 기준, 일반회계, 특별회계, 기금의 집행률은 97.3%, 94.7%, 97.6%입니다.\n",
      "REAL Answer:  2022년 기준, 집행률은 일반회계 97.3%, 특별회계 94.7%, 기금 97.6%\n",
      "=25/124\n",
      "Question:  2022년 결산 기준으로 사회보험성기금의 이월금 규모는 몇 억원인가요? | Context Number | 3069\n",
      "Answer:  2022년 결산 기준으로 사회보험성기금의 이월금 규모는 약 92.3조원입니다.\n",
      "REAL Answer:  223억원입니다.\n",
      "=27/124\n",
      "Question:  2022년 기준으로 국내총생산 대비 일반정부부채와 공공부문 부채의 비중은 각각 몇 퍼센트인가? | Context Number | 2047\n",
      "Answer:  2022년 기준으로 국내총생산 대비 일반정부부채는 53.5%, 공공부문 부채는 73.5%입니다.\n",
      "REAL Answer:  일반정부부채(D2)는 53.5%, 공공부문 부채(D3)는 73.5%이다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=37/124\n",
      "Question:  2007년 시행된 국가재정법에서 추경 편성 사유로 명시된 사항은 무엇인가? | Context Number | 853\n",
      "Answer:  추경 편성 사유는 ①전쟁이나 대규모 재해가 발생한 경우, ②경기침체, 대량 실업, 남북 관계의 변화, 경제협력과 같은 대내외 여건에 중대한 변화가 발생하였거나 발생할 우려가 있는 경우, ③법령에 따라 국가가 지급하여야 하는 지출이 발생하거나 증가하는 경우에 한정됩니다.\n",
      "REAL Answer:  국가재정법에서 추경 편성 사유로 명시된 사항은 전쟁이나 대규모 재해가 발생한 경우, 경기침체, 대량 실업, 남북 관계의 변화, 경제협력과 같은 대내외 여건에 중대한 변화가 발생하였거나 발생할 우려가 있는 경우, 법령에 따라 국가가 지급하여야 하는 지출이 발생하거나 증가하는 경우에 한정되어 있습니다.\n",
      "=41/124\n",
      "Question:  2024년 교육재정 교부금의 규모는 얼마이고, 전년 대비 추이는 어떠한가? | Context Number | 1574\n",
      "Answer:  2024년 교육재정 교부금은 68조 8,732억원으로 전년 대비 9.1% 감소합니다.\n",
      "REAL Answer:  2024년 교육재정교부금은 73.0조원이며 전년 대비 8.9% 감소하였다.\n",
      "=43/124\n",
      "Question:  2024년에 교육재정교부금에서 유아교육비 및 보육료 지원에 할당된 비중은? | Context Number | 2388\n",
      "Answer:  2024년 교육재정교부금에서 유아교육비 및 보육료 지원에 할당된 비중은 26.7%입니다.\n",
      "REAL Answer:  4.40%\n",
      "=44/124\n",
      "Question:  교육재정 교부금이란? | Context Number | 1750\n",
      "Answer:  교육재정 교부금은 국가가 지방 교육재정으로 교육의 균형발전을 위해 교육기관 및 교육행정기관 경비를 지원하는 일반지원금입니다.\n",
      "REAL Answer:  교육의 균형발전을 위해 교육기관 및 교육행정기관 경비를 국가가 교부하는 일반지원금으로, 일반회계 보통・특별교부금, 고교 무상교육 증액분, 특별회계 유아교육비・보육료 지원 교부금 등 4가지로 구성되었다.\n",
      "=46/124\n",
      "Question:  특별회계 국고보조금 중 국가균형발전특별회계에서 얼마가 포괄보조금으로 지출되는가? | Context Number | 1990\n",
      "Answer:  특별회계 국고보조금 중 국가균형발전특별회계에서 포괄보조금으로 지출되는 금액은 1.1조원입니다.\n",
      "REAL Answer:  특별회계 국고보조금 18.2조원 중 10.0조원이 국가균형발전특별회계에서 지출되는 포괄보조금이다.\n",
      "=47/124\n",
      "Question:  2024년의 국고보조사업(자치단체 이전)에서 기금 규모는 얼마인가? | Context Number | 1035\n",
      "Answer:  2024년의 국고보조사업(자치단체 이전) 규모는 89.3조원입니다.\n",
      "REAL Answer:  90,247억원으로 10.1%를 차지하고 있다.\n",
      "=52/124\n",
      "Question:  임신·출산을 희망하는 가구에 어떤 지원이 신규로 이뤄지고 있으며, 고위험 임산부와 미숙아·선천성 이상아의 의료비 지원은 어떻게 이루어지는가? | Context Number | 1886\n",
      "Answer:  임신·출산을 희망하는 가구에 신규로 지원되는 내용은 주거안정을 위한 신생아 3종 특례를 신설하고, 출산가구의 주거부담을 완화하는 것이다.\n",
      "REAL Answer:  임신·출산을 희망하는 가구에는 필수가임력(생식건강) 검진비와 냉동난자를 활용한 보조 생식술 비용을 신규로 지원하며, 고위험 임산부와 미숙아·선천성 이상아의 의료비는 소득수준에 관계없이 지원된다.\n",
      "=57/124\n",
      "Question:  2024년 R&D 분야에 대한 재정투자 규모는 2023년 대비 얼마나 감소했으며, 어떤 분야의 국가전략기술 투자를 확대할 계획인가? | Context Number | 2110\n",
      "Answer:  2024년 R&D 분야에 대한 재정투자 규모는 2023년 대비 △9.5% 감소한 26.5조원입니다.\n",
      "REAL Answer:  2024년 R&D 분야에 대한 재정투자 규모는 2023년 대비 9.5% 감소한 26.5조원이며, AI·바이오·반도체 등의 분야에 대한 국가전략기술 투자를 확대할 계획입니다.\n",
      "=58/124\n",
      "Question:  우주산업 클러스터 삼각체제 구축사업의 목표와 국가 우주산업 육성 거점 지역은 어디인가? | Context Number | 1473\n",
      "Answer:  전남, 경남, 대전을 국가 우주산업 육성 거점으로 지정하고 민간발사장, 우주환경시험시설, 특화지구별 거점센터 구축을 추진한다.\n",
      "REAL Answer:  우주산업 클러스터 삼각체제 구축사업은 우주경제 시대 대비 민간 주도 우주개발 역량 강화 및 자생적 생태계 조성을 위해 핵심 인프라를 구축하는 플래그십 프로젝트이며, 전남, 경남, 대전을 국가 우주산업 육성 거점으로 지정했다.\n",
      "=62/124\n",
      "Question:  2024년도 공공질서 및 안전 분야의 재정투자는 전년도 대비 어떻게 변화했으며, 어떤 분야에 특히 재정투자가 집중되었는가? | Context Number | 1539\n",
      "Answer:  2024년도 공공질서 및 안전 분야의 재정투자는 전년도 대비 6.5% 증가하여 24.4조원으로 집행되었습니다. 특히, 민생침해범죄 예방 및 대응, 재난 및 안전 사고에 대한 근본적 예방에 집중적으로 투자되었습니다.\n",
      "REAL Answer:  2024년도 공공질서 및 안전 분야의 재정투자는 24.4조원으로 2023년도 22.9조원 대비 6.5% 증가하였으며, 마약·스토킹 등 민생침해범죄 예방·대응과 재난·안전 사고에 대한 근본적 예방에 집중적으로 투자하였다.\n",
      "=77/124\n",
      "Question:  예산 증감률이 가장 높은 분야는 무엇인가요? | Context Number | 819\n",
      "Answer:  assistant\n",
      "2022년 예산 증감률이 가장 높은 분야는 보건･복지･고용 분야로, 40.8%의 증감률을 기록했습니다.\n",
      "REAL Answer:  외교·통일 분야가 17.7%로 예산 증감률이 가장 높습니다.\n",
      "=98/124\n",
      "Question:  하수관로정비 사업 예산은 2023년 대비 2024년에 얼마나 증가했는가? | Context Number | 1242\n",
      "Answer:  2024년 대비 2023년에 하수관로정비 사업 예산은 34.5% 증가했다.\n",
      "REAL Answer:  하수관로정비 사업 예산은 2023년 9,531억원에서 2024년 1조 2,816억원으로 증가하여 34.5% 증가하였다.\n",
      "=103/124\n",
      "Question:  국회의 입법활동 및 의정활동을 지원하기 위해 어떤 활동들이 실시되고 있는가? | Context Number | 1628\n",
      "Answer:  국회는 입법활동 및 의정활동을 지원하기 위해 다양한 활동을 실시하고 있습니다.\n",
      "REAL Answer:  국회 정책세미나·토론회·간담회 실시간 생중계 시스템 구축, SNS 영상 제작 지원 및 의정활동 안내 문자메시지 발송 등을 통해 국회 입법활동 및 의정활동을 지원하고 있다.\n",
      "=108/124\n",
      "Question:  국가첨단전략산업 특화단지에 대한 지원 계획은 어떻게 되어 있는가? | Context Number | 771\n",
      "Answer:  국가첨단전략산업 특화단지에 대한 지원 계획은 2024년 용수공급시설에 154억원, 진입도로에 200억원, 전력공급시설에 37.5억원을 지원하는 등 391.5억원을 지원하는 등 첨단산업 인프라 지원을 위한 국비를 확대한다.\n",
      "REAL Answer:  국가첨단전략산업 특화단지에 대한 저리융자, 기반시설 구축, 현장 맞춤형 실무교육 등을 종합적으로 지원할 계획이다.\n",
      "=109/124\n",
      "Question:  가족돌봄청년을 위해 신규로 지원되는 혜택은 무엇인가요? | Context Number | 1660\n",
      "Answer:  가족돌봄청년을 위해 신규로 지원되는 혜택은 중위소득 150% 이하 2자녀 이상 가구에 대해 본인부담금의 10%를 추가 지원하는 것입니다.\n",
      "REAL Answer:  자기돌봄비(연200만원)와 돌봄코디네이터를 통한 밀착 사례관리 및 자조모임 등을 신규로 지원한다.\n",
      "=110/124\n",
      "Question:  의료 분야에 대한 국고 지원이 어떻게 확대되고 있는가? | Context Number | 1951\n",
      "Answer:  2024년 건강보험·보건의료 및 식품의약품안전 부문 예산은 20조 275억원에서 18조 8,432억원으로 5.9% 감소하였으며, 국민건강 보장 강화를 위해 건강보험 11.0 → 12.2조원, 노인장기요양보험 2.0 → 2.2조원에 대한 국고 지원을 확대하고 취약계층 의료기반 확충을 위해 암검진비 지원 423억원, 재활병원 70억원 건립 등 차질없이 추진한다.\n",
      "REAL Answer:  달빛어린이병원(45개소)에 대해 국고 지원에 착수하고, 소아환자에게 24시간 의료상담을 제공하는 24시간 상담센터를 신설하고, 어린이 공공전문진료센터와 소아암 전문거점병원을 확충하고, 전공의 수련수당도 신규 지원하고 있다.\n",
      "=113/124\n",
      "Question:  2023년 기획재정부의 총세입예산은 얼마인가요? | Context Number | 347\n",
      "Answer:  2023년 기획재정부의 총세입예산은 1,044,000 천원입니다.\n",
      "REAL Answer:  438,715,377백만원\n",
      "=114/124\n",
      "Question:  기초생활보장제도 4대 급여의 예산 규모는 2023년 대비 2024년에 어떻게 변화되는가? | Context Number | 1515\n",
      "Answer:  2024년 기초생활보장제도 4대 급여의 예산 규모는 2023년 17.8조원에서 19.4조원으로 확대된다.\n",
      "REAL Answer:  2023년 17.8조원에서 2024년 19.4조원으로 확대된다.\n",
      "=120/124\n",
      "Question:  교육 분야 재정투자 계획에 따르면 2024년에 유아및초중등교육 분야의 예산이 2023년에 비해 어떻게 변하는가? | Context Number | 1553\n",
      "Answer:  2024년 유아 및 초·중등교육 부문 예산은 2023년보다 7.2조원, 8.9% 감소한다.\n",
      "REAL Answer:  2024년에 유아및초중등교육 분야의 예산은 737,290억원으로 2023년 대비 8.9% 감소한다.\n",
      "=125/124\n",
      "Question:  문화예술 부문의 총 예산은 어떻게 변화했는가? | Context Number | 1945\n",
      "Answer:  문화예술 부문의 총 예산은 2023년 40,022억 원에서 2024년 40,628억 원으로 1.5% 증가했습니다.\n",
      "REAL Answer:  문화예술 부문의 총 예산은 2023년 40,022억원에서 2024년 40,628억원으로 1.5% 증가하였다.\n",
      "=127/124\n",
      "Question:  2024년에 산업혁신지원 부문의 총 예산은 얼마이며, 전년 대비 어떤 증감률을 보였는가? | Context Number | 1592\n",
      "Answer:  2024년 산업혁신지원 부문의 총 예산은 5,100억원으로, 전년 대비 6.4% 증가했습니다.\n",
      "REAL Answer:  2024년에 산업혁신지원 부문의 총 예산은 63,146억원이며, 전년 대비 5.1% 증가하였다.\n",
      "=129/124\n",
      "Question:  산업혁신지원 부문 주요 변동 내역에서 2024년에 산업혁신인재성장지원 부문의 예산은 얼마이며, 전년 대비 어떤 증감률을 보였는가? | Context Number | 1587\n",
      "Answer:  2024년도 산업혁신인재성장지원 부문의 예산은 175억원으로, 전년 대비 0.0% 증감률을 보였다.\n",
      "REAL Answer:  2024년에 산업혁신인재성장지원 부문의 예산은 1,575억원이며, 전년 대비 16.0% 증가하였다.\n",
      "=136/124\n",
      "Question:  외교·통일 분야 재정투자 계획에서 2024년 외교·통상 부문 예산은 2023년 대비 얼마나 증가했는가? | Context Number | 1586\n",
      "Answer:  2023년 대비 29.8% 증가했습니다.\n",
      "REAL Answer:  14,736억원 증가하여 29.8% 증가하였다.\n",
      "=137/124\n",
      "Question:  재정투자 계획에서 2023년 대비 2024년에 가장 큰 증가율을 보인 분야는 무엇인가요? | Context Number | 1433\n",
      "Answer:  2024년에 재정투자 계획에서 가장 큰 증가율을 보인 분야는 SOC 분야로, 2023년 대비 5.8% 증가한 26.4조원으로 역대 최대 규모의 예산을 지원한다.\n",
      "REAL Answer:  2023년 대비 2024년에 22.1%의 증가율을 보인 재정·금융 분야입니다.\n",
      "=145/124\n",
      "Question:  예산 사전의결의 원칙은 무엇인가? | Context Number | 2672\n",
      "Answer:  예산 사전의결 원칙은 예산 편성 시 정부가 제안한 사업의 타당성을 사전적으로 검증하고 평가하여 투명하고 공정하게 사업의 신규 투자를 결정하는 것을 의미합니다.\n",
      "REAL Answer:  예산 사전의결의 원칙은 예산을 집행하기에 앞서 국회의 의결을 얻도록 하는 원칙입니다.\n",
      "=149/124\n",
      "Question:  예산이란 무엇을 의미하며 어떻게 표시되는가? | Context Number | 816\n",
      "Answer:  예산은 일정 기간 동안 국가의 재정 활동에 얼마만큼 지출하고 이를 위해 재원을 어떻게 조달할 것인지를 금액으로 표시한 것으로 회계연도 단위로 작성되어 운용하는 것으로, 회계연도 독립의 원칙에 따라 특정 회계연도의 지출은 당해 회계연도의 수입으로 이루어집니다.\n",
      "REAL Answer:  예산이란 일정 기간 동안 국가의 재정활동에 얼마만큼 지출하고 이를 위해 재원을 어떻게 조달할 것인가를 금액으로 표시한 것이며, 회계연도 단위로 작성되어 운용 회계연도 독립의 원칙에 따라 특정 회계연도의 지출은 당해 회계연도의 수입으로 이루어진다.\n",
      "=150/124\n",
      "Question:  세입세출예산은 어떤 원칙에 따라 작성되는가? | Context Number | 1241\n",
      "Answer:  세입세출예산은 총계주의 원칙에 따라 한 회계연도의 일체의 수입을 세입으로 하고 일체의 지출을 세출로 하여 작성합니다.\n",
      "REAL Answer:  세입세출예산은 총계주의 원칙에 따라 한 회계연도의 일체의 수입을 세입으로 하고 일체의 지출을 세출로 하여 작성된다.\n",
      "=159/124\n",
      "Question:  국고채무부담행위는 어떤 경우에 국회의 의결을 받아야 하나요? | Context Number | 2174\n",
      "Answer:  국고채무부담행위는 재정지출 총량제(PAYGO) 도입을 위한 국회의 의결을 받아야 합니다.\n",
      "REAL Answer:  법률에 의하지 않거나 세출예산 또는 계속비 총액범위를 벗어나 국가채무를 부담할 때 국회의 의결을 받아야 합니다.\n",
      "=161/124\n",
      "Question:  본예산, 수정예산, 준예산의 차이점은 무엇인가요? | Context Number | 1676\n",
      "Answer:  본예산, 수정예산, 준예산의 차이점은 다음과 같습니다. 본예산은 정부가 법률에 의해 정한 예산의 기본적인 틀을 담고 있으며, 정부가 법률에 의해 정한 예산의 기본적인 틀을 담고 있습니다. 수정예산은 본예산에 대한 변경을 의미하며, 국회에서 의결한 경우에만 가능합니다. 준예산은 본예산을 바탕으로 한 예산의 추정금액을 말합니다.\n",
      "REAL Answer:  본예산은 국회의 의결을 얻어 확정·성립된 통상적 의미의 예산이며, 수정예산은 정부가 예산을 국회에 제출한 후 국회의 심의·확정 전에 수정하여 제출하는 예산입니다. 준예산은 예산이 법정기한 내에 국회의 의결을 받지 못할 경우에 대비한 예산입니다.\n",
      "=162/124\n",
      "Question:  재정수지는 무엇을 판단하기 위한 재정 지표인가? | Context Number | 840\n",
      "Answer:  재정수지는 재정수입과 재정지출의 차액을 말하는 것으로, 국가채무의 증가, 재정적자, 재정적자 수준 등 재정상황을 판단하기 위한 중요한 지표입니다.\n",
      "REAL Answer:  재정수지는 국가재정의 건전성을 판단하기 위한 재정 지표로, 재정수입과 재정 지출의 차이를 의미합니다.\n",
      "=164/124\n",
      "Question:  정부는 언제 재정규모를 축소하고 언제 확대하는가? | Context Number | 2146\n",
      "Answer:  정부는 재정규모를 축소하는 경우는 경기가 호황일 때이며, 재정규모를 확대하는 경우는 불황일 때이다.\n",
      "REAL Answer:  정부는 경기조절을 위해 경기가 호황일 때는 경기의 과열을 막기 위하여 재정규모를 축소하고, 불황일 때에는 경기 회복을 위해 재정규모를 확대합니다.\n",
      "=168/124\n",
      "Question:  사회보장성기금은 정부가 어떤 목적을 위해 설치한 기금인가? | Context Number | 2820\n",
      "Answer:  사회보장성기금은 정부가 특정한 목적을 위하여 특정한 자금을 신축적으로 운용할 필요가 있을 때 법률로써 설치한 기금입니다.\n",
      "REAL Answer:  국민의 안정적 사회보장을 위해 사회보장 급여 지급을 목적으로 한다.\n",
      "=175/124\n",
      "Question:  외국환평형기금채권은 왜 발행하는가? | Context Number | 1716\n",
      "Answer:  외국환평형기금채권은 1998년 외환위기 이후 외환 보유액 확충을 위해 발행하는 채권입니다.\n",
      "REAL Answer:  외국환평형기금채권은 1998년 외환위기 이후 외환 보유액 확충을 위해 발행된다.\n",
      "=178/124\n",
      "Question:  국가채무(D1)는 어떤 지표로 활용되는가? | Context Number | 1375\n",
      "Answer:  국가채무(D1)는 재정건전성 관리를 위한 지표로 활용되며, 재정의 위험 및 비용이 증가하는 것을 방지하기 위해 적정 규모 수준에서 유지되도록 관리되어야 한다.\n",
      "REAL Answer:  국가채무(D1)는 중앙정부와 지방정부의 재정건전성 관리를 위한 지표로 활용된다.\n",
      "=179/124\n",
      "Question:  국가채무가 과다할 경우 어떤 위험이 발생할 수 있는가? | Context Number | 2003\n",
      "Answer:  국가채무가 과다할 경우 국가채무의 불안정성과 재정위기가 발생할 수 있으며, 이는 경제에 대한 투자 및 정부의 본질기능 수행에 영향을 미칠 수 있습니다.\n",
      "REAL Answer:  국가채무가 과다할 경우 재정의 위험 및 비용이 증가할 수 있다.\n",
      "=183/124\n",
      "Question:  우리나라는 언제부터 일반정부부채(D2)를 산출해 왔는가? | Context Number | 2332\n",
      "Answer:  2021년 기준, 우리나라의 일반정부 부채는 GDP 대비 50.8%이며 OECD 평균(120.6%) 에 비해 낮음.\n",
      "REAL Answer:  우리나라는 2011년부터 국가채무를 작성해 왔다.\n",
      "=188/124\n",
      "Question:  국가채무 통계에서 공공부문부채(D3)는 어떤 기준으로 산출되는가? | Context Number | 2266\n",
      "Answer:  공공부문부채(D3)는 발생주의 기준(PSDS12)에 기초하여 작성되며, 중앙 정부와 지방자치단체(지방교육재정 포함), 비영리공공기관, 비금융 공기업을 부채를 포괄한다.\n",
      "REAL Answer:  공공부문부채(D3)는 PSDS에 기초하여 발생주의 기준으로 산출된 일반정부부채(D2)와 비금융공기업 단위를 포괄한 부채로 나타낸다.\n",
      "=190/124\n",
      "Question:  국가보증채무가 국가채무와 어떻게 관련되어 있나요? | Context Number | 1899\n",
      "Answer:  국가보증채무는 주 채무자가 채무이행이 불가능한 경우, 국가가 대신해서 갚아야 하는 채무를 말하며, 지급 의무자가 국가로 확정된 것은 아니기 때문에 국가채무에 포함되지는 않습니다.\n",
      "REAL Answer:  국가보증채무는 국가채무의 범위에 포함되지 않지만, 대신 지급해야 할 사유가 발생하는 경우 국가채무로 전환되기 때문에 국가채무를 관리하는 주요 보조 지표이며, 잠재적 부채 중 하나임\n",
      "=192/124\n",
      "Question:  총수입은 무엇을 포함하는가? | Context Number | 1684\n",
      "Answer:  총수입은 중앙정부가 맡은 일을 수행하기 위하여 한 해 동안 거둬들이는 재정 수입 전체 규모로, 국세, 세외수입 등을 통한 일반회계, 특별회계의 예산세입과 기금수입의 총합계에서 내부거래와 보전거래를 제외한 정부 수입을 의미합니다.\n",
      "REAL Answer:  국세, 세외수입, 기금수입 등을 통한 일반회계, 특별회계의 예산세입과 기금수입의 총합계에서 내부거래와 보전거래를 제외한 정부 수입을 포함한다.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "\n",
    "weight = [0.5,0.5]\n",
    "train_faiss_db, train_bm_retrievier = make_db(train_df) \n",
    "\n",
    "train_k = 3\n",
    "train_bm_retrievier.k = train_k\n",
    "#knn_retriever.k = train_k\n",
    "train_faiss_retriever = train_faiss_db.as_retriever(search_type=\"mmr\",search_kwargs={'k':train_k} )\n",
    "train_ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[train_bm_retrievier, train_faiss_retriever], weights=weight\n",
    ")\n",
    "\n",
    "\n",
    "fewshot_k = 3\n",
    "\n",
    "k_folds = 4\n",
    "fold_results = []\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=52)\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_df)):\n",
    "    fold_result = []\n",
    "    train_set = train_df.iloc[train_index]\n",
    "    val_set = train_df.iloc[val_index]\n",
    "\n",
    "    pred = run(train_faiss_retriever, val_set, llm, verbose=True)\n",
    "    result = pd.DataFrame()\n",
    "    result['pred'] = [result['Answer'] for result in pred]\n",
    "    val_set.index = range(len(val_set))\n",
    "    result['gt'] = val_set['Answer']\n",
    "        \n",
    "    result = calculate_average_f1_score(result['gt'], result['pred'])\n",
    "    print(result)\n",
    "    fold_results.append(result)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
