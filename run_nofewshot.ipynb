{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "import torch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "# Vector stores\n",
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PDFPlumberLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, KonlpyTextSplitter, MarkdownHeaderTextSplitter, MarkdownTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever, KNNRetriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PDFPlumberLoader ,UnstructuredPDFLoader\n",
    "from langchain_community.retrievers import BM25Retriever, KNNRetriever \n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_teddynote.retrievers import KiwiBM25Retriever, OktBM25Retriever\n",
    "from langchain.docstore.document import Document\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import pymupdf4llm\n",
    "import time\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from konlpy.tag import Kkma\n",
    "# etc\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import logging\n",
    "from PyPDF2 import PdfReader\n",
    "import json\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # GPU 사용 가능 여부 및 MPS 지원 여부 확인\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intfloat/multilingual-e5-small\n",
    "# jhgan/ko-sroberta-multitask\n",
    "\n",
    "def get_embedding():\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='jhgan/ko-sroberta-multitask',\n",
    "        model_kwargs={'device': device},\n",
    "        encode_kwargs={'normalize_embeddings': True})\n",
    "    return embeddings\n",
    "def normalize_string(s):\n",
    "    try:\n",
    "        normalized = unicodedata.normalize('NFC', s)\n",
    "        return normalized.encode('utf-8', errors='replace').decode('utf-8')\n",
    "    except Exception:\n",
    "        return s\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"�\", \" \").replace(\"\u0003\", \" \")  # 잘못된 인코딩 문자 제거\n",
    "    return text\n",
    "\n",
    "def format_docs(docs):\n",
    "    context = \"\"\n",
    "    i = 1\n",
    "    for doc in docs:\n",
    "        #context += f\"Document: {i}\" +\"Source:\"+ doc.metadata['source'] +'\\n'\n",
    "        context += doc.page_content\n",
    "        context += '\\n---\\n'\n",
    "        i += 1\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs(pdf_path):\n",
    "    documents = []\n",
    "    try:\n",
    "        # 페이지 단위로 pymupdf4llm 사용\n",
    "        md_read = pymupdf4llm.to_markdown(pdf_path,page_chunks=True)\n",
    "        total_pages = len(md_read)    \n",
    "        \n",
    "        for page_data in md_read:\n",
    "            page_number = page_data.get('metadata', {}).get('page', None)\n",
    "            text = clean_text(normalize_string(page_data['text']))\n",
    "            metadata = {\n",
    "                \"Source_path\": pdf_path,\n",
    "                \"page_number\": page_number,\n",
    "                \"total_pages\": total_pages,\n",
    "                \"tables\": page_data.get('tables', None),\n",
    "            }\n",
    "            \n",
    "            documents.append(Document(page_content=text, metadata=metadata))\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to process PDF with pymupdf4llm: {e}\")\n",
    "\n",
    "    return documents\n",
    "\n",
    "def chunk_documents(docs):\n",
    "    markdown_headers = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "        (\"####\", \"Header 4\")\n",
    "    ]\n",
    "    \n",
    "    # 마크다운 스플리터 설정\n",
    "    markdown_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators = [\n",
    "                # First, try to split along Markdown headings (starting with level 2)\n",
    "                \"\\n#{1,6} \",\n",
    "                # Note the alternative syntax for headings (below) is not handled here\n",
    "                # Heading level 2\n",
    "                # ---------------\n",
    "                # End of code block\n",
    "                \"```\\n\",\n",
    "                # Horizontal lines\n",
    "                \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
    "                \"\\n---+\\n\",\n",
    "                \"\\n___+\\n\",\n",
    "                # Note that this splitter doesn't handle horizontal lines defined\n",
    "                # by *three or more* of ***, ---, or ___, but this is not handled\n",
    "                \"\\n\\n\",\n",
    "                \"\\n\",\n",
    "                \" \",\n",
    "                \"\",\n",
    "            ],\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "    )\n",
    "    \n",
    "    chunks = []\n",
    "    for doc in docs:\n",
    "        text = doc.page_content\n",
    "        metadata = doc.metadata\n",
    "        md_header_splits = markdown_splitter.split_text(text)\n",
    "        for md_split in md_header_splits:   \n",
    "            # 테이블이 있는 페이지는 청크로 분할하지 않음\n",
    "            chunks.append(Document(page_content=md_split, metadata = metadata))\n",
    "    return chunks\n",
    "\n",
    "def make_db(df):\n",
    "    documents = []\n",
    "    chunks = []\n",
    "    pdf_files = df['Source_path'].unique()\n",
    "    for pdf_file in tqdm(pdf_files):\n",
    "        # 문서 로드\n",
    "        documents.extend(get_docs(pdf_file))\n",
    "        # 청크 생성\n",
    "        # chunks.extend(chunk_documents(documents))\n",
    "    print(f\"Total number of documents: {len(documents)}\")\n",
    "    \n",
    "    # print(f\"Total number of chunks: {len(chunks)}\")\n",
    "\n",
    "    faiss = FAISS.from_documents(documents, embedding=get_embedding())\n",
    "    return faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fewshot_db(df):\n",
    "    df = df.drop('SAMPLE_ID', axis=1)\n",
    "    df = df.drop('Source_path', axis=1)\n",
    "    df = df.to_dict(orient='records')\n",
    "    print(\"Loaded Fewshot Set:\", len(df))\n",
    "    to_vectorize = [\"\\n\\n\".join(normalize_string(value) for value in example.values()) for example in df]\n",
    "    faiss = FAISS.from_texts(to_vectorize, embedding=get_embedding())\n",
    "    # bm = BM25Retriever.from_texts(to_vectorize)\n",
    "    # knn = KNNRetriever.from_texts(to_vectorize, embeddings=get_embedding())\n",
    "    return faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test_df = pd.read_csv('test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n",
    "    context = \"\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        #context += f\"Document {i+1}\\n\"\n",
    "        doc.page_content = doc.page_content.replace(\"{\", \"(\")\n",
    "        doc.page_content = doc.page_content.replace(\"}\", \")\")\n",
    "        \n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.03s/it]\n"
     ]
    }
   ],
   "source": [
    "def setup_llm_pipeline(model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"):\n",
    "    # 토크나이저 로드 및 설정\n",
    "        # 양자화 설정 적용\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config,low_cpu_mem_usage=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    text_generation_pipeline = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=1024,\n",
    "        eos_token_id = terminators,\n",
    "        pad_token_id = tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "    return llm\n",
    "# ghost-x/ghost-8b-beta-1608\n",
    "# OpenBuddy/openbuddy-llama3.1-8b-v22.3-131k\n",
    "llm = setup_llm_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def calculate_f1_score(true_sentence, predicted_sentence, sum_mode=True):\n",
    "\n",
    "    #공백 제거\n",
    "    true_sentence = ''.join(true_sentence.split())\n",
    "    predicted_sentence = ''.join(predicted_sentence.split())\n",
    "    \n",
    "    true_counter = Counter(true_sentence)\n",
    "    predicted_counter = Counter(predicted_sentence)\n",
    "\n",
    "    #문자가 등장한 개수도 고려\n",
    "    if sum_mode:\n",
    "        true_positive = sum((true_counter & predicted_counter).values())\n",
    "        predicted_positive = sum(predicted_counter.values())\n",
    "        actual_positive = sum(true_counter.values())\n",
    "\n",
    "    #문자 자체가 있는 것에 focus를 맞춤\n",
    "    else:\n",
    "        true_positive = len((true_counter & predicted_counter).values())\n",
    "        predicted_positive = len(predicted_counter.values())\n",
    "        actual_positive = len(true_counter.values())\n",
    "\n",
    "    #f1 score 계산\n",
    "    precision = true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    recall = true_positive / actual_positive if actual_positive > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def calculate_average_f1_score(true_sentences, predicted_sentences):\n",
    "    \n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1_score = 0\n",
    "    \n",
    "    for true_sentence, predicted_sentence in zip(true_sentences, predicted_sentences):\n",
    "        precision, recall, f1_score = calculate_f1_score(true_sentence, predicted_sentence)\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1_score += f1_score\n",
    "    \n",
    "    avg_precision = total_precision / len(true_sentences)\n",
    "    avg_recall = total_recall / len(true_sentences)\n",
    "    avg_f1_score = total_f1_score / len(true_sentences)\n",
    "    \n",
    "    return {\n",
    "        'average_precision': avg_precision,\n",
    "        'average_recall': avg_recall,\n",
    "        'average_f1_score': avg_f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_answer(response):\n",
    "    # AI: 로 시작하는 줄을 찾아 그 이후의 텍스트만 추출\n",
    "    lines = response.split('\\n')\n",
    "    for line in lines:\n",
    "        line = line.replace('**', '')\n",
    "        if line.startswith('Answer:'):\n",
    "            return line.replace('Answer:', '').strip()\n",
    "        if line.startswith('assistant:'):\n",
    "            return line.replace('assistant:', '').strip()\n",
    "    return response.strip()  # AI: 를 찾지 못한 경우 전체 응답을 정리해서 반환\n",
    "\n",
    "def equal_path(contexts, source_path):\n",
    "    adjusted_docs = []\n",
    "    for doc in contexts:\n",
    "        if doc.metadata['Source_path'] == source_path:\n",
    "            adjusted_docs.append(doc)\n",
    "    return adjusted_docs\n",
    "\n",
    "def rerun(question,context,answer,llm,num_repeat):\n",
    "    full_template = \"<|begin_of_text|>\"\n",
    "    full_template += \"\"\"<|start_header_id|>system<|end_header_id|>당신은 이전 답변을 검증하는 챗봇입니다. 질문과 문맥, 이전 답변을 참고해서 지시사항을 따르세요. 지시사항을 따를 때 서론 없이 출력하세요.<|eot_id|>\"\"\"\n",
    "    full_template += f\"\"\"<|start_header_id|>user<|end_header_id|>Question: {question} \\n\\nContexts: {context} \\n\\nPrevious Answer: {answer} \\n\\n\"\"\"\n",
    "    full_template += \"\"\"{input}<|eot_id|>\"\"\"\n",
    "    full_template += \"\"\"<|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(template=full_template)\n",
    "    chain = (\n",
    "    {\n",
    "        \"input\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    )\n",
    "    return chain.invoke(\"핵심 단어들을 바탕으로, 한 문장으로 요약하세요. 만약 한 문장이라면 그대로 출력하세요.\")\n",
    "    \n",
    "def run(faiss,dataset,llm,k=2,verbose=False):\n",
    "    results = []\n",
    "    source_path = dataset.iloc[0]['Source_path']\n",
    "    docs = faiss.similarity_search(\n",
    "        query=\"\",  # 유사도 기반이 아닌 메타데이터 필터링만 사용하므로 query는 빈 값으로\n",
    "        filter={\"Source_path\": source_path},\n",
    "        k = 99,\n",
    "        fetch_k = 20000\n",
    "        )\n",
    "    buff_faiss = FAISS.from_documents(docs, embedding=get_embedding())\n",
    "    faiss_retriever = buff_faiss.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": k})\n",
    "    knn_retriever = KNNRetriever.from_documents(docs, embeddings=get_embedding())\n",
    "    knn_retriever.k = k\n",
    "    bm_retriever = OktBM25Retriever.from_documents(docs)\n",
    "    bm_retriever.k = k\n",
    "    ensemble_retriever = EnsembleRetriever(retrievers=[faiss_retriever, knn_retriever,bm_retriever], weight=[0.4, 0.3, 0.3])\n",
    "    \n",
    "    for i, row in (dataset.iterrows()):\n",
    "        if source_path != row['Source_path']:   \n",
    "            source_path = row['Source_path']\n",
    "            docs = faiss.similarity_searchfaiss.similarity_search(\n",
    "                query=\"\",  # 유사도 기반이 아닌 메타데이터 필터링만 사용하므로 query는 빈 값으로\n",
    "                filter={\"Source_path\": source_path},\n",
    "                k = 99,\n",
    "                fetch_k = 20000\n",
    "                )\n",
    "            buff_faiss = FAISS.from_documents(docs, embedding=get_embedding())\n",
    "            faiss_retriever = buff_faiss.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": k})\n",
    "            knn_retriever = KNNRetriever.from_documents(docs, embeddings=get_embedding())\n",
    "            knn_retriever.k = k\n",
    "            bm_retriever = OktBM25Retriever.from_documents(docs)\n",
    "            bm_retriever.k = k\n",
    "            ensemble_retriever = EnsembleRetriever(retrievers=[faiss_retriever, knn_retriever,bm_retriever], weight=[0.4, 0.3, 0.3])\n",
    "            \n",
    "        full_template = \"<|begin_of_text|>\"\n",
    "        full_template += \"\"\"<|start_header_id|>system<|end_header_id|>\n",
    "당신은 유용한 금융 정보 QnA 챗봇입니다.\n",
    "질문을 차근차근 생각하고, 답변 시 반드시 문맥 정보를 활용해야합니다. \n",
    "객관적이고 공식적인 문체를 사용하세요.\n",
    "서론 없이 핵심 내용을 한 문장으로 작성해주세요. \n",
    "<|eot_id|>\n",
    "\"\"\"\n",
    "        question = row['Question']          \n",
    "        # full_template += \"\"\" \"\"\"\n",
    "        contexts = ensemble_retriever.invoke(normalize_string(question))\n",
    "        # contexts = equal_path(contexts,row['Source_path'])\n",
    "        contexts = format_docs(contexts)\n",
    "        full_template += \"\"\"<|start_header_id|>user<|end_header_id|>Question: {input}\\n\\n\"\"\"\n",
    "        full_template += f\"\"\"Contexts: {contexts}<|eot_id|>\"\"\"\n",
    "        full_template += \"\"\"<|start_header_id|>assistant<|end_header_id>\"\"\"\n",
    "        \n",
    "        prompt = PromptTemplate(template=full_template, input_variables=[\"input\"])\n",
    "        qa_chain = (\n",
    "        {\n",
    "            \"input\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        answer = qa_chain.invoke(input=question)\n",
    "        answer = extract_answer(answer)\n",
    "        lines = answer.split('\\n')\n",
    "        if  len(lines) > 1:\n",
    "            previous = answer\n",
    "            try:\n",
    "                before = calculate_f1_score(row['Answer'],answer)[2]\n",
    "            except:\n",
    "                before = None\n",
    "            answer = rerun(question=question,\n",
    "                           context=contexts,\n",
    "                           answer=answer,\n",
    "                           llm=llm,\n",
    "                           num_repeat=1)\n",
    "        answer = extract_answer(answer)\n",
    "        results.append({\n",
    "            \"Question\": question,\n",
    "            \"Answer\": answer,\n",
    "            \"Source\": row['Source']\n",
    "        })\n",
    "        if verbose:\n",
    "            print(f\"{i}/{len(dataset)}\")\n",
    "            print(\"Question: \", question, end=\" | \")\n",
    "            print(\"Context Number |\",len(contexts))\n",
    "            try:\n",
    "                print(calculate_f1_score(row['Answer'],answer)[2],end=\" | \")\n",
    "            except:\n",
    "                pass\n",
    "            print(\"Answer: \", results[-1]['Answer'])\n",
    "            try:\n",
    "                print(\"Before: \",before,\" | \",previous)  \n",
    "                \n",
    "                previous = None\n",
    "                before = None\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                print(\"REAL Answer: \",row['Answer'])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            print()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 케이폴드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:653: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/124\n",
      "Question:  2024년 중앙정부의 예산 지출은 어떻게 구성되어 있나요? | Context Number | 6447\n",
      "0.7863247863247863 | Answer:  2024년 중앙정부의 예산 지출은 총 656.6조원이며, 일반회계 356.5조원, 특별회계 81.7조원, 기금 218.4조원으로 구성됩니다.\n",
      "REAL Answer:  2024년 중앙정부의 예산 지출은 일반회계 356.5조원, 21개 특별회계 81.7조원으로 구성되어 있습니다.\n",
      "\n",
      "4/124\n",
      "Question:  2024년 총수입은 얼마이며, 예산수입과 기금수입은 각각 몇 조원인가요? | Context Number | 6745\n",
      "1.0 | Answer:  2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216.7조원입니다.\n",
      "REAL Answer:  2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216.7조원입니다.\n",
      "\n",
      "6/124\n",
      "Question:  2024년의 기금수입은 어떻게 구성되어 있나요? | Context Number | 6144\n",
      "0.6363636363636364 | Answer:  2024년 총수입은 612.2조원이며, 예산수입 395.5조원, 기금수입 216.7조원으로 구성되며, 기금수입은 사회보장기여금 92.3조원, 융자원금회수 33.8조원, 기타 90.6조원으로 구성됩니다.\n",
      "REAL Answer:  2024년도 기금수입은 사회보장성기금 92.3조원, 경상이전수입 39.6조원, 기타 84.7조원으로 구성되어 있습니다.\n",
      "\n",
      "11/124\n",
      "Question:  2024년 총지출 기준 예산의 일반회계와 특별회계의 비중이 각각 얼마인가? | Context Number | 5615\n",
      "0.8888888888888888 | Answer:  2024년 총지출 기준 예산의 일반회계와 특별회계의 비중은 각각 54.3%와 12.4%입니다.\n",
      "REAL Answer:  2024년 총지출 중 일반회계와 특별회계의 비중은 각각 54.3%와 12.4%이다.\n",
      "\n",
      "19/124\n",
      "Question:  2020년 결산 기준, 연구개발비 중 개발연구 규모는 몇 억원인가? | Context Number | 7757\n",
      "0.875 | Answer:  2020년 결산 기준, 연구개발비 중 개발연구 규모는 178억원입니다.\n",
      "REAL Answer:  2020년 결산 기준 연구개발비 중 개발연구 규모는 78754억원이다.\n",
      "\n",
      "20/124\n",
      "Question:  세출예산현액이란? | Context Number | 4492\n",
      "0.8965517241379309 | Answer:  세출예산현액이란 예산 확정 후 전년도로부터의 이월액, 추경 편성, 기금운용계획 변경, 이용･전용, 예비비 증액 등을 반영한 것으로, 실제 지출할 수 있는 한도액을 의미합니다.\n",
      "REAL Answer:  예산 확정 후 전년도로부터의 이월액 반영, 추경 편성, 기금운용계획 변경, 이용・전용, 예비비 증액 등을 반영한 것으로, 실제 지출할 수 있는 한도액을 의미한다.\n",
      "\n",
      "23/124\n",
      "Question:  2022년 기준, 일반회계, 특별회계, 기금의 집행률은? | Context Number | 8599\n",
      "0.896551724137931 | Answer:  2022년 기준, 일반회계, 특별회계, 기금의 집행률은 각각 97.3%, 94.7%, 97.6%입니다.\n",
      "REAL Answer:  2022년 기준, 집행률은 일반회계 97.3%, 특별회계 94.7%, 기금 97.6%\n",
      "\n",
      "25/124\n",
      "Question:  2022년 결산 기준으로 사회보험성기금의 이월금 규모는 몇 억원인가요? | Context Number | 8650\n",
      "0.3636363636363636 | Answer:  2022년 결산 기준으로 사회보험성기금의 이월금은 약 4,900억원입니다.\n",
      "REAL Answer:  223억원입니다.\n",
      "\n",
      "27/124\n",
      "Question:  2022년 기준으로 국내총생산 대비 일반정부부채와 공공부문 부채의 비중은 각각 몇 퍼센트인가? | Context Number | 5218\n",
      "0.6913580246913581 | Answer:  2022년 기준으로 국내 총생산 대비 일반정부부채는 53.5%, 공공부문 부채는 73.5%입니다.\n",
      "REAL Answer:  일반정부부채(D2)는 53.5%, 공공부문 부채(D3)는 73.5%이다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/124\n",
      "Question:  2007년 시행된 국가재정법에서 추경 편성 사유로 명시된 사항은 무엇인가? | Context Number | 6706\n",
      "0.28735632183908044 | Answer:  추가경정 예산은 예산 성립 후 법률로 인정되는 사유로 인해 예산에 추가 또는 변경을 가한 예산을 의미합니다.\n",
      "REAL Answer:  국가재정법에서 추경 편성 사유로 명시된 사항은 전쟁이나 대규모 재해가 발생한 경우, 경기침체, 대량 실업, 남북 관계의 변화, 경제협력과 같은 대내외 여건에 중대한 변화가 발생하였거나 발생할 우려가 있는 경우, 법령에 따라 국가가 지급하여야 하는 지출이 발생하거나 증가하는 경우에 한정되어 있습니다.\n",
      "\n",
      "41/124\n",
      "Question:  2024년 교육재정 교부금의 규모는 얼마이고, 전년 대비 추이는 어떠한가? | Context Number | 6958\n",
      "0.9166666666666667 | Answer:  2024년 교육재정 교부금은 73.0조원이며, 전년 대비 8.9% 감소했습니다.\n",
      "REAL Answer:  2024년 교육재정교부금은 73.0조원이며 전년 대비 8.9% 감소하였다.\n",
      "\n",
      "43/124\n",
      "Question:  2024년에 교육재정교부금에서 유아교육비 및 보육료 지원에 할당된 비중은? | Context Number | 12343\n",
      "0.1777777777777778 | Answer:  2024년 교육재정교부금에서 유아교육비 및 보육료 지원에 할당된 비중은 1.6%입니다.\n",
      "REAL Answer:  4.40%\n",
      "\n",
      "44/124\n",
      "Question:  교육재정 교부금이란? | Context Number | 5011\n",
      "0.8522727272727273 | Answer:  1. 교육재정 교부금은 국가가 교육기관 및 교육행정기관 경비를 지원하기 위해 일반회계 보통･특별교부금, 고교 무상교육 증액분, 특별회계 유아교육비･보육료 지원 교부금 등 4가지로 구성됩니다.\n",
      "REAL Answer:  교육의 균형발전을 위해 교육기관 및 교육행정기관 경비를 국가가 교부하는 일반지원금으로, 일반회계 보통・특별교부금, 고교 무상교육 증액분, 특별회계 유아교육비・보육료 지원 교부금 등 4가지로 구성되었다.\n",
      "\n",
      "46/124\n",
      "Question:  특별회계 국고보조금 중 국가균형발전특별회계에서 얼마가 포괄보조금으로 지출되는가? | Context Number | 6818\n",
      "0.6896551724137931 | Answer:  2024년 기준, 국가균형발전특별회계에서 지출되는 포괄보조금은 10.0조원입니다.\n",
      "REAL Answer:  특별회계 국고보조금 18.2조원 중 10.0조원이 국가균형발전특별회계에서 지출되는 포괄보조금이다.\n",
      "\n",
      "47/124\n",
      "Question:  2024년의 국고보조사업(자치단체 이전)에서 기금 규모는 얼마인가? | Context Number | 7556\n",
      "0.30000000000000004 | Answer:  2024년의 국고보조사업(자치단체 이전)에서 기금 규모는 89.3조원입니다.\n",
      "REAL Answer:  90,247억원으로 10.1%를 차지하고 있다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/124\n",
      "Question:  임신·출산을 희망하는 가구에 어떤 지원이 신규로 이뤄지고 있으며, 고위험 임산부와 미숙아·선천성 이상아의 의료비 지원은 어떻게 이루어지는가? | Context Number | 5163\n",
      "0.7272727272727273 | Answer:  1. 임신·출산을 희망하는 가구에 필수가임력(생식건강) 검진비와 냉동난자를 활용한 보조생식술 비용이 신규로 지원된다.\n",
      "REAL Answer:  임신·출산을 희망하는 가구에는 필수가임력(생식건강) 검진비와 냉동난자를 활용한 보조 생식술 비용을 신규로 지원하며, 고위험 임산부와 미숙아·선천성 이상아의 의료비는 소득수준에 관계없이 지원된다.\n",
      "\n",
      "57/124\n",
      "Question:  2024년 R&D 분야에 대한 재정투자 규모는 2023년 대비 얼마나 감소했으며, 어떤 분야의 국가전략기술 투자를 확대할 계획인가? | Context Number | 6341\n",
      "0.7049180327868853 | Answer:  2024 년 R&D 분야에 대한 재정투자 규모는 2023 년 대비 △9.5% 감소한 26.5 조원이다.\n",
      "REAL Answer:  2024년 R&D 분야에 대한 재정투자 규모는 2023년 대비 9.5% 감소한 26.5조원이며, AI·바이오·반도체 등의 분야에 대한 국가전략기술 투자를 확대할 계획입니다.\n",
      "\n",
      "58/124\n",
      "Question:  우주산업 클러스터 삼각체제 구축사업의 목표와 국가 우주산업 육성 거점 지역은 어디인가? | Context Number | 6084\n",
      "0.38016528925619836 | Answer:  국가 우주산업 육성 거점 지역은 전남, 경남, 대전입니다.\n",
      "REAL Answer:  우주산업 클러스터 삼각체제 구축사업은 우주경제 시대 대비 민간 주도 우주개발 역량 강화 및 자생적 생태계 조성을 위해 핵심 인프라를 구축하는 플래그십 프로젝트이며, 전남, 경남, 대전을 국가 우주산업 육성 거점으로 지정했다.\n",
      "\n",
      "62/124\n",
      "Question:  2024년도 공공질서 및 안전 분야의 재정투자는 전년도 대비 어떻게 변화했으며, 어떤 분야에 특히 재정투자가 집중되었는가? | Context Number | 3415\n",
      "0.5890410958904109 | Answer:  2024 년 공공질서 및 안전 분야의 재정투자는 전년도 대비 6.5% 증가하여 24.4조원으로 집행된다.\n",
      "REAL Answer:  2024년도 공공질서 및 안전 분야의 재정투자는 24.4조원으로 2023년도 22.9조원 대비 6.5% 증가하였으며, 마약·스토킹 등 민생침해범죄 예방·대응과 재난·안전 사고에 대한 근본적 예방에 집중적으로 투자하였다.\n",
      "\n",
      "77/124\n",
      "Question:  예산 증감률이 가장 높은 분야는 무엇인가요? | Context Number | 3653\n",
      "0.4761904761904762 | Answer:  2024년 예산에서 예산 증감률이 가장 높은 분야는 보건·복지·고용 분야입니다.\n",
      "REAL Answer:  외교·통일 분야가 17.7%로 예산 증감률이 가장 높습니다.\n",
      "\n",
      "98/124\n",
      "Question:  하수관로정비 사업 예산은 2023년 대비 2024년에 얼마나 증가했는가? | Context Number | 4135\n",
      "0.7551020408163266 | Answer:  하수관로정비 사업 예산은 2023년 대비 2024년에 1조 2,816억원으로 증가했습니다.\n",
      "REAL Answer:  하수관로정비 사업 예산은 2023년 9,531억원에서 2024년 1조 2,816억원으로 증가하여 34.5% 증가하였다.\n",
      "\n",
      "103/124\n",
      "Question:  국회의 입법활동 및 의정활동을 지원하기 위해 어떤 활동들이 실시되고 있는가? | Context Number | 5763\n",
      "0.28378378378378377 | Answer:  국회 입법 및 의정활동을 지원하기 위해 다양한 활동이 실시되고 있습니다. 국회는 원활한 입법활동을 지원하기 위해 2024년 1조 6,430억원의 예산을 배정했습니다. 이 중에서 국회의원 선거관리 정당보조금 선거보전금 정보기반보호 강화 입법정보화에 대한 예산은 16,430억원으로 42.4% 증가했습니다. 또한, 정부자원관리 부문에서는 코로나 한시 지원사업 종료로 지출 증가를 억제하고, 디지털 플랫폼 정부 구현에 투자하여 국민이 체감할 수 있는 편익을 증진하기 위해 1조 833억원의 예산을 배정했습니다.\n",
      "REAL Answer:  국회 정책세미나·토론회·간담회 실시간 생중계 시스템 구축, SNS 영상 제작 지원 및 의정활동 안내 문자메시지 발송 등을 통해 국회 입법활동 및 의정활동을 지원하고 있다.\n",
      "\n",
      "108/124\n",
      "Question:  국가첨단전략산업 특화단지에 대한 지원 계획은 어떻게 되어 있는가? | Context Number | 4217\n",
      "0.3076923076923077 | Answer:  국가첨단전략산업 특화단지는 2023년 용인·평택반도체 특화단지에 1,000억원을 지원하고, 2024년 포항 이차전지 특화단지에 154억원, 구미반도체 특화단지에 200억원, 울산 이차전지 특화단지에 37.5억원을 지원한다.\n",
      "Before:  0.1941747572815534  |  국가첨단전략산업 특화단지에 대한 지원 계획은 다음과 같습니다.\n",
      "\n",
      "1.  반도체 등 첨단산업 인프라 지원: 전력·용수 등 핵심 기반시설에 대한 국비 지원을 제도화한다. 2023년에 용인·평택반도체 특화단지에 1,000억원을 지원하고, 2024년에는 포항 이차전지 특화단지에 154억원, 구미반도체 특화단지에 200억원, 울산 이차전지 특화단지에 37.5억원을 지원한다.\n",
      "\n",
      "2.  기술 혁신을 위한 저리 융자: 기술 혁신을 위한 저리 융자를 신설하여 2024년 900억원을 지원한다.\n",
      "\n",
      "3.  첨단산업 인력 양성: 반도체 등 첨단산업 특성화대학을 8개교에서 21개교로 확대하고, 배터리 아카데미를 신설하여 첨단인재 양성 예산을 1.6조원에서 1.9조원으로 확대한다.\n",
      "\n",
      "4.  우주산업 클러스터 삼각체제 구축: 우주경제 시대 대비 민간 주도 우주개발 역량 강화 및 자생적 생태계 조성을 위해 핵심 인프라를 구축하는 플래그십 프로젝트이다.\n",
      "REAL Answer:  국가첨단전략산업 특화단지에 대한 저리융자, 기반시설 구축, 현장 맞춤형 실무교육 등을 종합적으로 지원할 계획이다.\n",
      "\n",
      "109/124\n",
      "Question:  가족돌봄청년을 위해 신규로 지원되는 혜택은 무엇인가요? | Context Number | 5865\n",
      "0.4077669902912621 | Answer:  가족돌봄청년에게는 학습, 신체·정신 건강을 위한 자기돌봄비를 분기당 50만원씩 최대 2년간 지원하는 서비스가 신규로 제공됩니다.\n",
      "Before:  0.338235294117647  |  가족돌봄청년에게 자기돌봄비를 지원하는 부분에 대해 답변해드리겠습니다.\n",
      "\n",
      "가족돌봄청년에게는 학습, 신체·정신 건강을 위한 자기돌봄비를 분기당 50만원씩 최대 2년간 지원하는 서비스가 신규로 제공됩니다.\n",
      "REAL Answer:  자기돌봄비(연200만원)와 돌봄코디네이터를 통한 밀착 사례관리 및 자조모임 등을 신규로 지원한다.\n",
      "\n",
      "110/124\n",
      "Question:  의료 분야에 대한 국고 지원이 어떻게 확대되고 있는가? | Context Number | 5778\n",
      "0.41891891891891886 | Answer:  국고 지원을 통한 의료 분야의 투자 확대는 건강보험과 노인장기요양보험에 대한 국고 지원을 확대하여 취약계층 의료기반 확충을 위해 암검진비 지원과 재활병원 건립을 추진하고 필수의료에 대한 투자를 강화하여 광역응급의료상황실 신설, 닥터헬기 및 닥터카 확충, 소아암 거점병원 및 소아전문응급의료센터 확충을 포함하여 어린이 환자 치료에 대한 투자를 대폭 강화하고 지역 간 의료격차를 해소하고 지역 완결적 의료 체계를 확립하기 위한 투자를 지속 확대합니다.\n",
      "Before:  0.36929460580912865  |  국고 지원을 통한 의료 분야의 투자 확대는 다음과 같이 진행되고 있습니다.\n",
      "\n",
      "1. 건강보험과 노인장기요양보험에 대한 국고 지원을 확대하여, 취약계층 의료기반 확충을 위해 암검진비 지원과 재활병원 건립 등도 추진하고 있습니다.\n",
      "2. 필수의료에 대한 투자도 강화하여, 광역응급의료상황실 신설, 닥터헬기 및 닥터카 확충, 소아암 거점병원 및 소아전문응급의료센터 확충 등이 있습니다.\n",
      "3. 어린이 환자 치료에 대한 투자도 대폭 강화하여, 어린이 공공전문진료센터와 소아전문응급의료센터 확충, 소아암 거점병원 신설, 야간·휴일 진료센터와 24시간 소아상담센터 신설, 소아청소년과 전공의 수련수당 지원 등이 있습니다.\n",
      "4. 지역 간 의료격차를 해소하고 지역 완결적 의료 체계를 확립하기 위한 투자도 지속 확대하여, 국립 대병원과 지방 의료원 확대, 책임 의료기관을 중심으로 지역 내 의료기관 간 협력 체계 강화, 의료 취약 지 주민들을 위한 분만실 설치 및 소아청소년과 운영 지원 등이 있습니다.\n",
      "REAL Answer:  달빛어린이병원(45개소)에 대해 국고 지원에 착수하고, 소아환자에게 24시간 의료상담을 제공하는 24시간 상담센터를 신설하고, 어린이 공공전문진료센터와 소아암 전문거점병원을 확충하고, 전공의 수련수당도 신규 지원하고 있다.\n",
      "\n",
      "113/124\n",
      "Question:  2023년 기획재정부의 총세입예산은 얼마인가요? | Context Number | 4060\n",
      "0.16666666666666669 | Answer:  2024 년 나라살림 예산 개에서는 총수입은 △2.2% 감소한 612.2조원으로 예상되며, 이 중 예산수입은 △7.0% 감소한 395.5조원으로 예상된다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  438,715,377백만원\n",
      "\n",
      "114/124\n",
      "Question:  기초생활보장제도 4대 급여의 예산 규모는 2023년 대비 2024년에 어떻게 변화되는가? | Context Number | 3635\n",
      "0.6744186046511628 | Answer:  기초생활보장제도 4대 급여의 예산 규모는 2023년 17.8조원에서 2024년 19.4조원으로 1.6조원 증가합니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2023년 17.8조원에서 2024년 19.4조원으로 확대된다.\n",
      "\n",
      "120/124\n",
      "Question:  교육 분야 재정투자 계획에 따르면 2024년에 유아및초중등교육 분야의 예산이 2023년에 비해 어떻게 변하는가? | Context Number | 4466\n",
      "0.7951807228915662 | Answer:  2024년 유아 및 초·중등교육 분야의 예산은 2023년보다 8.9% 감소한다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2024년에 유아및초중등교육 분야의 예산은 737,290억원으로 2023년 대비 8.9% 감소한다.\n",
      "\n",
      "125/124\n",
      "Question:  문화예술 부문의 총 예산은 어떻게 변화했는가? | Context Number | 4815\n",
      "0.8163265306122448 | Answer:  2024년 문화예술 부문 예산은 4조 628억원으로 2023년 4조 22억원보다 1.5% 증가했습니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  문화예술 부문의 총 예산은 2023년 40,022억원에서 2024년 40,628억원으로 1.5% 증가하였다.\n",
      "\n",
      "127/124\n",
      "Question:  2024년에 산업혁신지원 부문의 총 예산은 얼마이며, 전년 대비 어떤 증감률을 보였는가? | Context Number | 4892\n",
      "0.5609756097560975 | Answer:  2024 년 국방 분야 부문 예산은 2023 년 대비 4.2% 증가한 59.4 조원입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2024년에 산업혁신지원 부문의 총 예산은 63,146억원이며, 전년 대비 5.1% 증가하였다.\n",
      "\n",
      "129/124\n",
      "Question:  산업혁신지원 부문 주요 변동 내역에서 2024년에 산업혁신인재성장지원 부문의 예산은 얼마이며, 전년 대비 어떤 증감률을 보였는가? | Context Number | 4634\n",
      "0.8043478260869565 | Answer:  2024년 산업혁신지원 부문의 예산은 63,146억원이며, 전년 대비 5.1% 증가한 금액입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2024년에 산업혁신인재성장지원 부문의 예산은 1,575억원이며, 전년 대비 16.0% 증가하였다.\n",
      "\n",
      "136/124\n",
      "Question:  외교·통일 분야 재정투자 계획에서 2024년 외교·통상 부문 예산은 2023년 대비 얼마나 증가했는가? | Context Number | 3938\n",
      "0.2857142857142857 | Answer:  2024년 외교·통일 분야 재정투자 계획에서 2024년 외교·통상 부문 예산은 2023년 대비 29.8% 증가했습니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  14,736억원 증가하여 29.8% 증가하였다.\n",
      "\n",
      "137/124\n",
      "Question:  재정투자 계획에서 2023년 대비 2024년에 가장 큰 증가율을 보인 분야는 무엇인가요? | Context Number | 4397\n",
      "0.5360824742268041 | Answer:  2024년 SOC 분야 재정투자 규모는 26.4조원으로 2023년 25.0조원 대비 5.8% 증가하여 역대 최대 규모의 예산을 지원한다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2023년 대비 2024년에 22.1%의 증가율을 보인 재정·금융 분야입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "\n",
    "# weight = [0.3,0.3,0.4]\n",
    "# train_faiss_db,knn_retriever ,train_bm_retrievier = make_db(train_df) \n",
    "\n",
    "# train_k = 3\n",
    "# train_bm_retrievier.k = train_k\n",
    "# knn_retriever.k = train_k\n",
    "# train_faiss_retriever = train_faiss_db.as_retriever(search_type=\"mmr\",search_kwargs={'k':train_k} )\n",
    "# train_ensemble_retriever = EnsembleRetriever(\n",
    "#     retrievers=[train_bm_retrievier, knn_retriever,train_faiss_retriever], weights=weight , search_kwargs={'k':train_k}\n",
    "# )\n",
    "\n",
    "\n",
    "# fewshot_k = 3\n",
    "\n",
    "k_folds = 4\n",
    "fold_results = []\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=52)\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_df)):\n",
    "    fold_result = []\n",
    "    train_set = train_df.iloc[train_index]\n",
    "    val_set = train_df.iloc[val_index]\n",
    "\n",
    "    faiss = make_db(val_set)\n",
    "\n",
    "    pred = run(faiss,val_set, llm, verbose=True)\n",
    "    result = pd.DataFrame()\n",
    "    result['pred'] = [result['Answer'] for result in pred]\n",
    "    val_set.index = range(len(val_set))\n",
    "    result['gt'] = val_set['Answer']\n",
    "        \n",
    "    result = calculate_average_f1_score(result['gt'], result['pred'])\n",
    "    print(result)\n",
    "    fold_results.append(result)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from save_module import save\n",
    "\n",
    "\n",
    "# weight = [0.5,0.5]\n",
    "# test_faiss_db, test_bm_retrievier = make_db(test_df)\n",
    "\n",
    "# test_k = 3\n",
    "# test_bm_retrievier.k = test_k\n",
    "# #test_knn_retriever.k = test_k\n",
    "# test_faiss_retriever = test_faiss_db.as_retriever(search_type=\"mmr\",search_kwargs={'k':test_k} )\n",
    "# test_ensemble_retriever = EnsembleRetriever(\n",
    "#     retrievers=[test_bm_retrievier, test_faiss_retriever], weights=weight\n",
    "# )\n",
    "\n",
    "\n",
    "# results = run(test_ensemble_retriever, test_df, llm, verbose=True)\n",
    "# save(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
