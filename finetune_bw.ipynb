{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "from faiss_module import make_db\n",
    "import pandas as pd\n",
    "def format_docs(docs):\n",
    "    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n",
    "    context = \"\"\n",
    "    # context = \"<|start_header_id|>system<|end_header_id|>\\nContext\\n\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        #context += f\"Document {i+1}\\n\"\n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    # context += \"<|eot_id|>\"\n",
    "    return context \n",
    "\n",
    "def format_docs_wnum(docs):\n",
    "    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n",
    "    context = \"\"\n",
    "    # context = \"<|start_header_id|>system<|end_header_id|>\\nContext\\n\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        context += f\"Document {i+1}\\n\"\n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    # context += \"<|eot_id|>\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파인튜닝 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS DB from: ./train_faiss_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:796: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.76\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_db = make_db(train_df,'./train_faiss_db')\n",
    "answer_list = []\n",
    "context_list = []\n",
    "context_list_wnum = []\n",
    "for i, entry in enumerate(train_df.to_dict(orient='records')):\n",
    "    question = entry['Question']\n",
    "    answer = entry['Answer']+\"<|eot_id|>\"\n",
    "    # print(question)\n",
    "    # print(answer)\n",
    "    train_retriever = train_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                search_kwargs={'filter': {'source':entry['Source_path']},'score_threshold': 0.76,'k':3})\n",
    "    docs = train_retriever.invoke(question)\n",
    "    if len(docs) == 0:\n",
    "        context_list.append(\"None\")\n",
    "        context_list_wnum.append(\"None\")\n",
    "    else:\n",
    "        #print(format_docs(docs))\n",
    "        context_list.append(format_docs(docs))\n",
    "        context_list_wnum.append(format_docs_wnum(docs))\n",
    "    answer_list.append(answer)\n",
    "    \n",
    "train_df['Answer'] = answer_list\n",
    "train_df['context'] = context_list\n",
    "train_df['context_wnum'] = context_list_wnum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 생성\n",
    "def create_prompt(row):\n",
    "    context = row['context']\n",
    "    question = row['Question']\n",
    "    prompt  =f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "You are a Korean Q&A Assistant.<|eot_id|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "{context}\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{question}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "train_df['prompt'] = train_df.apply(create_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Source_path</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>context</th>\n",
       "      <th>context_wnum</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>2024년 중앙정부 재정체계는 어떻게 구성되어 있나요?</td>\n",
       "      <td>2024년 중앙정부 재정체계는 예산(일반·특별회계)과 기금으로 구분되며, 2024년...</td>\n",
       "      <td>주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는 예산(일반 ･특별회계...</td>\n",
       "      <td>Document 1\\n주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>2024년 중앙정부의 예산 지출은 어떻게 구성되어 있나요?</td>\n",
       "      <td>2024년 중앙정부의 예산 지출은 일반회계 356.5조원, 21개 특별회계 81.7...</td>\n",
       "      <td>주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는 예산(일반 ･특별회계...</td>\n",
       "      <td>Document 1\\n주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>기금이 예산과 다른 점은?</td>\n",
       "      <td>기금은 예산과 구분되는 재정수단으로서 재정운영의 신축성을 기할 필요가 있을 때, 정...</td>\n",
       "      <td>(1.4) (1.2) (1.5) (3.1) (3.4) (3.1) (3.6) (2.3...</td>\n",
       "      <td>Document 1\\n(1.4) (1.2) (1.5) (3.1) (3.4) (3.1...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>일반회계, 특별회계, 기금 간의 차이점은 무엇인가요?</td>\n",
       "      <td>일반회계는 특정 사업 운영 및 특정 세입으로 특정 세출을 충당하는데 사용되고, 특별...</td>\n",
       "      <td>특별회계 68.0 69.4 69.7 0.3 71.5 66.4 92.9 3.4 1.3...</td>\n",
       "      <td>Document 1\\n특별회계 68.0 69.4 69.7 0.3 71.5 66.4 ...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>2024년 총수입은 얼마이며, 예산수입과 기금수입은 각각 몇 조원인가요?</td>\n",
       "      <td>2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216...</td>\n",
       "      <td>주요 재정통계●\\nⅠ.\\n402재정수입\\n▸2024년도 총수입은 612.2조원이며,...</td>\n",
       "      <td>Document 1\\n주요 재정통계●\\nⅠ.\\n402재정수입\\n▸2024년도 총수입...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SAMPLE_ID               Source                             Source_path  \\\n",
       "0  TRAIN_000  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "1  TRAIN_001  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "2  TRAIN_002  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "3  TRAIN_003  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "4  TRAIN_004  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "\n",
       "                                   Question  \\\n",
       "0            2024년 중앙정부 재정체계는 어떻게 구성되어 있나요?   \n",
       "1          2024년 중앙정부의 예산 지출은 어떻게 구성되어 있나요?   \n",
       "2                            기금이 예산과 다른 점은?   \n",
       "3             일반회계, 특별회계, 기금 간의 차이점은 무엇인가요?   \n",
       "4  2024년 총수입은 얼마이며, 예산수입과 기금수입은 각각 몇 조원인가요?   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  2024년 중앙정부 재정체계는 예산(일반·특별회계)과 기금으로 구분되며, 2024년...   \n",
       "1  2024년 중앙정부의 예산 지출은 일반회계 356.5조원, 21개 특별회계 81.7...   \n",
       "2  기금은 예산과 구분되는 재정수단으로서 재정운영의 신축성을 기할 필요가 있을 때, 정...   \n",
       "3  일반회계는 특정 사업 운영 및 특정 세입으로 특정 세출을 충당하는데 사용되고, 특별...   \n",
       "4  2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216...   \n",
       "\n",
       "                                             context  \\\n",
       "0  주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는 예산(일반 ･특별회계...   \n",
       "1  주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는 예산(일반 ･특별회계...   \n",
       "2  (1.4) (1.2) (1.5) (3.1) (3.4) (3.1) (3.6) (2.3...   \n",
       "3  특별회계 68.0 69.4 69.7 0.3 71.5 66.4 92.9 3.4 1.3...   \n",
       "4  주요 재정통계●\\nⅠ.\\n402재정수입\\n▸2024년도 총수입은 612.2조원이며,...   \n",
       "\n",
       "                                        context_wnum  \\\n",
       "0  Document 1\\n주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는...   \n",
       "1  Document 1\\n주요 재정통계●\\nⅠ.\\n201재정체계\\n▸중앙정부 재정체계는...   \n",
       "2  Document 1\\n(1.4) (1.2) (1.5) (3.1) (3.4) (3.1...   \n",
       "3  Document 1\\n특별회계 68.0 69.4 69.7 0.3 71.5 66.4 ...   \n",
       "4  Document 1\\n주요 재정통계●\\nⅠ.\\n402재정수입\\n▸2024년도 총수입...   \n",
       "\n",
       "                                              prompt  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋을 학습셋과 검증셋으로 나누기\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=52)\n",
    "\n",
    "# train_df는 학습셋, val_df는 검증셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 허깅페이스 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Downloading shards: 100%|██████████| 4/4 [03:52<00:00, 58.25s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.61s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# 양자화 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "#만약 GPU에서 amp(Automatic Mixed Precision)를 지원한다면, fp16 대신 bfloat16을 사용하는 것이 더욱 안정적일 수 있습니다.\n",
    "\n",
    "# 모델 로드 및 양자화 설정 적용\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# LoRA 어댑터 설정 추가\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    inference_mode=False, \n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1\n",
    ")\n",
    "# task_type: 적용할 작업의 유형(GPT 계열의 경우 CAUSAL_LM).\n",
    "# inference_mode: 학습 모드(False) 또는 추론 모드(True).\n",
    "# r: LoRA의 병목 차원.\n",
    "# lora_alpha: 스케일링 인자.\n",
    "# lora_dropout: 드롭아웃 확률.\n",
    "\n",
    "# 모델에 LoRA 어댑터 적용\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# 이후 Trainer를 사용해 파인튜닝을 진행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 396/396 [00:00<00:00, 1781.50 examples/s]\n",
      "Map: 100%|██████████| 396/396 [00:00<00:00, 10040.89 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 2284.19 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 8432.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from datasets import Dataset\n",
    "# 토크나이즈 함수 정의\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['prompt'], padding='max_length', truncation=True, max_length=512)\n",
    "# 모델의 정답 라벨 설정\n",
    "def add_labels(examples):\n",
    "    labels = tokenizer(examples['Answer'], padding='max_length', truncation=True, max_length=512).input_ids\n",
    "    examples['labels'] = labels\n",
    "    return examples\n",
    "\n",
    "\n",
    "# 예시로, 기존 데이터셋 생성\n",
    "train_dataset = Dataset.from_pandas(train_df[['prompt', 'Answer']])\n",
    "val_dataset = Dataset.from_pandas(val_df[['prompt', 'Answer']])\n",
    "\n",
    "# 토크나이징과 라벨 추가는 동일하게 적용\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "train_dataset = train_dataset.map(add_labels, batched=True)\n",
    "\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(add_labels, batched=True)\n",
    "\n",
    "# DistributedSampler 생성\n",
    "train_sampler = DistributedSampler(train_dataset)\n",
    "val_sampler = DistributedSampler(val_dataset)\n",
    "\n",
    "# DataLoader에 샘플러 적용\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=1)\n",
    "val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "# F1 점수를 계산하는 함수\n",
    "def calculate_f1_score(true_sentence, predicted_sentence, sum_mode=True):\n",
    "    true_sentence = ''.join(true_sentence.split())\n",
    "    predicted_sentence = ''.join(predicted_sentence.split())\n",
    "    \n",
    "    true_counter = Counter(true_sentence)\n",
    "    predicted_counter = Counter(predicted_sentence)\n",
    "    \n",
    "    if sum_mode:\n",
    "        true_positive = sum((true_counter & predicted_counter).values())\n",
    "        predicted_positive = sum(predicted_counter.values())\n",
    "        actual_positive = sum(true_counter.values())\n",
    "    else:\n",
    "        true_positive = len((true_counter & predicted_counter).values())\n",
    "        predicted_positive = len(predicted_counter.values())\n",
    "        actual_positive = len(true_counter.values())\n",
    "\n",
    "    precision = true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    recall = true_positive / actual_positive if actual_positive > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "# compute_metrics 함수 정의\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    predicted_sentences = [tokenizer.decode(pred, skip_special_tokens=True) for pred in predictions]\n",
    "    true_sentences = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
    "    \n",
    "    f1_scores = [calculate_f1_score(true, pred)[2] for true, pred in zip(true_sentences, predicted_sentences)]\n",
    "    avg_f1_score = np.mean(f1_scores)\n",
    "    \n",
    "    return {\"f1\": avg_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/peft/peft_model.py\", line 1577, in forward\n    return self.base_model(\n           ^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/peft/tuners/tuners_utils.py\", line 188, in forward\n    return self.model.forward(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/accelerate/hooks.py\", line 169, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py\", line 1189, in forward\n    outputs = self.model(\n              ^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/accelerate/hooks.py\", line 169, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py\", line 1001, in forward\n    layer_outputs = decoder_layer(\n                    ^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/accelerate/hooks.py\", line 169, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py\", line 750, in forward\n    hidden_states = self.mlp(hidden_states)\n                    ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/accelerate/hooks.py\", line 169, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py\", line 309, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/accelerate/hooks.py\", line 169, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/bitsandbytes/nn/modules.py\", line 477, in forward\n    out = bnb.matmul_4bit(x, self.weight.t(), bias=bias, quant_state=self.weight.quant_state)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py\", line 579, in matmul_4bit\n    return MatMul4Bit.apply(A, B, out, bias, quant_state)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/autograd/function.py\", line 574, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py\", line 509, in forward\n    output = torch.nn.functional.linear(A, F.dequantize_4bit(B, quant_state).to(A.dtype).t(), bias)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 11.90 GiB of which 93.62 MiB is free. Including non-PyTorch memory, this process has 11.81 GiB memory in use. Of the allocated memory 11.42 GiB is allocated by PyTorch, and 128.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m\n\u001b[1;32m     17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     19\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 파인튜닝 실행\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llm23_bw/lib/python3.12/site-packages/transformers/trainer.py:1948\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1946\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llm23_bw/lib/python3.12/site-packages/transformers/trainer.py:2289\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2289\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2292\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2295\u001b[0m ):\n\u001b[1;32m   2296\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.conda/envs/llm23_bw/lib/python3.12/site-packages/transformers/trainer.py:3328\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3328\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3330\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3333\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3334\u001b[0m ):\n",
      "File \u001b[0;32m~/.conda/envs/llm23_bw/lib/python3.12/site-packages/transformers/trainer.py:3373\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3372\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3373\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3374\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3375\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:186\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    185\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 186\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:201\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:108\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    106\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 108\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/peft/peft_model.py\", line 1577, in forward\n    return self.base_model(\n           ^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/peft/tuners/tuners_utils.py\", line 188, in forward\n    return self.model.forward(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/accelerate/hooks.py\", line 169, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py\", line 1189, in forward\n    outputs = self.model(\n              ^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/accelerate/hooks.py\", line 169, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py\", line 1001, in forward\n    layer_outputs = decoder_layer(\n                    ^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/accelerate/hooks.py\", line 169, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py\", line 750, in forward\n    hidden_states = self.mlp(hidden_states)\n                    ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/accelerate/hooks.py\", line 169, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py\", line 309, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/accelerate/hooks.py\", line 169, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/bitsandbytes/nn/modules.py\", line 477, in forward\n    out = bnb.matmul_4bit(x, self.weight.t(), bias=bias, quant_state=self.weight.quant_state)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py\", line 579, in matmul_4bit\n    return MatMul4Bit.apply(A, B, out, bias, quant_state)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/torch/autograd/function.py\", line 574, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/MMI24LBW/.conda/envs/llm23_bw/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py\", line 509, in forward\n    output = torch.nn.functional.linear(A, F.dequantize_4bit(B, quant_state).to(A.dtype).t(), bias)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 11.90 GiB of which 93.62 MiB is free. Including non-PyTorch memory, this process has 11.81 GiB memory in use. Of the allocated memory 11.42 GiB is allocated by PyTorch, and 128.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# TrainingArguments 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                  # 결과를 저장할 디렉토리\n",
    "    evaluation_strategy=\"epoch\",             # 에포크마다 평가\n",
    "    per_device_train_batch_size=1,           # GPU 하나당 배치 크기 (DataLoader에서 설정한 것과 일치시킴)\n",
    "    per_device_eval_batch_size=1,            # GPU 하나당 평가 배치 크기 (DataLoader에서 설정한 것과 일치시킴)\n",
    "    num_train_epochs=3,                      # 학습할 에포크 수\n",
    "    learning_rate=5e-5,                      # 학습률\n",
    "    weight_decay=0.01,                       # 가중치 감소\n",
    "    fp16=True,                               # Mixed Precision 사용 (메모리 절약 및 학습 속도 증가)\n",
    "    dataloader_pin_memory=True,              # DataLoader가 메모리 핀 설정을 하도록 설정\n",
    "    dataloader_drop_last=False,              # 배치가 나누어 떨어지지 않을 경우 마지막 배치 드롭 여부\n",
    "    report_to=\"none\",                        # 로깅이나 기타 리포팅 도구를 사용하지 않음 (필요시 변경)\n",
    ")\n",
    "\n",
    "# Trainer 설정\n",
    "trainer = Trainer(\n",
    "    model=model,                             # 학습할 모델\n",
    "    args=training_args,                      # 위에서 설정한 TrainingArguments\n",
    "    train_dataloader=train_dataloader,       # 커스텀 DataLoader (DistributedSampler 사용)\n",
    "    eval_dataloader=val_dataloader,          # 커스텀 DataLoader (DistributedSampler 사용)\n",
    "    tokenizer=tokenizer,                     # 사용 중인 토크나이저\n",
    "    compute_metrics=compute_metrics          # 평가 메트릭 함수 (선택 사항)\n",
    ")\n",
    "\n",
    "# 학습 수행\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.save_pretrained(\"./saved_model\")\n",
    "tokenizer.save_pretrained(\"./saved_model\")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# 양자화된 모델과 LoRA 어댑터가 적용된 모델 로드\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./saved_model\", quantization_config=bnb_config)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./saved_model\", quantization_config=bnb_config)\n",
    "# model = PeftModel.from_pretrained(model, \"./saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
