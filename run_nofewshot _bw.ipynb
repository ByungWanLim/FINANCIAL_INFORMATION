{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leo97\\anaconda3\\envs\\llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig, LlamaForCausalLM\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "import torch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "# Vector stores\n",
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "#from langchain_community.document_loaders import PyMuPDFLoader, PDFPlumberLoader\n",
    "#from langchain.text_splitter import RecursiveCharacterTextSplitter, KonlpyTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "#from langchain_community.retrievers import BM25Retriever, KNNRetriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "#from langchain_community.document_loaders import PyMuPDFLoader, PDFPlumberLoader ,UnstructuredPDFLoader\n",
    "from langchain_community.retrievers import BM25Retriever, KNNRetriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "#from langchain_teddynote.retrievers import KiwiBM25Retriever, OktBM25Retriever\n",
    "from langchain_teddynote.retrievers import OktBM25Retriever\n",
    "from langchain.docstore.document import Document\n",
    "#from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import pymupdf4llm\n",
    "#import time\n",
    "#import re\n",
    "#from konlpy.tag import Okt\n",
    "#from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from konlpy.tag import Kkma\n",
    "# etc\n",
    "#import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import logging\n",
    "#from PyPDF2 import PdfReader\n",
    "#import json\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # GPU 사용 가능 여부 및 MPS 지원 여부 확인\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intfloat/multilingual-e5-small\n",
    "# jhgan/ko-sroberta-multitask\n",
    "\n",
    "def get_embedding():\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='jhgan/ko-sroberta-multitask',\n",
    "        model_kwargs={'device': device},\n",
    "        encode_kwargs={'normalize_embeddings': True})\n",
    "    return embeddings\n",
    "def normalize_string(s):\n",
    "    try:\n",
    "        normalized = unicodedata.normalize('NFC', s)\n",
    "        return normalized.encode('utf-8', errors='replace').decode('utf-8')\n",
    "    except Exception:\n",
    "        return s\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"�\", \" \").replace(\"\u0003\", \" \")  # 잘못된 인코딩 문자 제거\n",
    "    return text\n",
    "\n",
    "def format_docs(docs):\n",
    "    context = \"\"\n",
    "    i = 1\n",
    "    for doc in docs:\n",
    "        #context += f\"Document: {i}\" +\"Source:\"+ doc.metadata['source'] +'\\n'\n",
    "        context += doc.page_content\n",
    "        context += '\\n---\\n'\n",
    "        i += 1\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs(pdf_path):\n",
    "    documents = []\n",
    "    try:\n",
    "        # 페이지 단위로 pymupdf4llm 사용\n",
    "        md_read = pymupdf4llm.to_markdown(pdf_path,page_chunks=True)\n",
    "        total_pages = len(md_read)    \n",
    "        \n",
    "        for page_data in md_read:\n",
    "            page_number = page_data.get('metadata', {}).get('page', None)\n",
    "            text = clean_text(normalize_string(page_data['text']))\n",
    "            metadata = {\n",
    "                \"Source_path\": pdf_path,\n",
    "                \"page_number\": page_number,\n",
    "                \"total_pages\": total_pages,\n",
    "                \"tables\": page_data.get('tables', None),\n",
    "            }\n",
    "            \n",
    "            documents.append(Document(page_content=text, metadata=metadata))\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to process PDF with pymupdf4llm: {e}\")\n",
    "\n",
    "    return documents\n",
    "\n",
    "def chunk_documents(docs):\n",
    "    markdown_headers = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "        (\"####\", \"Header 4\")\n",
    "    ]\n",
    "    \n",
    "    # 마크다운 스플리터 설정\n",
    "    markdown_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators = [\n",
    "                # First, try to split along Markdown headings (starting with level 2)\n",
    "                \"\\n#{1,6} \",\n",
    "                # Note the alternative syntax for headings (below) is not handled here\n",
    "                # Heading level 2\n",
    "                # ---------------\n",
    "                # End of code block\n",
    "                \"```\\n\",\n",
    "                # Horizontal lines\n",
    "                \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
    "                \"\\n---+\\n\",\n",
    "                \"\\n___+\\n\",\n",
    "                # Note that this splitter doesn't handle horizontal lines defined\n",
    "                # by *three or more* of ***, ---, or ___, but this is not handled\n",
    "                \"\\n\\n\",\n",
    "                \"\\n\",\n",
    "                \" \",\n",
    "                \"\",\n",
    "            ],\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "    )\n",
    "    \n",
    "    chunks = []\n",
    "    for doc in docs:\n",
    "        text = doc.page_content\n",
    "        metadata = doc.metadata\n",
    "        md_header_splits = markdown_splitter.split_text(text)\n",
    "        for md_split in md_header_splits:   \n",
    "            # 테이블이 있는 페이지는 청크로 분할하지 않음\n",
    "            chunks.append(Document(page_content=md_split, metadata = metadata))\n",
    "    return chunks\n",
    "\n",
    "def make_db(df):\n",
    "    documents = []\n",
    "    chunks = []\n",
    "    pdf_files = df['Source_path'].unique()\n",
    "    for pdf_file in tqdm(pdf_files):\n",
    "        # 문서 로드\n",
    "        documents.extend(get_docs(pdf_file))\n",
    "        # 청크 생성\n",
    "        # chunks.extend(chunk_documents(documents))\n",
    "    print(f\"Total number of documents: {len(documents)}\")\n",
    "    \n",
    "    # print(f\"Total number of chunks: {len(chunks)}\")\n",
    "\n",
    "    faiss = FAISS.from_documents(documents, embedding=get_embedding())\n",
    "    return faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fewshot_db(df):\n",
    "    df = df.drop('SAMPLE_ID', axis=1)\n",
    "    df = df.drop('Source_path', axis=1)\n",
    "    df = df.to_dict(orient='records')\n",
    "    print(\"Loaded Fewshot Set:\", len(df))\n",
    "    to_vectorize = [\"\\n\\n\".join(normalize_string(value) for value in example.values()) for example in df]\n",
    "    faiss = FAISS.from_texts(to_vectorize, embedding=get_embedding())\n",
    "    # bm = BM25Retriever.from_texts(to_vectorize)\n",
    "    # knn = KNNRetriever.from_texts(to_vectorize, embeddings=get_embedding())\n",
    "    return faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test_df = pd.read_csv('test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n",
    "    context = \"\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        #context += f\"Document {i+1}\\n\"\n",
    "        doc.page_content = doc.page_content.replace(\"{\", \"(\")\n",
    "        doc.page_content = doc.page_content.replace(\"}\", \")\")\n",
    "        \n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.34s/it]\n"
     ]
    }
   ],
   "source": [
    "def setup_llm_pipeline(model_id=\"meta-llama/Meta-Llama-3.1-8B-Instruct\"):\n",
    "    # 양자화 설정 적용\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  # 기본적으로 4비트로 로드\n",
    "        bnb_4bit_use_double_quant=True,  # 두 번 양자화 적용\n",
    "        bnb_4bit_quant_type=\"nf4\",  # 4비트 양자화 유형 선택\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16  # 연산은 bf16으로 수행\n",
    "    )\n",
    "\n",
    "    # 모델 로드\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, \n",
    "        quantization_config=bnb_config,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "\n",
    "    # 일부 중요한 레이어는 FP16으로 유지\n",
    "    for name, module in model.named_modules():\n",
    "        if \"attention\" in name or \"ffn\" in name:  # 중요한 레이어 식별 (예: attention 및 ffn)\n",
    "            module.to(torch.float16)  # 이 부분은 16비트로 유지\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    text_generation_pipeline = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=1024,\n",
    "        eos_token_id = terminators,\n",
    "        pad_token_id = tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "    return llm\n",
    "# ghost-x/ghost-8b-beta-1608\n",
    "# OpenBuddy/openbuddy-llama3.1-8b-v22.3-131k\n",
    "llm = setup_llm_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def calculate_f1_score(true_sentence, predicted_sentence, sum_mode=True):\n",
    "\n",
    "    #공백 제거\n",
    "    true_sentence = ''.join(true_sentence.split())\n",
    "    predicted_sentence = ''.join(predicted_sentence.split())\n",
    "    \n",
    "    true_counter = Counter(true_sentence)\n",
    "    predicted_counter = Counter(predicted_sentence)\n",
    "\n",
    "    #문자가 등장한 개수도 고려\n",
    "    if sum_mode:\n",
    "        true_positive = sum((true_counter & predicted_counter).values())\n",
    "        predicted_positive = sum(predicted_counter.values())\n",
    "        actual_positive = sum(true_counter.values())\n",
    "\n",
    "    #문자 자체가 있는 것에 focus를 맞춤\n",
    "    else:\n",
    "        true_positive = len((true_counter & predicted_counter).values())\n",
    "        predicted_positive = len(predicted_counter.values())\n",
    "        actual_positive = len(true_counter.values())\n",
    "\n",
    "    #f1 score 계산\n",
    "    precision = true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    recall = true_positive / actual_positive if actual_positive > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def calculate_average_f1_score(true_sentences, predicted_sentences):\n",
    "    \n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1_score = 0\n",
    "    \n",
    "    for true_sentence, predicted_sentence in zip(true_sentences, predicted_sentences):\n",
    "        precision, recall, f1_score = calculate_f1_score(true_sentence, predicted_sentence)\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1_score += f1_score\n",
    "    \n",
    "    avg_precision = total_precision / len(true_sentences)\n",
    "    avg_recall = total_recall / len(true_sentences)\n",
    "    avg_f1_score = total_f1_score / len(true_sentences)\n",
    "    \n",
    "    return {\n",
    "        'average_precision': avg_precision,\n",
    "        'average_recall': avg_recall,\n",
    "        'average_f1_score': avg_f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_answer(response):\n",
    "    # AI: 로 시작하는 줄을 찾아 그 이후의 텍스트만 추출\n",
    "    lines = response.split('\\n')\n",
    "    for line in lines:\n",
    "        line = line.replace('**', '')\n",
    "        if line.startswith('Answer:'):\n",
    "            return line.replace('Answer:', '').strip()\n",
    "        if line.startswith('assistant:'):\n",
    "            return line.replace('assistant:', '').strip()\n",
    "    return response.strip()  # AI: 를 찾지 못한 경우 전체 응답을 정리해서 반환\n",
    "\n",
    "def equal_path(contexts, source_path):\n",
    "    adjusted_docs = []\n",
    "    for doc in contexts:\n",
    "        if doc.metadata['Source_path'] == source_path:\n",
    "            adjusted_docs.append(doc)\n",
    "    return adjusted_docs\n",
    "\n",
    "def rerun(question,context,answer,llm,num_repeat):\n",
    "    full_template = \"<|begin_of_text|>\"\n",
    "    full_template += \"\"\"<|start_header_id|>system<|end_header_id|>당신은 이전 답변을 검증하는 챗봇입니다. 질문과 문맥, 이전 답변을 참고해서 지시사항을 따르세요. 지시사항을 따를 때 서론 없이 출력하세요.<|eot_id|>\"\"\"\n",
    "    full_template += f\"\"\"<|start_header_id|>user<|end_header_id|>Question: {question} \\n\\nContexts: {context} \\n\\nPrevious Answer: {answer} \\n\\n\"\"\"\n",
    "    full_template += \"\"\"{input}<|eot_id|>\"\"\"\n",
    "    full_template += \"\"\"<|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(template=full_template)\n",
    "    chain = (\n",
    "    {\n",
    "        \"input\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    )\n",
    "    return chain.invoke(\"핵심 단어들을 바탕으로, 한 문장으로 요약하세요. 만약 한 문장이라면 그대로 출력하세요.\")\n",
    "    \n",
    "def run(faiss,dataset,llm,k=2,verbose=False):\n",
    "    results = []\n",
    "    source_path = dataset.iloc[0]['Source_path']\n",
    "    docs = faiss.similarity_search(\n",
    "        query=\"\",  # 유사도 기반이 아닌 메타데이터 필터링만 사용하므로 query는 빈 값으로\n",
    "        filter={\"Source_path\": source_path},\n",
    "        k = 99,\n",
    "        fetch_k = 20000\n",
    "        )\n",
    "    buff_faiss = FAISS.from_documents(docs, embedding=get_embedding())\n",
    "    faiss_retriever = buff_faiss.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": k})\n",
    "    knn_retriever = KNNRetriever.from_documents(docs, embeddings=get_embedding())\n",
    "    knn_retriever.k = k\n",
    "    bm_retriever = OktBM25Retriever.from_documents(docs)\n",
    "    bm_retriever.k = k\n",
    "    ensemble_retriever = EnsembleRetriever(retrievers=[faiss_retriever, knn_retriever,bm_retriever], weight=[0.4, 0.3, 0.3])\n",
    "    \n",
    "    for i, row in (dataset.iterrows()):\n",
    "        if source_path != row['Source_path']:   \n",
    "            source_path = row['Source_path']\n",
    "            docs = faiss.similarity_search(\n",
    "                query=\"\",  # 유사도 기반이 아닌 메타데이터 필터링만 사용하므로 query는 빈 값으로\n",
    "                filter={\"Source_path\": source_path},\n",
    "                k = 99,\n",
    "                fetch_k = 20000\n",
    "                )\n",
    "            buff_faiss = FAISS.from_documents(docs, embedding=get_embedding())\n",
    "            faiss_retriever = buff_faiss.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": k})\n",
    "            knn_retriever = KNNRetriever.from_documents(docs, embeddings=get_embedding())\n",
    "            knn_retriever.k = k\n",
    "            bm_retriever = OktBM25Retriever.from_documents(docs)\n",
    "            bm_retriever.k = k\n",
    "            ensemble_retriever = EnsembleRetriever(retrievers=[faiss_retriever, knn_retriever,bm_retriever], weight=[0.4, 0.3, 0.3])\n",
    "            \n",
    "        full_template = \"<|begin_of_text|>\"\n",
    "        full_template += \"\"\"<|start_header_id|>system<|end_header_id|>\n",
    "당신은 유용한 금융 정보 QnA 챗봇입니다.\n",
    "질문을 차근차근 생각하고, 답변 시 반드시 문맥 정보를 활용해야합니다. \n",
    "객관적이고 공식적인 문체를 사용하세요.\n",
    "서론 없이 핵심 내용을 한 문장으로 작성해주세요. \n",
    "<|eot_id|>\n",
    "\"\"\"\n",
    "        question = row['Question']          \n",
    "        # full_template += \"\"\" \"\"\"\n",
    "        contexts = ensemble_retriever.invoke(normalize_string(question))\n",
    "        # contexts = equal_path(contexts,row['Source_path'])\n",
    "        contexts = format_docs(contexts)\n",
    "        full_template += \"\"\"<|start_header_id|>user<|end_header_id|>Question: {input}\\n\\n\"\"\"\n",
    "        full_template += f\"\"\"Contexts: {contexts}<|eot_id|>\"\"\"\n",
    "        full_template += \"\"\"<|start_header_id|>assistant<|end_header_id>\"\"\"\n",
    "        \n",
    "        prompt = PromptTemplate(template=full_template, input_variables=[\"input\"])\n",
    "        qa_chain = (\n",
    "        {\n",
    "            \"input\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        answer = qa_chain.invoke(input=question)\n",
    "        answer = extract_answer(answer)\n",
    "        lines = answer.split('\\n')\n",
    "        if  len(lines) > 1:\n",
    "            previous = answer\n",
    "            try:\n",
    "                before = calculate_f1_score(row['Answer'],answer)[2]\n",
    "            except:\n",
    "                before = None\n",
    "            answer = rerun(question=question,\n",
    "                           context=contexts,\n",
    "                           answer=answer,\n",
    "                           llm=llm,\n",
    "                           num_repeat=1)\n",
    "        answer = extract_answer(answer)\n",
    "        results.append({\n",
    "            \"Question\": question,\n",
    "            \"Answer\": answer,\n",
    "            \"Source\": row['Source']\n",
    "        })\n",
    "        if verbose:\n",
    "            print(f\"{i}/{len(dataset)}\")\n",
    "            print(\"Question: \", question, end=\" | \")\n",
    "            print(\"Context Number |\",len(contexts))\n",
    "            try:\n",
    "                print(calculate_f1_score(row['Answer'],answer)[2],end=\" | \")\n",
    "            except:\n",
    "                pass\n",
    "            print(\"Answer: \", results[-1]['Answer'])\n",
    "            try:\n",
    "                print(\"Before: \",before,\" | \",previous)  \n",
    "                \n",
    "                previous = None\n",
    "                before = None\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                print(\"REAL Answer: \",row['Answer'])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            print()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 케이폴드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [02:51<00:00, 12.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 1071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leo97\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\leo97\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:660: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/124\n",
      "Question:  2024년 중앙정부의 예산 지출은 어떻게 구성되어 있나요? | Context Number | 3784\n",
      "0.9166666666666665 | Answer:  2024년 중앙정부의 예산 지출은 일반회계 356.5조원, 특별회계 81.7조원으로 구성됩니다.\n",
      "REAL Answer:  2024년 중앙정부의 예산 지출은 일반회계 356.5조원, 21개 특별회계 81.7조원으로 구성되어 있습니다.\n",
      "\n",
      "4/124\n",
      "Question:  2024년 총수입은 얼마이며, 예산수입과 기금수입은 각각 몇 조원인가요? | Context Number | 2713\n",
      "0.9278350515463918 | Answer:  2024년 총수입은 612.2조원입니다. 예산수입은 395.5조원, 기금수입은 216.7조원입니다.\n",
      "REAL Answer:  2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216.7조원입니다.\n",
      "\n",
      "6/124\n",
      "Question:  2024년의 기금수입은 어떻게 구성되어 있나요? | Context Number | 2827\n",
      "0.7563025210084033 | Answer:  2024년 기금수입은 216.7조원으로 사회보장기여금 92.3조원, 융자원금회수 33.8조원, 기타 90.6조원으로 구성됩니다.\n",
      "REAL Answer:  2024년도 기금수입은 사회보장성기금 92.3조원, 경상이전수입 39.6조원, 기타 84.7조원으로 구성되어 있습니다.\n",
      "\n",
      "11/124\n",
      "Question:  2024년 총지출 기준 예산의 일반회계와 특별회계의 비중이 각각 얼마인가? | Context Number | 5431\n",
      "0.8461538461538461 | Answer:  2024년 총지출 기준 일반회계와 특별회계의 비중은 각각 87.3%와 12.7%입니다.\n",
      "REAL Answer:  2024년 총지출 중 일반회계와 특별회계의 비중은 각각 54.3%와 12.4%이다.\n",
      "\n",
      "19/124\n",
      "Question:  2020년 결산 기준, 연구개발비 중 개발연구 규모는 몇 억원인가? | Context Number | 5696\n",
      "0.875 | Answer:  2020년 결산 기준, 연구개발비 중 개발연구 규모는 178억원입니다.\n",
      "REAL Answer:  2020년 결산 기준 연구개발비 중 개발연구 규모는 78754억원이다.\n",
      "\n",
      "20/124\n",
      "Question:  세출예산현액이란? | Context Number | 2420\n",
      "0.8993288590604026 | Answer:  세출예산현액이란, 예산 확정 후 전년도로부터의 이월액을 반영, 추경 편성, 기금운용계획 변경, 이용･전용, 예비비 증액 등을 반영한 것으로, 실제 지출할 수 있는 한도액을 의미합니다.\n",
      "REAL Answer:  예산 확정 후 전년도로부터의 이월액 반영, 추경 편성, 기금운용계획 변경, 이용・전용, 예비비 증액 등을 반영한 것으로, 실제 지출할 수 있는 한도액을 의미한다.\n",
      "\n",
      "23/124\n",
      "Question:  2022년 기준, 일반회계, 특별회계, 기금의 집행률은? | Context Number | 5182\n",
      "0.9176470588235294 | Answer:  2022년 기준, 일반회계, 특별회계, 기금의 집행률은 97.3%, 94.7%, 97.6%입니다.\n",
      "REAL Answer:  2022년 기준, 집행률은 일반회계 97.3%, 특별회계 94.7%, 기금 97.6%\n",
      "\n",
      "25/124\n",
      "Question:  2022년 결산 기준으로 사회보험성기금의 이월금 규모는 몇 억원인가요? | Context Number | 5502\n",
      "0.3555555555555555 | Answer:  2022년 결산 기준으로 사회보험성기금의 이월금 규모는 4,900억원입니다.\n",
      "REAL Answer:  223억원입니다.\n",
      "\n",
      "27/124\n",
      "Question:  2022년 기준으로 국내총생산 대비 일반정부부채와 공공부문 부채의 비중은 각각 몇 퍼센트인가? | Context Number | 5059\n",
      "0.5813953488372093 | Answer:  2022년 기준으로 국내총생산 대비 일반정부부채와 공공부문 부채의 비중은 각각 53.5%와 73.5%입니다.\n",
      "REAL Answer:  일반정부부채(D2)는 53.5%, 공공부문 부채(D3)는 73.5%이다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/124\n",
      "Question:  2007년 시행된 국가재정법에서 추경 편성 사유로 명시된 사항은 무엇인가? | Context Number | 4329\n",
      "0.9 | Answer:  추가경정예산의 추경 편성 사유는 국가재정법에 따라 ①전쟁이나 대규모 재해가 발생한 경우, ②경기침체, 대량 실업, 남북 관계의 변화, 경제협력과 같은 대내외 여건에 중대한 변화가 발생하였거나 발생할 우려가 있는 경우, ③법령에 따라 국가가 지급하여야 하는 지출이 발생하거나 증가하는 경우에 한정됩니다.\n",
      "REAL Answer:  국가재정법에서 추경 편성 사유로 명시된 사항은 전쟁이나 대규모 재해가 발생한 경우, 경기침체, 대량 실업, 남북 관계의 변화, 경제협력과 같은 대내외 여건에 중대한 변화가 발생하였거나 발생할 우려가 있는 경우, 법령에 따라 국가가 지급하여야 하는 지출이 발생하거나 증가하는 경우에 한정되어 있습니다.\n",
      "\n",
      "41/124\n",
      "Question:  2024년 교육재정 교부금의 규모는 얼마이고, 전년 대비 추이는 어떠한가? | Context Number | 4452\n",
      "0.9428571428571428 | Answer:  2024년 교육재정 교부금은 73.0조원이며, 전년 대비 8.9% 감소했다.\n",
      "REAL Answer:  2024년 교육재정교부금은 73.0조원이며 전년 대비 8.9% 감소하였다.\n",
      "\n",
      "43/124\n",
      "Question:  2024년에 교육재정교부금에서 유아교육비 및 보육료 지원에 할당된 비중은? | Context Number | 7165\n",
      "0.1739130434782609 | Answer:  2024년에 교육재정교부금에서 유아교육비 및 보육료 지원에 할당된 비중은 1.6%입니다.\n",
      "REAL Answer:  4.40%\n",
      "\n",
      "44/124\n",
      "Question:  교육재정 교부금이란? | Context Number | 4289\n",
      "0.8555555555555556 | Answer:  교육재정 교부금은 국가가 교육기관 및 교육행정기관 경비를 지원하기 위해 일반회계 보통･특별교부금, 고교 무상교육 증액분, 특별회계 유아교육비･보육료 지원 교부금 등 4가지로 구성된 일반지원금입니다.\n",
      "REAL Answer:  교육의 균형발전을 위해 교육기관 및 교육행정기관 경비를 국가가 교부하는 일반지원금으로, 일반회계 보통・특별교부금, 고교 무상교육 증액분, 특별회계 유아교육비・보육료 지원 교부금 등 4가지로 구성되었다.\n",
      "\n",
      "46/124\n",
      "Question:  특별회계 국고보조금 중 국가균형발전특별회계에서 얼마가 포괄보조금으로 지출되는가? | Context Number | 3022\n",
      "0.631578947368421 | Answer:  국가균형발전특별회계에서 포괄보조금으로 지출되는 금액은 2024년 예산 기준으로 550.0조원입니다.\n",
      "REAL Answer:  특별회계 국고보조금 18.2조원 중 10.0조원이 국가균형발전특별회계에서 지출되는 포괄보조금이다.\n",
      "\n",
      "47/124\n",
      "Question:  2024년의 국고보조사업(자치단체 이전)에서 기금 규모는 얼마인가? | Context Number | 4209\n",
      "0.4 | Answer:  2024년 국고보조사업(자치단체 이전)에서 기금 규모는 109.1조원입니다.\n",
      "REAL Answer:  90,247억원으로 10.1%를 차지하고 있다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leo97\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/124\n",
      "Question:  임신·출산을 희망하는 가구에 어떤 지원이 신규로 이뤄지고 있으며, 고위험 임산부와 미숙아·선천성 이상아의 의료비 지원은 어떻게 이루어지는가? | Context Number | 3972\n",
      "0.3790849673202615 | Answer:  임신·출산을 희망하는 가구에 대한 지원은 '다담씨앗통장'을 통해 자산 형성을 지원 중이며, 2024년부터 지원 대상과 지원 연령을 대폭 확대한다.\n",
      "Before:  0.164079822616408  |  2024 년 나라살림 예산안에 따른 주요 지원 내용은 다음과 같다.\n",
      "\n",
      "1. 임신·출산을 희망하는 가구에 대한 지원\n",
      "* 임신·출산을 희망하는 가구에 대한 지원을 위해 '다담씨앗통장'을 통해 자산 형성을 지원 중이며, 2024년부터 지원 대상과 지원 연령을 대폭 확대한다. 지원 대상은 생계·의료급여 대상자에서 생계·의료·주거·교육급여 대상자로 확대하고, 지원 연령은 만 12~17세에서 만 0~17세로 확대한다.\n",
      "\n",
      "2. 고위험 임산부와 미숙아·선천성 이상아의 의료비 지원\n",
      "* 고위험 임산부와 미숙아·선천성 이상아의 의료비 지원은 연 50만 명에 대한 연 20만 원의 의료비를 지원한다.\n",
      "\n",
      "3. 주거 및 교육급여 수급권자 포함\n",
      "* 주거 및 교육급여 수급권자 포함 5.6만 명이 추가로 지원된다.\n",
      "\n",
      "4. 저소득 아동의 사회 진출 초기 목돈 마련\n",
      "* 저소득 아동의 사회 진출 초기 목돈 마련을 위해 '다담씨앗통장'을 통해 자산 형성을 지원 중이며, 2024년부터 지원 대상과 지원 연령을 대폭 확대한다. 지원 대상은 생계·의료급여 대상자에서 생계·의료·주거·교육급여 대상자로 확대하고, 지원 연령은 만 12~17세에서 만 0~17세로 확대한다.\n",
      "\n",
      "5. 저소득 아동의 보육 지원\n",
      "* 저소득 아동의 보육 지원을 위해 '아동 수당'과 '첫만남 이용권'을 제공한다.\n",
      "\n",
      "6. 저소득층 기저귀 및 조제분유 지원\n",
      "* 저소득층 기저귀 및 조제분유 지원을 위해 월 9 만원과 월 11 만원을 지원한다.\n",
      "\n",
      "7. 저소득층 영유아 보육료 지원\n",
      "* 저소득층 영유아 보육료 지원을 위해 5% 인상한다.\n",
      "\n",
      "8. 아동 학대 예방 및 피해 아동 보호\n",
      "* 아동 학대 예방 및 피해 아동 보호를 위해 아동 보호 전문기관을 확대하고, 방문형 가족회복을 확대한다.\n",
      "\n",
      "9. 자립준비 청년 자립 지원\n",
      "* 자립준비 청년 자립 지원을 위해 자립 수당을 월 50 만원으로 인상하고, 자립 지원 전담 인력을 확충하고, 맞춤형 사례 관리 지원 대상자를 확대한다.\n",
      "\n",
      "10. 아동·보육 부문 주요 변동 내역\n",
      "* 아동 수당, 첫만남 이용권, 저소득층 기저귀 및 조제분유 지원, 저소득층 영유아 보육료 지원, 아동 학대 예방 및 피해 아동 보호, 자립준비 청년 자립 지원 등 아동·보육 부문 주요 변동 내역을 나타낸다.\n",
      "REAL Answer:  임신·출산을 희망하는 가구에는 필수가임력(생식건강) 검진비와 냉동난자를 활용한 보조 생식술 비용을 신규로 지원하며, 고위험 임산부와 미숙아·선천성 이상아의 의료비는 소득수준에 관계없이 지원된다.\n",
      "\n",
      "57/124\n",
      "Question:  2024년 R&D 분야에 대한 재정투자 규모는 2023년 대비 얼마나 감소했으며, 어떤 분야의 국가전략기술 투자를 확대할 계획인가? | Context Number | 3064\n",
      "0.5892857142857143 | Answer:  2024년 R&D 분야의 재정투자 규모는 2023년 대비 8.5% 감소한다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2024년 R&D 분야에 대한 재정투자 규모는 2023년 대비 9.5% 감소한 26.5조원이며, AI·바이오·반도체 등의 분야에 대한 국가전략기술 투자를 확대할 계획입니다.\n",
      "\n",
      "58/124\n",
      "Question:  우주산업 클러스터 삼각체제 구축사업의 목표와 국가 우주산업 육성 거점 지역은 어디인가? | Context Number | 3271\n",
      "0.4472049689440994 | Answer:  국가 우주산업 육성 거점 지역은 과기계 ministry가 2024년 1,000억원으로 확대한 우주산업 클러스터 삼각체제 구축사업의 목표입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  우주산업 클러스터 삼각체제 구축사업은 우주경제 시대 대비 민간 주도 우주개발 역량 강화 및 자생적 생태계 조성을 위해 핵심 인프라를 구축하는 플래그십 프로젝트이며, 전남, 경남, 대전을 국가 우주산업 육성 거점으로 지정했다.\n",
      "\n",
      "62/124\n",
      "Question:  2024년도 공공질서 및 안전 분야의 재정투자는 전년도 대비 어떻게 변화했으며, 어떤 분야에 특히 재정투자가 집중되었는가? | Context Number | 2826\n",
      "0.5798816568047337 | Answer:  2024년 공공질서 및 안전 분야의 재정투자는 전년도 대비 6.5% 증가한 244.3억 원으로 예상되며, 법원 및 헌법재판소 부문에서 가장 큰 증가율을 보였다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2024년도 공공질서 및 안전 분야의 재정투자는 24.4조원으로 2023년도 22.9조원 대비 6.5% 증가하였으며, 마약·스토킹 등 민생침해범죄 예방·대응과 재난·안전 사고에 대한 근본적 예방에 집중적으로 투자하였다.\n",
      "\n",
      "77/124\n",
      "Question:  예산 증감률이 가장 높은 분야는 무엇인가요? | Context Number | 2251\n",
      "0.4 | Answer:  2024년 예산 증감률이 가장 높은 분야는 △96,405 억원(8.9%)의 △96,405 억원(8.9%)입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  외교·통일 분야가 17.7%로 예산 증감률이 가장 높습니다.\n",
      "\n",
      "98/124\n",
      "Question:  하수관로정비 사업 예산은 2023년 대비 2024년에 얼마나 증가했는가? | Context Number | 1537\n",
      "0.7086614173228347 | Answer:  2024년 하수관로정비 예산은 2023년 대비 32.7% 증가한 10,241 억원으로, 2023년 예산인 7,716 억원보다 2,525 억원 증가했습니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  하수관로정비 사업 예산은 2023년 9,531억원에서 2024년 1조 2,816억원으로 증가하여 34.5% 증가하였다.\n",
      "\n",
      "103/124\n",
      "Question:  국회의 입법활동 및 의정활동을 지원하기 위해 어떤 활동들이 실시되고 있는가? | Context Number | 5614\n",
      "0.42857142857142855 | Answer:  2024 년 국회 입법활동 및 의정활동을 지원하기 위해 다양한 활동들이 실시되고 있습니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  국회 정책세미나·토론회·간담회 실시간 생중계 시스템 구축, SNS 영상 제작 지원 및 의정활동 안내 문자메시지 발송 등을 통해 국회 입법활동 및 의정활동을 지원하고 있다.\n",
      "\n",
      "108/124\n",
      "Question:  국가첨단전략산업 특화단지에 대한 지원 계획은 어떻게 되어 있는가? | Context Number | 2740\n",
      "0.5227272727272727 | Answer:  국가첨단전략산업 특화단지에 대한 지원 계획은 2024년 495억원으로 확대된다.\n",
      "Before:  0.4035087719298246  |  국가첨단전략산업 특화단지에 대한 지원 계획은 다음과 같다.\n",
      "\n",
      "국가첨단전략산업 특화단지에 대한 지원 계획은 2024년 495억원으로 확대된다.\n",
      "REAL Answer:  국가첨단전략산업 특화단지에 대한 저리융자, 기반시설 구축, 현장 맞춤형 실무교육 등을 종합적으로 지원할 계획이다.\n",
      "\n",
      "109/124\n",
      "Question:  가족돌봄청년을 위해 신규로 지원되는 혜택은 무엇인가요? | Context Number | 2026\n",
      "0.2180094786729858 | Answer:  2024년 가족돌봄청년을 위해 지원되는 혜택으로는 월 20만원의 청년 월세 한시 특별 지원이 1년 연장되며, 공공주택 공급이 대폭 확대되며, 「산리단길 프로젝트」를 통하여 산업단지를 청년이 선호하는 환경으로 전환하고, 취약계층 아동의 사회진출 초기 목돈 마련을 위한 '다담씨앗통장'을 통해 자산형성을 지원하며, 의료 인프라를 확대하여 소아청소년 분야의 의료공백을 해소합니다.\n",
      "Before:  0.1697612732095491  |  2024년 가족돌봄청년을 위해 지원되는 혜택은 다음과 같습니다. \n",
      "\n",
      "1. 가족돌봄청년을 위해 월 20만원의 청년 월세 한시 특별 지원이 1년 연장됩니다.\n",
      "2. 청년 대상 공공분양(6.7만호) 및 공공 임대(5.7만호) 등 공공주택 공급이 대폭 확대됩니다.\n",
      "3. 「산리단길 프로젝트」를 통해 산업단지를 청년이 선호하는 환경으로 전환합니다.\n",
      "4. 기숙사형 오피스텔, 편의시설 등을 조성하는 산단환경개선펀드가 0.2조원으로 대폭 확대됩니다.\n",
      "5. 청년복합문화센터(100개) 및 아름다운거리(60개)를 조성합니다.\n",
      "6. 노후공장 150개사의 근무환경을 개선하는 사업이 신설됩니다.\n",
      "7. 취약계층 아동의 사회진출 초기 목돈 마련을 위해 ‘다담씨앗통장’을 통해 자산형성을 지원합니다.\n",
      "8. 의료 인프라를 확대하여 소아청소년 분야의 의료공백을 해소합니다.\n",
      "REAL Answer:  자기돌봄비(연200만원)와 돌봄코디네이터를 통한 밀착 사례관리 및 자조모임 등을 신규로 지원한다.\n",
      "\n",
      "110/124\n",
      "Question:  의료 분야에 대한 국고 지원이 어떻게 확대되고 있는가? | Context Number | 4259\n",
      "0.2258064516129032 | Answer:  의료 분야에 대한 국고 지원이 확대되고 있습니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  달빛어린이병원(45개소)에 대해 국고 지원에 착수하고, 소아환자에게 24시간 의료상담을 제공하는 24시간 상담센터를 신설하고, 어린이 공공전문진료센터와 소아암 전문거점병원을 확충하고, 전공의 수련수당도 신규 지원하고 있다.\n",
      "\n",
      "113/124\n",
      "Question:  2023년 기획재정부의 총세입예산은 얼마인가요? | Context Number | 5589\n",
      "0.19047619047619047 | Answer:  2023 년 기획재정부의 총 세입 예산은 625.7 조원입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  438,715,377백만원\n",
      "\n",
      "114/124\n",
      "Question:  기초생활보장제도 4대 급여의 예산 규모는 2023년 대비 2024년에 어떻게 변화되는가? | Context Number | 4081\n",
      "0.4651162790697675 | Answer:  기초생활보장제도 4대 급여의 예산 규모는 2023년 대비 2024년에 약 2.9% 증가한 3,447,126백만원입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2023년 17.8조원에서 2024년 19.4조원으로 확대된다.\n",
      "\n",
      "120/124\n",
      "Question:  교육 분야 재정투자 계획에 따르면 2024년에 유아및초중등교육 분야의 예산이 2023년에 비해 어떻게 변하는가? | Context Number | 3158\n",
      "0.7032967032967034 | Answer:  2024년 교육 분야의 예산은 2023년 예산 대비 2.9% 증가한 3,447,126억 원입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2024년에 유아및초중등교육 분야의 예산은 737,290억원으로 2023년 대비 8.9% 감소한다.\n",
      "\n",
      "125/124\n",
      "Question:  문화예술 부문의 총 예산은 어떻게 변화했는가? | Context Number | 2777\n",
      "0.6265060240963856 | Answer:  2024 년 문화예술 부문 예산은 81.7조원으로 14.1% 증가했다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  문화예술 부문의 총 예산은 2023년 40,022억원에서 2024년 40,628억원으로 1.5% 증가하였다.\n",
      "\n",
      "127/124\n",
      "Question:  2024년에 산업혁신지원 부문의 총 예산은 얼마이며, 전년 대비 어떤 증감률을 보였는가? | Context Number | 2420\n",
      "0.7422680412371134 | Answer:  2024년 산업혁신지원 부문의 총 예산은 101,719,441백만원이며, 전년 대비 약 4.0% 증가한 금액입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2024년에 산업혁신지원 부문의 총 예산은 63,146억원이며, 전년 대비 5.1% 증가하였다.\n",
      "\n",
      "129/124\n",
      "Question:  산업혁신지원 부문 주요 변동 내역에서 2024년에 산업혁신인재성장지원 부문의 예산은 얼마이며, 전년 대비 어떤 증감률을 보였는가? | Context Number | 1980\n",
      "0.7741935483870968 | Answer:  2024년 산업혁신인재성장지원 부문의 예산은 22,300억원이며, 전년 대비 2.9% 감소합니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2024년에 산업혁신인재성장지원 부문의 예산은 1,575억원이며, 전년 대비 16.0% 증가하였다.\n",
      "\n",
      "136/124\n",
      "Question:  외교·통일 분야 재정투자 계획에서 2024년 외교·통상 부문 예산은 2023년 대비 얼마나 증가했는가? | Context Number | 3020\n",
      "0.39344262295081966 | Answer:  2024년 예산 총지출은 2023년 본예산 대비 2.8% 증가한 656.6조원이다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  14,736억원 증가하여 29.8% 증가하였다.\n",
      "\n",
      "137/124\n",
      "Question:  재정투자 계획에서 2023년 대비 2024년에 가장 큰 증가율을 보인 분야는 무엇인가요? | Context Number | 3186\n",
      "0.7761194029850746 | Answer:  2024년 대비 2023년에 가장 큰 증가율을 보인 분야는 기금입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2023년 대비 2024년에 22.1%의 증가율을 보인 재정·금융 분야입니다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leo97\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/124\n",
      "Question:  예산 사전의결의 원칙은 무엇인가? | Context Number | 2389\n",
      "0.8505747126436781 | Answer:  예산 사전의결의 원칙은 국가재정법 제54조에 의거, 예산을 집행하기에 앞서 국회의 의결을 얻도록 하는 원칙입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  예산 사전의결의 원칙은 예산을 집행하기에 앞서 국회의 의결을 얻도록 하는 원칙입니다.\n",
      "\n",
      "149/124\n",
      "Question:  예산이란 무엇을 의미하며 어떻게 표시되는가? | Context Number | 3102\n",
      "0.33887043189368776 | Answer:  국가채무는 중앙정부의 채무를 의미하며, 채무를 상환할 수 있는 재원이 있는지에 따라 적자성 채무와 금융성 채무로 구분됩니다. 적자성 채무는 국민의 세금으로 상환해야 하는 채무로, 주로 경기침체로 인한 적자보전용 국채를 발행하거나, 공적자금의 국채전환, 중앙정부가 지방정부에 진 채무 등이 해당됩니다. 금융성 채무는 융자금 회수, 자산매각 등 자체상환이 가능한 채무로, 주로 외환시장 안정이나 서민 주거 안정 등을 위해 채권을 발행하는 경우 해당됩니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  예산이란 일정 기간 동안 국가의 재정활동에 얼마만큼 지출하고 이를 위해 재원을 어떻게 조달할 것인가를 금액으로 표시한 것이며, 회계연도 단위로 작성되어 운용 회계연도 독립의 원칙에 따라 특정 회계연도의 지출은 당해 회계연도의 수입으로 이루어진다.\n",
      "\n",
      "150/124\n",
      "Question:  세입세출예산은 어떤 원칙에 따라 작성되는가? | Context Number | 3275\n",
      "0.4255319148936171 | Answer:  1.  일반회계는 일반적인 조세수입으로 일반적인 지출을 수행하는 국가 예산의 근간이 되는 회계입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  세입세출예산은 총계주의 원칙에 따라 한 회계연도의 일체의 수입을 세입으로 하고 일체의 지출을 세출로 하여 작성된다.\n",
      "\n",
      "159/124\n",
      "Question:  국고채무부담행위는 어떤 경우에 국회의 의결을 받아야 하나요? | Context Number | 2951\n",
      "0.5555555555555556 | Answer:  국고채무부담행위는 국회의 사전의결을 받아야 합니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  법률에 의하지 않거나 세출예산 또는 계속비 총액범위를 벗어나 국가채무를 부담할 때 국회의 의결을 받아야 합니다.\n",
      "\n",
      "161/124\n",
      "Question:  본예산, 수정예산, 준예산의 차이점은 무엇인가요? | Context Number | 3870\n",
      "0.8309178743961353 | Answer:  본예산, 수정예산, 준예산의 차이점은 본예산이 통상적 의미의 예산, 수정예산이 정부가 국회에 제출한 후 국회의 심의·확정 전에 수정하여 제출하는 예산, 준예산이 예산이 법정기한 내에 국회의 의결을 받지 못할 경우에 대비한 예산입니다.\n",
      "Before:  0.8122270742358079  |  본예산, 수정예산, 준예산의 차이점은 다음과 같습니다.\n",
      "\n",
      "본예산: 통상적 의미의 예산, 법정기한 내에 국회의 의결을 받은 예산\n",
      "수정예산: 정부가 예산을 국회에 제출한 후 국회의 심의·확정 전에 수정하여 제출하는 예산\n",
      "준예산: 예산이 법정기한 내에 국회의 의결을 받지 못할 경우에 대비한 예산\n",
      "REAL Answer:  본예산은 국회의 의결을 얻어 확정·성립된 통상적 의미의 예산이며, 수정예산은 정부가 예산을 국회에 제출한 후 국회의 심의·확정 전에 수정하여 제출하는 예산입니다. 준예산은 예산이 법정기한 내에 국회의 의결을 받지 못할 경우에 대비한 예산입니다.\n",
      "\n",
      "162/124\n",
      "Question:  재정수지는 무엇을 판단하기 위한 재정 지표인가? | Context Number | 4215\n",
      "0.9111111111111111 | Answer:  재정수지는 국가의 재정운용을 판단하기 위한 지표로, 정부의 재정수입과 재정지출의 차이를 의미합니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  재정수지는 국가재정의 건전성을 판단하기 위한 재정 지표로, 재정수입과 재정 지출의 차이를 의미합니다.\n",
      "\n",
      "164/124\n",
      "Question:  정부는 언제 재정규모를 축소하고 언제 확대하는가? | Context Number | 5612\n",
      "0.6170212765957446 | Answer:  정부는 경기 호황시 재정규모를 축소하고 불황시 재정규모를 확대합니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  정부는 경기조절을 위해 경기가 호황일 때는 경기의 과열을 막기 위하여 재정규모를 축소하고, 불황일 때에는 경기 회복을 위해 재정규모를 확대합니다.\n",
      "\n",
      "168/124\n",
      "Question:  사회보장성기금은 정부가 어떤 목적을 위해 설치한 기금인가? | Context Number | 3613\n",
      "0.380952380952381 | Answer:  사회보장성기금은 국민의 사회보장에 대한 보장의 원천으로서, 국민의 연금, 노동자들의 산업재해, 노동자들의 노동자보험, 사회보장의 보장을 위해 정부가 설치한 기금입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  국민의 안정적 사회보장을 위해 사회보장 급여 지급을 목적으로 한다.\n",
      "\n",
      "175/124\n",
      "Question:  외국환평형기금채권은 왜 발행하는가? | Context Number | 2714\n",
      "0.9090909090909091 | Answer:  외국환평형기금채권은 1998년 외환위기 이후 외환 보유액 확충을 위해 발행하는 채권입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  외국환평형기금채권은 1998년 외환위기 이후 외환 보유액 확충을 위해 발행된다.\n",
      "\n",
      "178/124\n",
      "Question:  국가채무(D1)는 어떤 지표로 활용되는가? | Context Number | 2670\n",
      "0.5161290322580645 | Answer:  국가채무(D1)는 국가재정법 및 GFSM에 기초하여 현금주의 기준으로 산출한 중앙정부와 지방자치단체의 채무를 의미합니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  국가채무(D1)는 중앙정부와 지방정부의 재정건전성 관리를 위한 지표로 활용된다.\n",
      "\n",
      "179/124\n",
      "Question:  국가채무가 과다할 경우 어떤 위험이 발생할 수 있는가? | Context Number | 3121\n",
      "0.25316455696202533 | Answer:  국가채무가 과다할 경우, 적자성 채무와 금융성 채무로 구분하여, 적자성 채무는 국민의 세금으로 상환해야 하는 채무로, 주로 경기침체로 인한 적자보전용 국채를 발행하거나, 공적자금의 국채전환, 중앙정부가 지방정부에 진 채무 등이 해당되며, 대응자산이 없기 때문에 조세와 같은 국민 부담으로 상환할 수 있다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  국가채무가 과다할 경우 재정의 위험 및 비용이 증가할 수 있다.\n",
      "\n",
      "183/124\n",
      "Question:  우리나라는 언제부터 일반정부부채(D2)를 산출해 왔는가? | Context Number | 2003\n",
      "0.30588235294117644 | Answer:  2003년부터 2006년까지 이루어진 정부보증채무의 국채전환으로 인해 국가채무(D1)가 상대적으로 빠르게 증가한 것을 볼 수 있습니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  우리나라는 2011년부터 국가채무를 작성해 왔다.\n",
      "\n",
      "188/124\n",
      "Question:  국가채무 통계에서 공공부문부채(D3)는 어떤 기준으로 산출되는가? | Context Number | 2139\n",
      "0.8571428571428571 | Answer:  공공부문부채(D3)는 국제지침 (PSDS)에 기초하여 발생주의 기준으로 산출한 일반정부부채(D2)와 비금융공기업을 포괄한 부채입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  공공부문부채(D3)는 PSDS에 기초하여 발생주의 기준으로 산출된 일반정부부채(D2)와 비금융공기업 단위를 포괄한 부채로 나타낸다.\n",
      "\n",
      "190/124\n",
      "Question:  국가보증채무가 국가채무와 어떻게 관련되어 있나요? | Context Number | 2499\n",
      "0.46875 | Answer:  국가보증채무는 주 채무자의 채무상환이 불가능한 경우 국가가 주 채무자 대신 채무이행을 보증하는 채무를 의미합니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  국가보증채무는 국가채무의 범위에 포함되지 않지만, 대신 지급해야 할 사유가 발생하는 경우 국가채무로 전환되기 때문에 국가채무를 관리하는 주요 보조 지표이며, 잠재적 부채 중 하나임\n",
      "\n",
      "192/124\n",
      "Question:  총수입은 무엇을 포함하는가? | Context Number | 2758\n",
      "0.42222222222222217 | Answer:  총수입은 국세수입, 세외수입, 기금수입으로 구성됩니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  국세, 세외수입, 기금수입 등을 통한 일반회계, 특별회계의 예산세입과 기금수입의 총합계에서 내부거래와 보전거래를 제외한 정부 수입을 포함한다.\n",
      "\n",
      "197/124\n",
      "Question:  농어촌특별세와 주세는 어디에 사용되는가? | Context Number | 2881\n",
      "0.4126984126984127 | Answer:  농어촌특별세와 주세는 주민세에 부가됩니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  농어촌특별세와 주세는 각각 농어촌구조개선특별회계 및 국가균형발전특별회계 재원으로 사용된다.\n",
      "\n",
      "198/124\n",
      "Question:  농어촌특별세와 주세의 소관기관은 무엇인가? | Context Number | 3449\n",
      "0.5862068965517241 | Answer:  농어촌특별세와 주세의 소관기관은 지방자치단체입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  농어촌특별세와 주세의 소관기관은 각각 농림축산식품부와 기획재정부이다.\n",
      "\n",
      "199/124\n",
      "Question:  내국세에 포함되는 세목은 총 몇 개이며, 어떤 세목들이 포함되는가? | Context Number | 3388\n",
      "0.49723756906077354 | Answer:  내국세는 총 13종에 대한 세목을 포함합니다. 이 중 직접세는 5종(소득세, 법인세, 상속세, 증여세, 종합부동산세), 간접세는 5종(개별소비세, 주세, 유통세, 취득세, 등록면허세), 목적세는 3종(교통·에너지·환경세, 교육세, 농어촌특별세)입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  내국세에는 주세를 제외한 8개 세목이 포함되며, 소득세, 법인세, 부가가치세, 상속세, 증여세, 개별소비세, 증권거래세, 인지세가 포함된다.\n",
      "\n",
      "202/124\n",
      "Question:  국세 중 목적세에는 어떤 세목이 포함되어 있나요? | Context Number | 3533\n",
      "0.9500000000000001 | Answer:  국세 중 목적세에는 교통·에너지·환경세, 교육세, 농어촌특별세 세목이 포함되어 있습니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  국세 중 목적세에는 교통·에너지·환경세, 교육세, 농어촌특별세가 포함되어 있습니다.\n",
      "\n",
      "204/124\n",
      "Question:  세외수입은 어떤 종류의 수입으로 구성되어 있나요? | Context Number | 1665\n",
      "0.9784172661870504 | Answer:  세외수입은 일반회계와 특별회계의 수입 중 조세 외의 수입으로, 행정서비스에 대한 공과금, 정부 재산에 대한 이용료, 벌금·과태료 성격의 수입 등으로 구성됩니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  세외수입은 일반회계·특별회계 수입 중 조세 외의 수입으로, 행정서비스에 대한 공과금, 정부 재산에 대한 이용료, 벌금·과태료 성격의 수입 등으로 구성됩니다.\n",
      "\n",
      "207/124\n",
      "Question:  기금수입의 주요 원천은 무엇인가? | Context Number | 4339\n",
      "0.5714285714285714 | Answer:  기금수입의 주요 원천은 사회보장기여금수입, 경상이전수입, 재산수입입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  기금수입은 부담금, 정부출연금 등 다양한 재원으로 조성되고, 성질에 따라 사회 보장기여금, 경상이전수입, 재산수입 등으로 구분\n",
      "\n",
      "210/124\n",
      "Question:  조세부담률은 어떻게 정의되며, 어떻게 계산되는가? | Context Number | 2574\n",
      "0.3793103448275862 | Answer:  조세부담률은 국민의 재산과 소득에서 납부해야 하는 조세의 비율을 말하며, 국가 또는 지방자치단체의 일반적 지출을 충당하기 위해 부과되는 보통세와 특정 지출 목적에 한정되어있는 목적세로 구분됩니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  국내총생산(경상GDP)에서 조세수입이 차지하는 비중으로 국민들의 조세부담 정도를 측정하는 지표이며, 조세부담률 = 조세수입/경상GDP = (국세수입+지방세수입)/경상GDP로 계산된다.\n",
      "\n",
      "211/124\n",
      "Question:  조세 부담률과 국민부담률은 무엇을 기준으로 구분되나요? | Context Number | 3295\n",
      "0.4424778761061947 | Answer:  조세 부담률은 조세 수입의 총액을 GDP의 100%에 대한 비율로 계산하는 반면, 국민부담률은 국민의 실제 부담하는 조세 부담 비율을 의미합니다.\n",
      "Before:  0.19161676646706588  |  내용을 요약하면 다음과 같습니다.\n",
      "\n",
      "조세 부담률과 국민부담률은 다음과 같이 구분됩니다.\n",
      "\n",
      "1. 조세 부담률: 조세 부담률은 조세 수입의 총액을 GDP의 100%에 대한 비율을 나타냅니다. 조세 부담률은 조세 수입의 총액을 GDP의 100%에 대한 비율로 계산됩니다.\n",
      "\n",
      "2. 국민부담률: 국민부담률은 조세 부담률보다 더 세분화된 개념으로, 국민의 실제 부담하는 조세 부담 비율을 의미합니다. 국민부담률은 조세 부담률보다 더 세분화된 개념으로, 국민의 실제 부담하는 조세 부담 비율을 의미합니다.\n",
      "\n",
      "이 두 개념의 차이점은 조세 부담률은 조세 수입의 총액을 GDP의 100%에 대한 비율로 계산하는 반면, 국민부담률은 국민의 실제 부담하는 조세 부담 비율을 의미합니다.\n",
      "REAL Answer:  조세 부담률과 국민부담률은 조세수입(국세와 지방세) 외에 사회보장기여금을 포함하는지 여부에 따라 구분됩니다.\n",
      "\n",
      "215/124\n",
      "Question:  한국의 조세수입은 부과 목적에 따라 어떻게 구분되나요? | Context Number | 3853\n",
      "0.41758241758241765 | Answer:  내국세는 부과목적에 따라 직접세, 간접세, 목적세로 구분됩니다.\n",
      "Before:  0.1188118811881188  |  내국세(13)|직접세(5)|간접세(5)|목적세(3)|관세(1)|도세(6)|보통세(4)|목적세(2)|시·군세(5)|보통세(5)|\n",
      "\n",
      "내국세(13) |직접세(5) |간접세(5)|목적세(3)|관세(1)|도세(6)|보통세(4)|목적세(2)|시·군세(5)|보통세(5)|\n",
      "REAL Answer:  한국의 조세수입은 국가 또는 지방자치 단체의 일반적 지출을 충당하기위해 부과되는 보통세와 특정 지출 목적에 한정되어있는 목적세로 구분됩니다.\n",
      "\n",
      "219/124\n",
      "Question:  기획재정부는 언제부터 중앙정부 재정지출 규모를 총지출 기준으로 산출하여 발표하기 시작했는가? | Context Number | 5249\n",
      "0.17142857142857143 | Answer:  2020년.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  기획재정부는 2004년 「2005~2009년 국가재정운용계획」에 중앙정부 재정지출 규모를 총지출 기준으로 산출하여 발표하기 시작하였다.\n",
      "\n",
      "224/124\n",
      "Question:  기금은 기능 및 주체에 따라 어떻게 구분되는가? | Context Number | 4705\n",
      "0.7945205479452055 | Answer:  기금은 기능 및 주체에 따라 계정성기금, 사업성기금, 사회보험성기금으로 구분됩니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  기금은 사회보험성기금, 계정성기금, 금융성기금, 사업성기금으로 구분된다.\n",
      "\n",
      "231/124\n",
      "Question:  예산의 목적외 사용 금지 원칙에 대한 예외가 허용되는 경우는 어떤 경우인가? | Context Number | 3141\n",
      "0.5739130434782609 | Answer:  예산의 목적외 사용 금지 원칙에 대한 예외로 허용되는 경우는 이용, 전용, 이체가 있습니다.\n",
      "Before:  0.47826086956521746  |  예산의 목적외 사용 금지 원칙에 대한 예외가 허용되는 경우는 다음 세 가지가 있습니다.\n",
      "\n",
      "1.  이용: 예산이 정한 각 기관, 장(분야), 관(부문), 항(프로그램)에 편성된 금액을 상호 융통하는 제도\n",
      "2.  전용: 예산이 정한 각 세항 (단위사업), 목에 편성된 금액을 상호 융통하는 제도\n",
      "3.  이체: 정부조직의 권한에 변동이 있는 경우 관련 예산의 소관을 변경하는 제도\n",
      "REAL Answer:  예산의 변경에 해당되는 이용, 전용, 조정, 이체는 예측하지 못했던 이유로 신축적인 예산운용이 필요할 경우에 대비하여 예산의 목적외 사용 금지 원칙에 대한 예외를 허용하는 경우임\n",
      "\n",
      "236/124\n",
      "Question:  국가채무(D1)는 어떤 지표로 활용되며, 과다할 경우 어떤 위험이 발생하고, 관련된 대표적인 보고서는 무엇인가? | Context Number | 4097\n",
      "0.43171806167400884 | Answer:  국가채무(D1)는 국가의 재정수지 상 세입부족액을 보전하여 수지 균형을 위해 국가가 발행하는 채권, 정부가 한국은행, 민간기관 또는 국제기금 등으로부터 법정 유가증권 발행 없이 차입하는 금액, 국고채무부담행위, 정부가 주 채무자 대신 채무를 이행하기로 확정된 채무를 포함하는 금전채무의 규모입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  국가채무(D1)는 중앙정부와 지방정부의 재정건전성 관리를 위한 지표로 활용되며, 과다할 경우 재정의 위험 및 비용이 증가할 수 있다. 관련된 대표적인 보고서로는 '국가 채무관리계획'과 '국가채무관리보고서'가 있다.\n",
      "\n",
      "238/124\n",
      "Question:  농어촌특별세와 주세는 어디에 사용되며, 각각의 소관기관은 무엇인가? | Context Number | 4273\n",
      "0.4587155963302752 | Answer:  농어촌특별세는 농어촌특별회계에, 주세는 주민세에 사용됩니다.\n",
      "Before:  0.45454545454545453  |  |\n",
      "\n",
      "농어촌특별세는 농어촌특별회계에, 주세는 주민세에 사용됩니다.\n",
      "REAL Answer:  농어촌특별세는 농어촌구조개선특별회계에, 주세는 국가균형발전특별회계 재원으로 사용된다. 농어촌특별세의 소관기관은 농림축산식품부이며, 주세의 소관기관은 기획재정부이다.\n",
      "\n",
      "240/124\n",
      "Question:  관세의 정의와 관세 행정사무를 담당하는 기관은 무엇인가? | Context Number | 3369\n",
      "0.5555555555555555 | Answer:  관세의 정의와 관세 행정사무를 담당하는 기관은 관세청입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  관세는 수입되는 물건에 부과하는 조세이며, 관세 행정사무는 기획재정부 산하 조직인 관세청이 담당한다.\n",
      "\n",
      "245/124\n",
      "Question:  이월이란 무엇을 의미하며, 이월명세서를 작성하여 제출해야 하는 기한은 언제인가? | Context Number | 3330\n",
      "0.4774193548387096 | Answer:  이월이란 예산의 잔여금을 의미하며, 이월명세서를 작성하여 제출해야 하는 기한은 2월 말까지입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  이월은 세출예산 중 회계연도 내에 지출하지 못한 금액을 다음 회계연도의 세출 예산에 합산하여 반영하는 것을 의미합니다. 이월명세서를 작성하여 제출해야 하는 기한은 12월 31일 기준으로 작성하여 1월 31일까지 기획재정부장관과 감사원에 제출해야 합니다.\n",
      "\n",
      "255/124\n",
      "Question:  정부의 예비비는 주로 어떤 상황에서 사용되며, 그 사용의 법적 기준은 무엇인가요? | Context Number | 4064\n",
      "0.4981132075471698 | Answer:  정부의 예비비는 예측할 수 없는 지출로 인한 예산의 부족에 대비해 두는 비용으로, 일반 예비비와 목적 예비비로 구분됩니다. 일반 예비비는 특정한 목적 없이 예산 편성 시점에서 예측할 수 없는 재정 지출 소요를 충당하기 위한 예비비이며, 목적 예비비는 그 사용 목적이 예산 총칙 등을 통하여 제한되어 있는 예비비입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  정부의 예비비는 주로 예상치 못한 긴급 상황이나 자연재해, 경제 위기 등 예측 불가능한 상황에서 사용됩니다. 예비비의 사용은 국가재정법에 의해 엄격히 규제되며, 예비비 사용 시 대통령의 승인을 받아야 한다. 이는 예비비가 한정적이고 중요한 자원이기 때문에 효율적이고 적절한 사용이 이루어져야 하기 때문입니다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leo97\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/124\n",
      "Question:  주택도시기금의 소관 기관은 무엇인가요? | Context Number | 2386\n",
      "0.3846153846153846 | Answer:  주택도시기금의 소관 기관은 국토교통부입니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  국토교통부\n",
      "\n",
      "257/124\n",
      "Question:  전세임대 정책은 어떤 근거로 추진되고 있는가? | Context Number | 2386\n",
      "0.0634920634920635 | Answer:  전세임대 정책은 주거복지 강화와 주거비 부담 완화를 위해 추진되고 있습니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  주택도시기금법 제9조, 공공주택 특별법 제3조의2 및 제45조의2\n",
      "\n",
      "258/124\n",
      "Question:  '17년 11월에 발표된 사회통합형 주거사다리 구축을 위한 주거복지로드맵에는 어떤 내용이 포함되어 있나요? | Context Number | 2386\n",
      "0.4235294117647059 | Answer:  사회통합형 주거사다리 구축을 위한 주거복지로드맵에는 '18~'22년까지 임차형 17만호가 공급되며, 주요 내용은 총사업비 4,546,931만원, 사업기간은 '05년부터 계속, 사업시행주체는 한국토지주택공사, 지방공사, 사업 수혜자는 생계·의료급여 수급자, 보호대상 한부모가정 등 도시근로자 월평균소득의 50% 이하이며 보조, 융자, 출연, 출자 등의 경우 보조․융자 등 지원 비율은 80~100%이다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  2017년 11월에 발표된 사회통합형 주거사다리 구축을 위한 주거복지로드맵에는 2018~2022년간 임차형 17만호 공급에 관한 내용이 포함되어 있습니다.\n",
      "\n",
      "259/124\n",
      "Question:  '18년 7월에 발표된 신혼부부·청년 주거지원방안에는 어떤 내용이 포함되어 있나요? | Context Number | 2386\n",
      "0.88 | Answer:  신혼부부·청년 주거지원방안에는 신혼부부 전세임대Ⅱ, 기숙사형 신규 도입 등이 포함되어 있습니다.\n",
      "Before:  0.7766990291262136  |  신혼부부·청년 주거지원방안에 포함된 내용은 다음과 같습니다.\n",
      "\n",
      "신혼부부 전세임대Ⅱ, 기숙사형 신규 도입 등\n",
      "REAL Answer:  '18년 7월에 발표된 신혼부부·청년 주거지원방안에는 '신혼부부 전세임대Ⅱ, 기숙사형 신규 도입' 등이 포함되어 있습니다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leo97\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/124\n",
      "Question:  청년일자리도약장려금 사업 집행절차는 어떤 단계로 되어 있나요? | Context Number | 1428\n",
      "0.4042553191489362 | Answer:  청년일자리도약장려금과 빈일자리청년취업지원금의 사업 집행절차는 다음과 같습니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  사업 집행절차에는 사업 참여신청, 기업 참여 승인, 청년 채용 및 지원금 신청, 지원금 지급 요청, 지원금 지급이 포함되어 있습니다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leo97\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/124\n",
      "Question:  내일배움카드(일반)의 예산은 2022년부터 2024년까지 어떻게 변화하고 있는가? | Context Number | 2610\n",
      "0.7445255474452553 | Answer:  2022년 322,799백만, 2023년 518,815백만, 2024년 584,906백만으로 증가하고 있습니다.\n",
      "Before:  None  |  None\n",
      "REAL Answer:  내일배움카드(일반)의 예산은 2022년 322,799백만원에서 2023년 518,815백만원으로 증가하고, 2024년에는 584,906백만원으로 더 증가하는 추세이다.\n",
      "\n",
      "279/124\n",
      "Question:  평생크레딧에 대한 사업 집행절차는 어떻게 이루어지는가? | Context Number | 3607\n",
      "0.8761904761904761 | Answer:  평생크레딧의 사업 집행절차는 훈련과정 선정, 훈련생의 국민내일배움카드 발급 및 훈련 참여, 훈련비 등 지급으로 이루어집니다.\n",
      "Before:  0.3881856540084388  |  평생크레딧의 사업 집행절차는 다음과 같이 이루어집니다.\n",
      "\n",
      "1. 훈련과정 선정: 평생크레딧을 지원하는 훈련과정이 선정됩니다.\n",
      "2. 훈련생의 국민내일배움카드 발급 및 훈련 참여: 훈련생에게 국민내일배움카드를 발급하고 훈련에 참여하도록 합니다.\n",
      "3. 훈련비 등 지급: 훈련비 및 기타 지원금을 지급합니다.\n",
      "\n",
      "평생크레딧의 사업 집행절차는 훈련과정 선정, 훈련생의 국민내일배움카드 발급 및 훈련 참여, 훈련비 등 지급으로 이루어집니다.\n",
      "REAL Answer:  평생크레딧 사업은 훈련과정 선정, 훈련생의 국민내일배움카드 발급 및 훈련참여, 훈련비 등의 집행절차가 있습니다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leo97\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# import copy\n",
    "\n",
    "# # weight = [0.3,0.3,0.4]\n",
    "# # train_faiss_db,knn_retriever ,train_bm_retrievier = make_db(train_df) \n",
    "\n",
    "# # train_k = 3\n",
    "# # train_bm_retrievier.k = train_k\n",
    "# # knn_retriever.k = train_k\n",
    "# # train_faiss_retriever = train_faiss_db.as_retriever(search_type=\"mmr\",search_kwargs={'k':train_k} )\n",
    "# # train_ensemble_retriever = EnsembleRetriever(\n",
    "# #     retrievers=[train_bm_retrievier, knn_retriever,train_faiss_retriever], weights=weight , search_kwargs={'k':train_k}\n",
    "# # )\n",
    "\n",
    "\n",
    "# # fewshot_k = 3\n",
    "\n",
    "# k_folds = 4\n",
    "# fold_results = []\n",
    "# kf = KFold(n_splits=k_folds, shuffle=True, random_state=52)\n",
    "# for fold, (train_index, val_index) in enumerate(kf.split(train_df)):\n",
    "#     fold_result = []\n",
    "#     train_set = train_df.iloc[train_index]\n",
    "#     val_set = train_df.iloc[val_index]\n",
    "\n",
    "#     faiss = make_db(val_set)\n",
    "\n",
    "#     pred = run(faiss,val_set, llm, verbose=True)\n",
    "#     result = pd.DataFrame()\n",
    "#     result['pred'] = [result['Answer'] for result in pred]\n",
    "#     val_set.index = range(len(val_set))\n",
    "#     result['gt'] = val_set['Answer']\n",
    "        \n",
    "#     result = calculate_average_f1_score(result['gt'], result['pred'])\n",
    "#     print(result)\n",
    "#     fold_results.append(result)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from save_module import save\n",
    "\n",
    "\n",
    "weight = [0.5,0.5]\n",
    "test_faiss_db, test_bm_retrievier = make_db(test_df)\n",
    "\n",
    "test_k = 3\n",
    "test_bm_retrievier.k = test_k\n",
    "#test_knn_retriever.k = test_k\n",
    "test_faiss_retriever = test_faiss_db.as_retriever(search_type=\"mmr\",search_kwargs={'k':test_k} )\n",
    "test_ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[test_bm_retrievier, test_faiss_retriever], weights=weight\n",
    ")\n",
    "\n",
    "\n",
    "results = run(test_ensemble_retriever, test_df, llm, verbose=True)\n",
    "save(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
