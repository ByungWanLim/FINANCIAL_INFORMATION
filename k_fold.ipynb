{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import torch\n",
    "from faiss_module import load_and_vectorize,load_chunks_make_docdb, make_db, make_fewshot_db\n",
    "from model import setup_llm_pipeline\n",
    "from fewshot_module import fewshot_ex\n",
    "from save_module import save\n",
    "from seed_module import seed_everything\n",
    "from utils_module import make_dict, extract_answer, format_docs\n",
    "from run import run\n",
    "seed_everything(52)\n",
    "from sklearn.model_selection import KFold\n",
    "def calculate_f1_score(true_sentence, predicted_sentence, sum_mode=True):\n",
    "\n",
    "    #공백 제거\n",
    "    true_sentence = ''.join(true_sentence.split())\n",
    "    predicted_sentence = ''.join(predicted_sentence.split())\n",
    "    \n",
    "    true_counter = Counter(true_sentence)\n",
    "    predicted_counter = Counter(predicted_sentence)\n",
    "\n",
    "    #문자가 등장한 개수도 고려\n",
    "    if sum_mode:\n",
    "        true_positive = sum((true_counter & predicted_counter).values())\n",
    "        predicted_positive = sum(predicted_counter.values())\n",
    "        actual_positive = sum(true_counter.values())\n",
    "\n",
    "    #문자 자체가 있는 것에 focus를 맞춤\n",
    "    else:\n",
    "        true_positive = len((true_counter & predicted_counter).values())\n",
    "        predicted_positive = len(predicted_counter.values())\n",
    "        actual_positive = len(true_counter.values())\n",
    "\n",
    "    #f1 score 계산\n",
    "    precision = true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    recall = true_positive / actual_positive if actual_positive > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def calculate_average_f1_score(true_sentences, predicted_sentences):\n",
    "    \n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1_score = 0\n",
    "    \n",
    "    for true_sentence, predicted_sentence in zip(true_sentences, predicted_sentences):\n",
    "        precision, recall, f1_score = calculate_f1_score(true_sentence, predicted_sentence)\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1_score += f1_score\n",
    "    \n",
    "    avg_precision = total_precision / len(true_sentences)\n",
    "    avg_recall = total_recall / len(true_sentences)\n",
    "    avg_f1_score = total_f1_score / len(true_sentences)\n",
    "    \n",
    "    return {\n",
    "        'average_precision': avg_precision,\n",
    "        'average_recall': avg_recall,\n",
    "        'average_f1_score': avg_f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:24<00:00,  6.02s/it]\n"
     ]
    }
   ],
   "source": [
    "k_folds = 4\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=52)\n",
    "train_df = pd.read_csv('train.csv')\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "llm = setup_llm_pipeline(model_id)\n",
    "fold_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/4\n",
      "Loading FAISS DB from: ./train_faiss_db\n",
      "Loaded Fewshot Set: [{'Source': '1-1 2024 주요 재정통계 1권', 'Source_path': './train_source/1-1 2024 주요 재정통계 1권.pdf', 'Question': '2024년 중앙정부 재정체계는 어떻게 구성되어 있나요?', 'Answer': '2024년 중앙정부 재정체계는 예산(일반·특별회계)과 기금으로 구분되며, 2024년 기준으로 일반회계 1개, 특별회계 21개, 기금 68개로 구성되어 있습니다.'}]\n",
      "Creating FAISS DB\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/124 [00:35<1:13:33, 35.88s/it]"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, val_index) in enumerate(kf.split(train_df)):\n",
    "    fold_results = []\n",
    "    print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "    # 수정된 부분: .iloc[] 사용\n",
    "    train_set = train_df.iloc[train_index]\n",
    "    val_set = train_df.iloc[val_index]\n",
    "    \n",
    "    train_db = make_db(train_set,'./train_faiss_db')\n",
    "\n",
    "    fewshot_db = make_fewshot_db(train_set,None)\n",
    "    \n",
    "    pred = results = run(train_db= train_db,\n",
    "        test_db= train_db,\n",
    "        fewshot_db=fewshot_db, \n",
    "        dataset= val_set.to_dict(orient='records') ,\n",
    "        llm=llm,\n",
    "        varbose=False)\n",
    "    result = pd.DataFrame()\n",
    "    result['pred'] = [result['Answer'] for result in pred]\n",
    "    val_set.index = range(len(val_set))\n",
    "    result['gt'] = val_set['Answer']\n",
    "        \n",
    "    result = calculate_average_f1_score(result['gt'], result['pred'])\n",
    "    print(result)\n",
    "    fold_result.append(result)\n",
    "    break\n",
    "    fewshot_db = None\n",
    "    train_db = None\n",
    "    val_db = None\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "# 모든 fold의 결과를 집계하고 메트릭 계산\n",
    "all_results = [result for fold_result in fold_results for result in fold_result]\n",
    "print(f\"Average F1 Score: {np.mean([result['average_f1_score'] for result in all_results])}\")\n",
    "print(f\"Average Precision: {np.mean([result['average_precision'] for result in all_results])}\")\n",
    "print(f\"Average Recall: {np.mean([result['average_recall'] for result in all_results])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "context위치변경\n",
    "\n",
    "1트 \n",
    "\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "Now Do it for real.<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Question: {input}\\n\\nContext: {context}<|eot_id|>\n",
    "\n",
    "k-fold 0.63\n",
    "\n",
    "2트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new prompt 예제에서 context에서 answer를 도출했다고 말함 그리고 그런식으로 작성하라고 함\n",
    "\n",
    "temp = 0.4, topp = 0.6 repetition_penalty = 1.1\n",
    "\n",
    "fewshot num = 3, fewshot context = 1 , context = 2 청크 512, 오버랩 64, \n",
    "\n",
    "LB: \n",
    "\n",
    "fold 1:0.6356956690740023 (원래)\n",
    "\n",
    "\n",
    "(NeW)\n",
    "LB: 0.5846913577\n",
    "\n",
    "fold 1 0.6375135913067492\n",
    " \n",
    " \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "Today Date: 8 Aug 2024\n",
    "\n",
    "You are the financial expert who helps me with my financial information Q&As.\n",
    "You earn 10 points when you answer me and follow the rules and lose 7 points when you don't.\n",
    "\n",
    "12,500 백만원 = 125 억원 = 12,500,000,000 원\n",
    "5,400 백만원 = 54 억원 = 5,400,000,000 원\n",
    "\n",
    "Here are some rules you should follow.\n",
    "- Please use contexts to answer the question.\n",
    "- Please your answers should be concise.\n",
    "- Please answers must be written in Korean.\n",
    "- Please answer the question in 1-3 sentences.\n",
    "\n",
    "Please learn the answering like examples below.<|eot_id|>\n",
    "\"\"\" +f\"{fewshot_str}\" + \"\"\"<|start_header_id|>system<|end_header_id|>\n",
    "Now Do it for real.\n",
    "Given the following contexts about Question:\n",
    "{context}<|start_header_id|>user<|end_header_id|>\n",
    "{input}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\\n\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search_type=\"similarity_score_threshold\"\n",
    "temp = 0.4, topp = 0.6 repetition_penalty = 1.1\n",
    "\n",
    "fewshot num = 3, fewshot context = 1 , context = 2 청크 512, 오버랩 64, \n",
    "\n",
    "LB: 0.6014109705\t\n",
    "\n",
    "fold 1: 0.6478771022993277\n",
    "\n",
    "~~\n",
    "\n",
    "fewshot num = 3, fewshot context = 1 , context = 5 청크 512, 오버랩 64, \n",
    "\n",
    "LB: 0.5791770154\n",
    "\n",
    "fold 1: 0.661329586886551\n",
    "\n",
    "~~\n",
    "\n",
    "fewshot num = 3, fewshot context = 0 , context = 5 청크 512, 오버랩 64, \n",
    "\n",
    "LB: 0.5722539904\n",
    "\n",
    "fold 1: 0.6533704753399003\n",
    "\n",
    "\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "Today Date: 8 Aug 2024\n",
    "1,000,000 원= 100 만원\n",
    "10 백만원 = 10,000,000 원\n",
    "100 백만원 = 100,000,000 원\n",
    "100 백만원 = 1 억원\n",
    "1,000 백만원 = 10 억원\n",
    "You are the financial expert who helps me with my financial information Q&As.\n",
    "You earn 10 points when you answer me and follow the rules and lose 7 points when you don't.\n",
    "\n",
    "Here are some rules you should follow.\n",
    "- Please use contexts to answer the question.\n",
    "- Please your answers should be concise.\n",
    "- Please answers must be written in Korean.\n",
    "- Please answer the question in 1-3 sentences.\n",
    "\n",
    "Please answer like the example below.<|eot_id|>\n",
    "\"\"\" +f\"{fewshot_str}\" + \"\"\"<|start_header_id|>system<|end_header_id|>\n",
    "Now Do it for me.\n",
    "Given the following contexts about Question:\n",
    "{context}<|start_header_id|>user<|end_header_id|>\n",
    "{input}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\\n\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp = 0.4, topp = 0.6 repetition_penalty = 1.1\n",
    "\n",
    "fewshot num = 3, fewshot context = 1 , context = 3 청크 512, 오버랩 64, \n",
    "\n",
    "LB: \n",
    "\n",
    "fold 1: 0.7253077903895752\n",
    "\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp = 0.2, topp = 0.6 repetition_penalty = 1.1\n",
    "\n",
    "fewshot num = 3, fewshot context = 1 , context = 3\n",
    "\n",
    "LB: \n",
    "\n",
    "fold 1:  0.6544007302469212\n",
    "\n",
    "temp = 0.1, topp = 0.7 repetition_penalty = 1.1\n",
    "\n",
    "fewshot num = 3, fewshot context = 1 , context = 3\n",
    "\n",
    "LB: \n",
    "\n",
    "fold 1:  0.6554498759729692"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp = 0.4, topp = 0.6 repetition_penalty = 1.1\n",
    "\n",
    "fewshot num = 3, fewshot context = 3 , context = 3\n",
    "\n",
    "LB: 0.5859080344\n",
    "\n",
    "fold 1: 0.6586463841048915"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp = 0.4, topp = 0.6 repetition_penalty = 1.1\n",
    "\n",
    "fewshot num = 3, fewshot context = 0 , context = 3\n",
    "\n",
    "LB: \n",
    "\n",
    "fold 1: 0.6381098591323223"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp = 0.4, topp = 0.6 repetition_penalty = 1.1\n",
    "\n",
    "fewshot num = 10, fewshot context = 0 , context = 3\n",
    "\n",
    "LB: \n",
    "\n",
    "fold 1: 0.6327671925994144"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
