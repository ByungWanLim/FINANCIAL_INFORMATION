{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faiss_module import load_and_vectorize,load_chunks_make_docdb\n",
    "from model import setup_llm_pipeline\n",
    "from fewshot_module import fewshot_ex\n",
    "from save_module import save\n",
    "from seed_module import seed_everything\n",
    "from utils_module import make_dict, extract_answer, format_docs\n",
    "from run import run\n",
    "seed_everything(52)\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 4\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "train_dict = make_dict('train.csv')\n",
    "# train에도 RAG를 쓸 때 사용\n",
    "train_db = load_chunks_make_docdb('./train_source', './train_faiss_db')\n",
    "train_retriever = train_db.as_retriever(search_kwargs={'k': 1})\n",
    "\n",
    "test_retriver = train_db.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "fewshot_db = load_and_vectorize('train.csv', './fewshot_faiss_db')\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "llm = setup_llm_pipeline(model_id)\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_dict)):\n",
    "    print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "    train_set = [train_dict[i] for i in train_index]\n",
    "    val_set = [train_dict[i] for i in val_index]\n",
    "    run(train_retriever,\n",
    "        test_retriver,\n",
    "        fewshot_db, \n",
    "        val_set ,\n",
    "        llm)\n",
    "\n",
    "        # K-fold 교차 검증을 위한 데이터 분할\n",
    "        kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "        \n",
    "        fold_results = []\n",
    "        \n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(train_dict)):\n",
    "            print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "            \n",
    "            # 현재 fold에 대한 학습 및 검증 데이터 설정\n",
    "            train_set = [train_dict[i] for i in train_index]\n",
    "            val_set = [train_dict[i] for i in val_index]\n",
    "            \n",
    "            # 현재 fold에 대한 데이터베이스 설정\n",
    "            train_db = load_chunks_make_docdb('./train_source', './train_faiss_db')\n",
    "            train_retriever = train_db.as_retriever(search_kwargs={'k': 1})\n",
    "            \n",
    "            # 검증 데이터베이스 설정\n",
    "            val_db = load_chunks_make_docdb('./val_source', './val_faiss_db')\n",
    "            val_retriever = val_db.as_retriever(search_kwargs={'k': 5})\n",
    "            \n",
    "            fewshot_db = load_and_vectorize('train.csv', './fewshot_faiss_db')\n",
    "            llm = setup_llm_pipeline(model_id)\n",
    "            \n",
    "            fold_results.append([])\n",
    "            \n",
    "            for item in tqdm(val_set):\n",
    "                fewshot_str = fewshot_ex(fewshot_db, item, train_retriever=train_retriever, fewshot_num=7)\n",
    "                \n",
    "                full_template = \"\"\"system\n",
    "Today Date: 8 Aug 2024\n",
    "1,000,000 원= 100 만원\n",
    "10 백만원 = 10,000,000 원\n",
    "100 백만원 = 100,000,000 원\n",
    "You are the financial expert who helps me with my financial information Q&As.\n",
    "You earn 10 points when you answer me and follow the rules and lose 7 points when you don't.\n",
    "\n",
    "Here are some rules you should follow.\n",
    "- Please use contexts to answer the question.\n",
    "- Please your answers should be concise.\n",
    "- Please answers must be written in Korean.\n",
    "- Please answer the question in 1-3 sentences.\n",
    "\n",
    "Please answer like the example below.\n",
    "\"\"\" + f\"{fewshot_str}\" + \"\"\"system\n",
    "Now Do it for me.\n",
    "Given the following contexts about Question:\n",
    "{context}user\n",
    "{input}\n",
    "assistant\\n\\n\n",
    "\"\"\"\n",
    "                prompt = PromptTemplate.from_template(full_template)\n",
    "                qa_chain = (\n",
    "                {\n",
    "                    \"context\": val_retriever | format_docs,\n",
    "                    \"input\": RunnablePassthrough(),\n",
    "                }\n",
    "                | prompt\n",
    "                | llm\n",
    "                | StrOutputParser()\n",
    "                )\n",
    "                \n",
    "                answer = qa_chain.invoke(item['Question'])\n",
    "                answer = extract_answer(answer)\n",
    "                result = {\n",
    "                    \"Question\": item['Question'],\n",
    "                    \"Answer\": answer,\n",
    "                    \"Source\": item['Source']\n",
    "                }\n",
    "                fold_results[-1].append(result)\n",
    "                print(f\"Question: {item['Question']}\\nAnswer: {result['Answer']}\")\n",
    "            \n",
    "            # 현재 fold에 대한 결과 저장\n",
    "            fold_save_path = f\"fold_{fold + 1}_results.json\"\n",
    "            save(fold_results[-1], path=fold_save_path)\n",
    "        \n",
    "        # 모든 fold의 결과를 집계하고 메트릭 계산\n",
    "        all_results = [result for fold_result in fold_results for result in fold_result]\n",
    "        \n",
    "        # 예시로 정확도 계산, 필요에 따라 조정\n",
    "        # y_true, y_pred를 정의하여 정확도 계산\n",
    "        # accuracy = accuracy_score(y_true, y_pred)  # 예시\n",
    "        \n",
    "        # 집계된 결과 저장\n",
    "        aggregate_save_path = \"aggregate_results.json\"\n",
    "        save(all_results, path=aggregate_save_path)\n",
    "        \n",
    "        print(\"K-fold 교차 검증이 완료되었습니다.\")\n",
    "    else:\n",
    "        # 검증을 수행하지 않을 경우\n",
    "        print(\"검증을 수행하지 않습니다.\")\n",
    "        # 기본적인 run 함수를 호출하여 전체 데이터에 대해 실행\n",
    "        run(model_id=model_id)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
