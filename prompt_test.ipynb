{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import os\n",
    "from glob import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_huggingface import HuggingFacePipeline ,HuggingFaceEmbeddings\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pandas as pd\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import (\n",
    "    FewShotPromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "import pickle\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "\n",
    "from faiss_module import load_and_vectorize,load_chunks_make_docdb\n",
    "from model import setup_llm_pipeline\n",
    "from save import save\n",
    "from seed import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS DB from: ./fewshot_faiss_db\n",
      "Loading FAISS DB from: ./train_faiss_db\n",
      "Loading FAISS DB from: ./test_faiss_db\n"
     ]
    }
   ],
   "source": [
    "def make_dict(dir='train.csv'):\n",
    "    df = pd.read_csv(dir)\n",
    "    df.drop('SAMPLE_ID', axis=1, inplace=True)\n",
    "    \n",
    "    return df.to_dict(orient='records')\n",
    "\n",
    "def make_fewshot_prompt(fewshot_vectordb, k = 10):\n",
    "    # Semantic Similarity Example Selector 설정\n",
    "    example_prompt = PromptTemplate.from_template(\"<|start_header_id|>user<|end_header_id|>: <|begin_of_text|>{Question}<|end_of_text|>\\n<|start_header_id|>assistant<|end_header_id|>: <|begin_of_text|>{Answer}<|end_of_text|>\")\n",
    "\n",
    "    example_selector = SemanticSimilarityExampleSelector(\n",
    "        vectorstore=fewshot_vectordb,\n",
    "        k=k,\n",
    "    )\n",
    "\n",
    "    # FewShotPromptTemplate 생성\n",
    "    fewshot_prompt = FewShotPromptTemplate(\n",
    "        example_selector=example_selector,\n",
    "        example_prompt=example_prompt,\n",
    "        suffix=\"Question: {input}\",\n",
    "        input_variables=[\"input\"],\n",
    "    )\n",
    "    return fewshot_prompt\n",
    "\n",
    "def make_fewshot_string(fewshot_prompt, train_retriever, buff):\n",
    "    ex_qa = fewshot_prompt.invoke({\"input\": buff['Question']}).to_string()\n",
    "    fewshot_list = ex_qa.split('\\n\\n')[:-1]\n",
    "    for i, entry in enumerate(fewshot_list):\n",
    "        question = entry.split('\\n')[0]\n",
    "        question = question.replace('Question: ', '')\n",
    "        retrieved_docs = train_retriever.invoke(question)\n",
    "        num = \"Example {}\\n\".format(i+1)\n",
    "        fewshot_list[i] = num + \"<|start_header_id|>context<|end_header_id|>: <|begin_of_text|>\" + entry + '<|end_of_text|>\\n\\n##################################################'\n",
    "    return str(fewshot_list)\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n",
    "    context = \"\"\n",
    "    for doc in docs:\n",
    "        context += doc.page_content\n",
    "        context += '\\n\\n'\n",
    "    return context\n",
    "\n",
    "def extract_answer(response):\n",
    "    # AI: 로 시작하는 줄을 찾아 그 이후의 텍스트만 추출\n",
    "    lines = response.split('\\n')\n",
    "    for line in lines:\n",
    "        if line.startswith('Answer:'):\n",
    "            return line.replace('Answer:', '').strip()\n",
    "        if line.startswith('assistant:'):\n",
    "            return line.replace('assistant:', '').strip()\n",
    "    return response.strip()  # AI: 를 찾지 못한 경우 전체 응답을 정리해서 반환\n",
    "\n",
    "fewshot_db = load_and_vectorize('train.csv', './fewshot_faiss_db')\n",
    "fewshot_prompt = make_fewshot_prompt(fewshot_db)\n",
    "\n",
    "train_db = load_chunks_make_docdb('./train_source', './train_faiss_db')\n",
    "train_retriever = train_db.as_retriever(search_type = \"mmr\",search_kwargs={'k': 1})\n",
    "\n",
    "test_db = load_chunks_make_docdb('./test_source', './test_faiss_db')\n",
    "test_retriver = test_db.as_retriever(search_type = \"mmr\",search_kwargs={'k': 3})\n",
    "\n",
    "train_dict = make_dict('train.csv')\n",
    "test_dict = make_dict('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.89s/it]\n",
      "c:\\ProgramData\\anaconda3\\envs\\llm_project\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q19================================================\n",
      "Questions:  노인장기요양보험법이 언제 제정되고 공포되었나?\n",
      "Answer:  노인장기요양보험법은 2008년 3월 4일 제정, 2008년 4월 4일 공포되었습니다.\n",
      "Q24================================================\n",
      "Questions:  에너지바우처 사업의 주요 수혜자는 누구인가요?\n",
      "Answer:  에너지바우처 사업의 주요 수혜자는 저소득층 및 취약계층입니다.\n",
      "Q57================================================\n",
      "Questions:  재정성과관리제도는 어떤 측면에서 국정운영과 연결되는가?\n",
      "Answer:  재정성과관리제도는 국정운영과 연결되는 측면은 다음과 같습니다.\n",
      "\n",
      "1.  성과관리의 내용을 성과목표관리 및 성과평가로 구체화하여 국정운영을 위한 전략을 수립하고, 성과보고서를 작성하여 국무회의에 보고하여 성과중심 재정운용을 확대하고 강화하는 데 기여합니다.\n",
      "2.  재정사업 성과관리의 기본계획을 수립하고, 성과보고서를 작성하고 성과평가 근거를 마련하여 국정운영을 위한 전략을 수립하고, 성과를 중시하여 재정운용을 확대하고 강화하는 데 기여합니다.\n",
      "3.  재정사업 성과목표를 위한 추진체계를 마련하여 국정운영을 위한 전략을 수립하고, 성과를 중시하여 재정운용을 확대하고 강화하는 데 기여합니다.\n",
      "4.  성과정보관리시스템을 구축하고 운영하여 성과를 중시하여 재정운용을 확대하고 강화하는 데 기여하고, 정보를 전자\n",
      "Q58================================================\n",
      "Questions:  성과관리의 실효성 강화를 위해 정부가 취한 조치는 무엇인가?\n",
      "Answer:  정부는 성과관리의 실효성 강화를 위해 다음과 같은 조치를 취했습니다.\n",
      "\n",
      "1. 2021년 「국가재정법」 개정: 성과관리의 내용을 성과목표관리 및 성과평가로 구체화하고, 재정사업 성과관리 기본계획 수립, 성과보고서 작성 및 성과평가 근거 마련, 재정사업 성과목표 관리를 위한 추진체계 마련, 성과정보관리시스템 구축 및 운영, 성과목표 관리 결과를 국무회의에 보고하여 성과 중심 재정운용 확대 및 강화하는 등 5가지 조치를 마련했습니다.\n",
      "\n",
      "2. 성과정보관리시스템 운영 및 정보공개를 위한 시스템 전자 연계 요구권 설정: 재정사업 평가 결과 정보의 전자 매체를 통한 공개가 더욱 확대되어 재정 투명성 강화에 기여\n",
      "\n",
      "3. 성과관리의 내용을 성과목표관리 및 성과평가로 구체화: 성과목표를 구체화하고, 성과평가의 근거를 마련하여 성과관리의 실효성을 강화\n",
      "Q61================================================\n",
      "Questions:  재정성과관리는 무엇을 목표로 하는가?\n",
      "Answer:  재정성과관리는 재정사업의 성과를 관리하기 위해 성과목표를 설정하고, 성과목표를 달성하기 위해 필요한 계획을 수립하고, 성과를 평가하고, 성과를 공유하고, 성과를 기반으로 재정운용을 강화하는 것을 목표로 한다.\n",
      "Q65================================================\n",
      "Questions:  성과관리제도는 지출 구조조정을 위해 어떤 방향으로 추진되고 있는가?\n",
      "Answer:  성과관리제도는 지출 구조조정을 위해 다음과 같은 방향으로 추진되고 있습니다.\n",
      "\n",
      "1.  성과정보를 바탕으로 한 재정운영의 노력은 미래의 성과를 예측하고, 성과를 달성하기 위한 노력을 강조하기 위해 시작되었습니다.\n",
      "2.  재정의 목적 달성 여부는 효율성, 형평성 등 다양한 가치를 통하여 평가될 수 있으며, 이를 위해 정부는 각종 측정 수단을 구비하여 계획 대비 집행 성과를 수집하고 이 성과 정보를 환류하여 차년도 예산을 합리적으로 편성하기 위해 노력하고 있습니다.\n",
      "3.  프로그램 예산체계는 각 부처에서 동질적인 사업의 묶음인 프로그램을 예산 편성 착수 전에 미리 결정하고 성과 목표 수준도 함께 정하는 것으로, 프로그램 내의 사업 간 비교 기준이 명확해지고 성과를 중심으로 재정에 환류하기가 용이합니다.\n",
      "Q70================================================\n",
      "Questions:  재정성과관리제도의 중요성과 국정운영과의 연결성은 무엇인가?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run(model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"):\n",
    "\n",
    "    \n",
    "    llm = setup_llm_pipeline(model_id)\n",
    "    # reordering = LongContextReorder()\n",
    "    results =[]\n",
    "    iii = [19,24,57,58,61,65,70,73,78,87]\n",
    "    for i in (iii):\n",
    "        \n",
    "        fewshot_str = make_fewshot_string(fewshot_prompt, train_retriever, test_dict[i])\n",
    "        # print(fewshot_str)\n",
    "        \n",
    "        full_template = \"\"\"\n",
    "##################################################\n",
    "You will be my Financial Q&A helper.\n",
    "\n",
    "\n",
    "##################################################\n",
    "Below is an example of an answer taskic that you should reference.:\n",
    "##################################################\n",
    "\"\"\" +\"\"\"Here are some rules you should follow.\n",
    "\n",
    "Rule 1: Be sure to utilize retrieved contexts for your answers.\n",
    "Rule 2: The most important thing is to be concise and relevant in your answers. \n",
    "Rule 3: Answers must be written in Korean.\n",
    "Rule 4: Use fewer than 128 tokens.\n",
    "Rule 5: If you can't answer that, try summarizing the context and make it a 1-2 Sentence summary.\n",
    "\n",
    "##################################################\n",
    "<|start_header_id|>context<|end_header_id|>: <|begin_of_text|>{context}<|end_of_text|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>: <|begin_of_text|>{input}<|end_of_text|>\n",
    "\n",
    "<|start_header_id|>assistant<|end_header_id|>: \n",
    "\"\"\"\n",
    "        prompt = PromptTemplate.from_template(full_template)\n",
    "        qa_chain = (\n",
    "        {\n",
    "            \"context\": test_retriver | format_docs,\n",
    "            \"input\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "        )\n",
    "        print(f\"Q{i}================================================\")\n",
    "        print(\"Questions: \",test_dict[i]['Question'])\n",
    "        answer = qa_chain.invoke(test_dict[i]['Question'])\n",
    "        #answer = extract_answer(answer)\n",
    "        results.append({\n",
    "            \"Question\": test_dict[i]['Question'],\n",
    "            \"Answer\": answer,\n",
    "            \"Source\": test_dict[i]['Source']\n",
    "            })\n",
    "        print(\"Answer: \",results[-1]['Answer'])\n",
    "        #print(results[-1]['Source'])\n",
    "run(model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
